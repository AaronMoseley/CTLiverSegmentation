{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install d2l==1.0.0b0\n",
        "!conda install -c conda-forge torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y_BxamkKyQSd",
        "outputId": "0984efd3-e7e2-4ac0-aeaf-ee016035eb02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:16\n",
            "🔁 Restarting kernel...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch\n",
            "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
            "Installing collected packages: typing-extensions, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 typing-extensions-4.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.14.1-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/site-packages (from torchvision) (1.13.1)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from torchvision) (2.28.1)\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (65.5.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (1.26.13)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (2022.9.24)\n",
            "Installing collected packages: pillow, numpy, torchvision\n",
            "Successfully installed numpy-1.24.2 pillow-9.4.0 torchvision-0.14.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l==1.0.0b0\n",
            "  Downloading d2l-1.0.0b0-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from d2l==1.0.0b0) (2.28.1)\n",
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.9.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from d2l==1.0.0b0) (1.24.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym==0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting cloudpickle>=1.2.0\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting linear-operator>=0.2.0\n",
            "  Downloading linear_operator-0.3.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting notebook\n",
            "  Downloading notebook-6.5.3-py3-none-any.whl (529 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-console\n",
            "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.21.3-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbconvert\n",
            "  Downloading nbconvert-7.2.9-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipywidgets\n",
            "  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.8/137.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.39.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources>=3.2.0\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->d2l==1.0.0b0) (9.4.0)\n",
            "Collecting traitlets\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (1.26.13)\n",
            "Collecting zipp>=3.1.0\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/site-packages (from linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (1.13.1)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pyzmq>=20\n",
            "  Downloading pyzmq-25.0.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-8.0.3-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12\n",
            "  Downloading jupyter_core-5.2.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.3/94.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado>=6.1\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting comm>=0.1.1\n",
            "  Downloading comm-0.1.2-py3-none-any.whl (6.5 kB)\n",
            "Collecting debugpy>=1.6.5\n",
            "  Downloading debugpy-1.6.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=7.23.1\n",
            "  Downloading ipython-8.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.3/793.3 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting jupyterlab-widgets~=3.0\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting widgetsnbextension~=4.0\n",
            "  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit>=3.0.30\n",
            "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbformat>=5.1\n",
            "  Downloading nbformat-5.7.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.1/78.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-pygments\n",
            "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting defusedxml\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting tinycss2\n",
            "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
            "Collecting importlib-metadata>=3.6\n",
            "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting markupsafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting pandocfilters>=1.4.1\n",
            "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting nbclient>=0.5.0\n",
            "  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mistune<3,>=2.0.3\n",
            "  Downloading mistune-2.0.5-py2.py3-none-any.whl (24 kB)\n",
            "Collecting bleach\n",
            "  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.5/162.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argon2-cffi\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Collecting terminado>=0.8.3\n",
            "  Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\n",
            "Collecting nbclassic>=0.4.7\n",
            "  Downloading nbclassic-0.5.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Send2Trash>=1.8.0\n",
            "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
            "Collecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting prometheus-client\n",
            "  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting platformdirs>=2.5\n",
            "  Downloading platformdirs-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting jupyter-server>=1.8\n",
            "  Downloading jupyter_server-2.4.0-py3-none-any.whl (366 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.7/366.7 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
            "Collecting jsonschema>=2.6\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastjsonschema\n",
            "  Downloading fastjsonschema-2.16.3-py3-none-any.whl (23 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting ptyprocess\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.10.3.66)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (65.5.1)\n",
            "Collecting argon2-cffi-bindings\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=17.4.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio>=3.1.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websocket-client\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-server-terminals\n",
            "  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
            "Collecting jupyter-events>=0.4.0\n",
            "  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (1.15.1)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (2.21)\n",
            "Collecting rfc3986-validator>=0.1.1\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting python-json-logger>=2.0.4\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting pyyaml>=5.3\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616798 sha256=cd80cdd2e0be14f299532fd69491f72a8a6f0eb671165597b8e4a0bc25da1d9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/2e/15/b9642e5913560f946cf8b27f8654e095437c17cada3d5b809e\n",
            "Successfully built gym\n",
            "Installing collected packages: webencodings, wcwidth, Send2Trash, pytz, pure-eval, ptyprocess, pickleshare, mistune, ipython-genutils, fastjsonschema, executing, backcall, zipp, widgetsnbextension, websocket-client, webcolors, uri-template, traitlets, tornado, tinycss2, threadpoolctl, soupsieve, sniffio, six, scipy, rfc3986-validator, pyzmq, pyyaml, python-json-logger, pyrsistent, pyparsing, pygments, psutil, prompt-toolkit, prometheus-client, platformdirs, pkgutil-resolve-name, pexpect, parso, pandocfilters, packaging, nest-asyncio, markupsafe, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, joblib, fqdn, fonttools, defusedxml, decorator, debugpy, cycler, contourpy, cloudpickle, attrs, terminado, scikit-learn, rfc3339-validator, qtpy, python-dateutil, matplotlib-inline, jupyter-core, jinja2, jedi, importlib-resources, importlib-metadata, gym, comm, bleach, beautifulsoup4, asttokens, argon2-cffi-bindings, anyio, stack-data, pandas, matplotlib, jupyter-server-terminals, jupyter-client, jsonschema, arrow, argon2-cffi, nbformat, linear-operator, isoduration, ipython, nbclient, ipykernel, gpytorch, qtconsole, nbconvert, jupyter-events, jupyter-console, ipywidgets, jupyter-server, notebook-shim, nbclassic, notebook, jupyter, d2l\n",
            "Successfully installed Send2Trash-1.8.0 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 asttokens-2.2.1 attrs-22.2.0 backcall-0.2.0 beautifulsoup4-4.11.2 bleach-6.0.0 cloudpickle-2.2.1 comm-0.1.2 contourpy-1.0.7 cycler-0.11.0 d2l-1.0.0b0 debugpy-1.6.6 decorator-5.1.1 defusedxml-0.7.1 executing-1.2.0 fastjsonschema-2.16.3 fonttools-4.39.0 fqdn-1.5.1 gpytorch-1.9.1 gym-0.21.0 importlib-metadata-6.0.0 importlib-resources-5.12.0 ipykernel-6.21.3 ipython-8.11.0 ipython-genutils-0.2.0 ipywidgets-8.0.4 isoduration-20.11.0 jedi-0.18.2 jinja2-3.1.2 joblib-1.2.0 jsonpointer-2.3 jsonschema-4.17.3 jupyter-1.0.0 jupyter-client-8.0.3 jupyter-console-6.6.3 jupyter-core-5.2.0 jupyter-events-0.6.3 jupyter-server-2.4.0 jupyter-server-terminals-0.4.4 jupyterlab-pygments-0.2.2 jupyterlab-widgets-3.0.5 kiwisolver-1.4.4 linear-operator-0.3.0 markupsafe-2.1.2 matplotlib-3.7.1 matplotlib-inline-0.1.6 mistune-2.0.5 nbclassic-0.5.3 nbclient-0.7.2 nbconvert-7.2.9 nbformat-5.7.3 nest-asyncio-1.5.6 notebook-6.5.3 notebook-shim-0.2.2 packaging-23.0 pandas-1.5.3 pandocfilters-1.5.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pkgutil-resolve-name-1.3.10 platformdirs-3.1.0 prometheus-client-0.16.0 prompt-toolkit-3.0.38 psutil-5.9.4 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.14.0 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2022.7.1 pyyaml-6.0 pyzmq-25.0.0 qtconsole-5.4.0 qtpy-2.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 scikit-learn-1.2.1 scipy-1.10.1 six-1.16.0 sniffio-1.3.0 soupsieve-2.4 stack-data-0.6.2 terminado-0.17.1 threadpoolctl-3.1.0 tinycss2-1.2.1 tornado-6.2 traitlets-5.9.0 uri-template-1.2.0 wcwidth-0.2.6 webcolors-1.12 webencodings-0.5.1 websocket-client-1.5.1 widgetsnbextension-4.0.5 zipp-3.15.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "defusedxml",
                  "ipython_genutils",
                  "kiwisolver",
                  "pexpect",
                  "pickleshare",
                  "tornado",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - torchmetrics\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       2_kmp_llvm           6 KB  conda-forge\n",
            "    ca-certificates-2022.12.7  |       ha878542_0         143 KB  conda-forge\n",
            "    certifi-2022.12.7          |     pyhd8ed1ab_0         147 KB  conda-forge\n",
            "    colorama-0.4.6             |     pyhd8ed1ab_0          25 KB  conda-forge\n",
            "    conda-23.1.0               |   py38h578d9bd_0         907 KB  conda-forge\n",
            "    cudatoolkit-11.8.0         |      h37601d7_11       635.9 MB  conda-forge\n",
            "    cudnn-8.4.1.50             |       hed8a83a_0       618.4 MB  conda-forge\n",
            "    libblas-3.9.0              |16_linux64_openblas          13 KB  conda-forge\n",
            "    libcblas-3.9.0             |16_linux64_openblas          13 KB  conda-forge\n",
            "    libgfortran-ng-12.2.0      |      h69a702a_19          22 KB  conda-forge\n",
            "    libgfortran5-12.2.0        |      h337968e_19         1.8 MB  conda-forge\n",
            "    libhwloc-2.9.0             |       hd6dc26d_0         2.4 MB  conda-forge\n",
            "    liblapack-3.9.0            |16_linux64_openblas          13 KB  conda-forge\n",
            "    libopenblas-0.3.21         |pthreads_h78a6416_3        10.1 MB  conda-forge\n",
            "    libprotobuf-3.21.12        |       h3eb15da_0         2.1 MB  conda-forge\n",
            "    llvm-openmp-15.0.7         |       h0cdce71_0         3.1 MB  conda-forge\n",
            "    magma-2.6.2                |       hc72dce7_0       231.5 MB  conda-forge\n",
            "    mkl-2022.2.1               |   h84fe81f_16997       157.3 MB  conda-forge\n",
            "    nccl-2.14.3.1              |       h0800d71_0       145.2 MB  conda-forge\n",
            "    ninja-1.11.1               |       h924138e_0         2.1 MB  conda-forge\n",
            "    numpy-1.24.2               |   py38h10c12cc_0         6.3 MB  conda-forge\n",
            "    openssl-3.0.8              |       h0b41bf4_0         2.5 MB  conda-forge\n",
            "    packaging-23.0             |     pyhd8ed1ab_0          40 KB  conda-forge\n",
            "    pluggy-1.0.0               |     pyhd8ed1ab_5          16 KB  conda-forge\n",
            "    pytorch-1.13.1             |cuda112py38hd94e077_200       362.3 MB  conda-forge\n",
            "    ruamel.yaml-0.17.21        |   py38h0a891b7_2         172 KB  conda-forge\n",
            "    ruamel.yaml.clib-0.2.7     |   py38h1de0b5d_1         143 KB  conda-forge\n",
            "    sleef-3.5.1                |       h9b69904_2         1.5 MB  conda-forge\n",
            "    tbb-2021.8.0               |       hf52228f_0         1.4 MB  conda-forge\n",
            "    torchmetrics-0.11.3        |     pyhd8ed1ab_0         213 KB  conda-forge\n",
            "    tqdm-4.65.0                |     pyhd8ed1ab_1          86 KB  conda-forge\n",
            "    typing_extensions-4.4.0    |     pyha770c72_0          29 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        2.13 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 None\n",
            "  cudatoolkit        conda-forge/linux-64::cudatoolkit-11.8.0-h37601d7_11 None\n",
            "  cudnn              conda-forge/linux-64::cudnn-8.4.1.50-hed8a83a_0 None\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_openblas None\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_openblas None\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19 None\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19 None\n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.9.0-hd6dc26d_0 None\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_openblas None\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.21-pthreads_h78a6416_3 None\n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-3.21.12-h3eb15da_0 None\n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.7-h0cdce71_0 None\n",
            "  magma              conda-forge/linux-64::magma-2.6.2-hc72dce7_0 None\n",
            "  mkl                conda-forge/linux-64::mkl-2022.2.1-h84fe81f_16997 None\n",
            "  nccl               conda-forge/linux-64::nccl-2.14.3.1-h0800d71_0 None\n",
            "  ninja              conda-forge/linux-64::ninja-1.11.1-h924138e_0 None\n",
            "  numpy              conda-forge/linux-64::numpy-1.24.2-py38h10c12cc_0 None\n",
            "  packaging          conda-forge/noarch::packaging-23.0-pyhd8ed1ab_0 None\n",
            "  pluggy             conda-forge/noarch::pluggy-1.0.0-pyhd8ed1ab_5 None\n",
            "  pytorch            conda-forge/linux-64::pytorch-1.13.1-cuda112py38hd94e077_200 None\n",
            "  ruamel.yaml        conda-forge/linux-64::ruamel.yaml-0.17.21-py38h0a891b7_2 None\n",
            "  ruamel.yaml.clib   conda-forge/linux-64::ruamel.yaml.clib-0.2.7-py38h1de0b5d_1 None\n",
            "  sleef              conda-forge/linux-64::sleef-3.5.1-h9b69904_2 None\n",
            "  tbb                conda-forge/linux-64::tbb-2021.8.0-hf52228f_0 None\n",
            "  torchmetrics       conda-forge/noarch::torchmetrics-0.11.3-pyhd8ed1ab_0 None\n",
            "  tqdm               conda-forge/noarch::tqdm-4.65.0-pyhd8ed1ab_1 None\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0 None\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2022.9.24-ha878542_0 --> 2022.12.7-ha878542_0 None\n",
            "  certifi                            2022.9.24-pyhd8ed1ab_0 --> 2022.12.7-pyhd8ed1ab_0 None\n",
            "  conda                               22.9.0-py38h578d9bd_2 --> 23.1.0-py38h578d9bd_0 None\n",
            "  openssl                                  3.0.7-h0b41bf4_1 --> 3.0.8-h0b41bf4_0 None\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-2_kmp_llvm None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.79it/s]\n",
            "ruamel.yaml-0.17.21  | 172 KB    | : 100% 1.0/1 [00:00<00:00, 10.24it/s]\n",
            "tqdm-4.65.0          | 86 KB     | : 100% 1.0/1 [00:00<00:00, 15.46it/s]\n",
            "libprotobuf-3.21.12  | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.33it/s]\n",
            "ca-certificates-2022 | 143 KB    | : 100% 1.0/1 [00:00<00:00, 20.73it/s]\n",
            "cudnn-8.4.1.50       | 618.4 MB  | : 100% 1.0/1 [01:28<00:00, 88.34s/it]  \n",
            "openssl-3.0.8        | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  5.23it/s]\n",
            "libopenblas-0.3.21   | 10.1 MB   | : 100% 1.0/1 [00:02<00:00,  2.07s/it]               \n",
            "numpy-1.24.2         | 6.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.67it/s]\n",
            "nccl-2.14.3.1        | 145.2 MB  | : 100% 1.0/1 [00:19<00:00, 19.39s/it]               \n",
            "tbb-2021.8.0         | 1.4 MB    | : 100% 1.0/1 [00:00<00:00, 12.12it/s]\n",
            "libblas-3.9.0        | 13 KB     | : 100% 1.0/1 [00:00<00:00, 23.56it/s]\n",
            "cudatoolkit-11.8.0   | 635.9 MB  | : 100% 1.0/1 [00:15<00:00, 15.56s/it]               \n",
            "typing_extensions-4. | 29 KB     | : 100% 1.0/1 [00:00<00:00, 14.30it/s]\n",
            "sleef-3.5.1          | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.37it/s]\n",
            "_openmp_mutex-4.5    | 6 KB      | : 100% 1.0/1 [00:00<00:00, 27.66it/s]\n",
            "mkl-2022.2.1         | 157.3 MB  | : 100% 1.0/1 [00:06<00:00,  6.28s/it]               \n",
            "libgfortran5-12.2.0  | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.25it/s]\n",
            "libhwloc-2.9.0       | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  3.08it/s]\n",
            "pluggy-1.0.0         | 16 KB     | : 100% 1.0/1 [00:00<00:00, 24.76it/s]\n",
            "colorama-0.4.6       | 25 KB     | : 100% 1.0/1 [00:00<00:00, 22.91it/s]\n",
            "libgfortran-ng-12.2. | 22 KB     | : 100% 1.0/1 [00:00<00:00, 23.77it/s]\n",
            "ruamel.yaml.clib-0.2 | 143 KB    | : 100% 1.0/1 [00:00<00:00, 23.48it/s]\n",
            "certifi-2022.12.7    | 147 KB    | : 100% 1.0/1 [00:00<00:00, 25.86it/s]\n",
            "pytorch-1.13.1       | 362.3 MB  | : 100% 1.0/1 [00:12<00:00, 12.41s/it]               \n",
            "ninja-1.11.1         | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  9.19it/s]\n",
            "magma-2.6.2          | 231.5 MB  | : 100% 1.0/1 [00:34<00:00, 34.58s/it]               \n",
            "conda-23.1.0         | 907 KB    | : 100% 1.0/1 [00:00<00:00,  4.87it/s]\n",
            "libcblas-3.9.0       | 13 KB     | : 100% 1.0/1 [00:00<00:00, 28.76it/s]\n",
            "packaging-23.0       | 40 KB     | : 100% 1.0/1 [00:00<00:00, 27.34it/s]\n",
            "torchmetrics-0.11.3  | 213 KB    | : 100% 1.0/1 [00:00<00:00,  9.29it/s]\n",
            "liblapack-3.9.0      | 13 KB     | : 100% 1.0/1 [00:00<00:00, 21.62it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
            "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "sbV9155tKF7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl9Rf7gIC-Lb",
        "outputId": "b5104704-7ef1-49ad-b7ec-67096767277f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UySZvCsHhycT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a852da5-a339-4209-f548-bcfa80908fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torchsummary import summary\n",
        "from d2l import torch as d2l\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import gc\n",
        "import skimage\n",
        "import h5py\n",
        "import math\n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight0=1, weight1=1, gamma=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.weight0 = weight0\n",
        "        self.weight1 = weight1\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        loss = 0\n",
        "\n",
        "        #Takes negative average loss over each element of input\n",
        "        #Loss = ln(prediction) * (absolute loss ^ gamma) * class weight\n",
        "        #prediction is the predicted likelihood that the correct label is true\n",
        "        for i, el in enumerate(input):\n",
        "            if target[i] == 1:\n",
        "                loss += torch.log(el) * (abs(1 - el) ** self.gamma) * self.weight1\n",
        "            else:\n",
        "                loss += torch.log(1 - el) * (abs(0 - el) ** self.gamma) * self.weight0\n",
        "\n",
        "        return -1 * loss / len(input)"
      ],
      "metadata": {
        "id": "vBBsw05Qw7DO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BalancedCELoss(nn.Module):\n",
        "    def __init__(self, weight0=1, weight1=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.weight0 = weight0\n",
        "        self.weight1 = weight1\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        loss = 0\n",
        "\n",
        "        #Takes negative average loss over each element of input\n",
        "        #Loss = ln(prediction) * class weight\n",
        "        #prediction is the predicted likelihood that the correct label is true\n",
        "        for i, el in enumerate(input):\n",
        "            if target[i] == 1:\n",
        "                loss += torch.log(el) * self.weight1\n",
        "            else:\n",
        "                loss += torch.log(1 - el) * self.weight0\n",
        "\n",
        "        return -1 * loss / len(input)"
      ],
      "metadata": {
        "id": "IsZV06GU0ue3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LITSBinaryDataset(Dataset):\n",
        "    def __init__(self, fileName):\n",
        "        super().__init__()\n",
        "\n",
        "        #Keeps a file pointer open throughout use\n",
        "        self.file = h5py.File(fileName, 'r')\n",
        "\n",
        "        #Precalculates length to reduce training computations\n",
        "        self.length = len(list(self.file.keys()))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.file[\"Slice\" + str(idx)][\"Slice\"]\n",
        "        label = self.file[\"Slice\" + str(idx)].attrs.get(\"ImageLabel\")\n",
        "\n",
        "        result = []\n",
        "\n",
        "        #Returns list containing slice data and image label\n",
        "        #Does not currently return segmentation data, will need to implement for decoder\n",
        "        result.append(torch.Tensor(data[...]).unsqueeze(0))\n",
        "        result.append(torch.Tensor(label).squeeze(0))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def closeFile(self):\n",
        "        #Closes file once dataset is no longer being used\n",
        "        #Do not use class instance after this function is called\n",
        "        self.file.close()"
      ],
      "metadata": {
        "id": "8iO7WioSr-Yk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9-kqO-PVhycU"
      },
      "outputs": [],
      "source": [
        "class convBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, batchNorm, strides, layerMean, layerDev) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        #Uses 2 convolutional layers for each block\n",
        "        self.conv1 = nn.Conv2d(inChannels, outChannels, kernel_size=3, padding=1, stride=strides)\n",
        "        self.conv2 = nn.Conv2d(outChannels, outChannels, kernel_size=3, padding=1)\n",
        "\n",
        "        #Initializes convolutional layers using hyperparameters for mean and standard deviation\n",
        "        nn.init.normal_(self.conv1.weight, mean=layerMean, std=layerDev)\n",
        "        nn.init.normal_(self.conv2.weight, mean=layerMean, std=layerDev)\n",
        "\n",
        "        if(batchNorm):\n",
        "            self.bn1 = nn.BatchNorm2d(outChannels)\n",
        "        else:\n",
        "            self.bn1 = False\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.conv1(X)\n",
        "\n",
        "        if(self.bn1):\n",
        "            Y = self.bn1(Y)\n",
        "\n",
        "        Y = F.relu(Y)\n",
        "\n",
        "        return torch.Tensor(F.relu(self.conv2(Y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q0sgeg3EhycU"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, strides) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        #Creates a convBlock with batch norm and max pooling layer, directly from UNet paper\n",
        "        self.conv = convBlock(inChannels, outChannels, True, strides, 0, 0.025)\n",
        "        self.pool = nn.MaxPool2d(2, stride=strides)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        Y = self.conv.forward(X)\n",
        "\n",
        "        #Will eventually need to return data directly from conv as well as max pooling for the skip connections\n",
        "        #return torch.Tensor(self.pool(Y)), Y\n",
        "        return self.pool(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_rhGtpfGhycV"
      },
      "outputs": [],
      "source": [
        "#Not fully implemented yet, waiting until encoder section performs well enough\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, strides) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.convTrans = nn.ConvTranspose2d(inChannels, outChannels, 2, stride=strides, padding=1)\n",
        "        self.conv = convBlock(outChannels, outChannels, True, strides, 0, 0.25)\n",
        "\n",
        "    def forward(self, X, skipFeatures):\n",
        "        Y = self.convTrans(X)\n",
        "        Y = torch.cat(X, skipFeatures)\n",
        "        return self.conv(Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderNetwork(nn.Module):\n",
        "    def __init__(self, channels, strides, dropout, device) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        #Creates a list of encoder blocks w/ in and out channels specified by parameter\n",
        "        self.blocks = []\n",
        "        for i in range(len(channels)):\n",
        "            if i == 0:\n",
        "                self.blocks.append(EncoderBlock(1, channels[i], 1).to(device))\n",
        "            else:\n",
        "                self.blocks.append(EncoderBlock(channels[i - 1], channels[i], 1).to(device))\n",
        "\n",
        "        #Creates dropout layer and classification branch\n",
        "        self.dropout = nn.Dropout(dropout).to(device)\n",
        "        self.classification = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(channels[-1], 1), nn.Sigmoid()).to(device)\n",
        "\n",
        "    def forward(self, X):\n",
        "        y = X.to(self.device)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            y = block(y)\n",
        "\n",
        "            #Need to check if we use dropout after every layer\n",
        "            y = self.dropout(y)\n",
        "\n",
        "        return self.classification(y)"
      ],
      "metadata": {
        "id": "uBhZXZ3x8mnJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(net, testIter, lossFunc, device=None):\n",
        "    if isinstance(net, nn.Module):\n",
        "        net.eval()\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "\n",
        "    #Accuracy, number of samples, loss\n",
        "    metric = d2l.Accumulator(3)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in testIter:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yhat = net(X)\n",
        "\n",
        "            prediction = torch.round(yhat).to(device)\n",
        "\n",
        "            metric.add(d2l.accuracy(prediction, y) / torch.numel(y), torch.numel(y), lossFunc(yhat, y))\n",
        "\n",
        "    return metric[0] / metric[1], metric[2] / len(testIter)"
      ],
      "metadata": {
        "id": "98eUKvAr2KPz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7ZgVGj5whycV"
      },
      "outputs": [],
      "source": [
        "def train(net: nn.Sequential, trainIter, testIter, numEpochs, startEpoch, learnRate, batchSize, device: torch.device, startDim, epochsToDouble, modelFileName, epochsToSave, \n",
        "          useWandB=False, cosineAnnealing=True, restartEpochs=-1, progressive=False, lossFunc = nn.BCEWithLogitsLoss()):\n",
        "    print(f\"Training on {device}\")\n",
        "    \n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=learnRate)\n",
        "\n",
        "    #Setting restartEpochs to a negative will use no warm restarts, otherwise will use warm restarts \n",
        "    if cosineAnnealing:\n",
        "        if restartEpochs < 0:\n",
        "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "        else:\n",
        "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, restartEpochs, T_mult=1)\n",
        "\n",
        "    numBatches = len(trainIter)\n",
        "    bestValLoss = float('inf')\n",
        "\n",
        "    currDim = startDim\n",
        "    for epoch in range(startEpoch, numEpochs):\n",
        "        #Progressive learning\n",
        "        if (epoch + 1) % epochsToDouble == 0 and progressive == 1:\n",
        "            currDim *= 2\n",
        "        #Reverse progressive learning\n",
        "        elif (epoch + 1) % epochsToDouble == 0 and progressive == 2:\n",
        "            currDim /= 2\n",
        "        \n",
        "        net.train()\n",
        "        \n",
        "        #Loss, accuracy\n",
        "        metric = d2l.Accumulator(2)\n",
        "\n",
        "        for i, (X, y) in enumerate(trainIter):\n",
        "            optimizer.zero_grad()\n",
        "            y = y.to(device)\n",
        "\n",
        "            if progressive > 0:\n",
        "                #If using progressive learning, downsamples image to the current dimension\n",
        "                X = F.interpolate(X, size=int(currDim))\n",
        "\n",
        "            X = X.to(device)\n",
        "\n",
        "            yhat = net(X).squeeze(1)\n",
        "\n",
        "            prediction = torch.round(yhat).to(device)\n",
        "\n",
        "            l = lossFunc(yhat, y)\n",
        "\n",
        "            #print(f\"Loss: {l.item()} Predictions: {yhat.tolist()} Labels: {y.tolist()}\")\n",
        "\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if cosineAnnealing:\n",
        "                scheduler.step(epoch + i / numBatches)\n",
        "\n",
        "            metric.add(l, d2l.accuracy(prediction, y) / batchSize)\n",
        "\n",
        "        #Checkpoints model\n",
        "        if (epoch + 1) % epochsToSave == 0:\n",
        "            torch.save(net.state_dict(), modelFileName + \"Epoch\" + str(epoch))\n",
        "\n",
        "        validationAcc, validationLoss = evaluate_accuracy(net, testIter, lossFunc, device=device)\n",
        "\n",
        "        #Overwrites previous best model based on validation accuracy\n",
        "        if validationLoss < bestValLoss:\n",
        "            bestValLoss = validationLoss\n",
        "            torch.save(net.state_dict(), modelFileName + \"BestLoss\")\n",
        "\n",
        "        print(f\"Train Acc: {metric[1] / numBatches} Validation Acc: {validationAcc} Train Loss: {metric[0] / numBatches} Validation Loss: {validationLoss}\")\n",
        "\n",
        "        #Externally logs epoch info to WandB\n",
        "        if useWandB:\n",
        "            wandb.log({\"Train Acc\": metric[1] / numBatches,\n",
        "                    \"Validation Acc\": validationAcc,\n",
        "                    \"Train Loss\": metric[0] / numBatches,\n",
        "                    \"Validation Loss\": validationLoss\n",
        "                    })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters and training modifications\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "modelName = \"LiverClassifierBaseline\"\n",
        "fileSaveName = \"/content/drive/MyDrive/\" + modelName\n",
        "\n",
        "#Use if starting from a checkpoint\n",
        "startEpoch = 0\n",
        "\n",
        "useWandB = False\n",
        "\n",
        "batchSize = 8\n",
        "learnRate = 0.001\n",
        "epochs = 100\n",
        "dropout = 0.15\n",
        "\n",
        "#Progressive training parameters\n",
        "startDim = 32\n",
        "epochsToDouble = 25\n",
        "\n",
        "#0: not progressive, 1: progressive, 2: reverse progressive\n",
        "progressive = 1\n",
        "\n",
        "#Checkpointing\n",
        "epochsToSave = 10\n",
        "\n",
        "#Learn rate scheduling parameters\n",
        "cosineAnnealing = True\n",
        "cosineRestartEpochs = 10\n",
        "\n",
        "#lossFunc = BalancedCELoss(weight0=1, weight1=1.5)\n",
        "lossFunc = FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n",
        "#lossFunc = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "tbHyODbs1XNH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load model\n",
        "networkFileName = \"\"\n",
        "\n",
        "net = EncoderNetwork([16, 32, 64, 128, 256], 1, dropout, device)\n",
        "#print(summary(net, (1, 256, 256)))\n",
        "\n",
        "#Loads model from file if using a pretrained version\n",
        "if networkFileName != \"\":\n",
        "    net.load_state_dict(torch.load(networkFileName))\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "print(\"Intialized model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvELD2iw1fgj",
        "outputId": "a8150992-13d9-4b66-eed6-220cfadbe4bf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intialized model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Datasets\n",
        "trainDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/PartialTrainDataset.hdf5\")\n",
        "validationDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/ValidationDataset.hdf5\")\n",
        "testDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/TestDataset.hdf5\")\n",
        "\n",
        "trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "validationIter = DataLoader(validationDataset, batch_size=batchSize)\n",
        "testIter = DataLoader(testDataset, batch_size=batchSize)\n",
        "\n",
        "print(\"Dataset loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0JenAeF1rFu",
        "outputId": "fefb794a-1870-4637-c239-30ad558f6b0e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "8YVz5cMohycW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "ccdf7c73-d74f-4bdb-8677-0c5a00b45271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda\n",
            "Train Acc: 0.4006849315068493 Validation Acc: 0.24496644295302014 Train Loss: 0.06682059648510529 Validation Loss: 0.06052293304942156\n",
            "Train Acc: 0.4006849315068493 Validation Acc: 0.24496644295302014 Train Loss: 0.06638380303366544 Validation Loss: 0.06112554963482054\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-8551fde07a48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             })\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m train(net, trainIter, validationIter, epochs, startEpoch, learnRate, batchSize, device, startDim, epochsToDouble, fileSaveName, epochsToSave, useWandB=useWandB, \n\u001b[0m\u001b[1;32m     16\u001b[0m       cosineAnnealing=False, restartEpochs=cosineRestartEpochs, progressive=progressive, lossFunc=lossFunc)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-31b99e190b38>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainIter, testIter, numEpochs, startEpoch, learnRate, batchSize, device, startDim, epochsToDouble, modelFileName, epochsToSave, useWandB, cosineAnnealing, restartEpochs, progressive, lossFunc)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelFileName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Epoch\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mvalidationAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidationLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestIter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#Overwrites previous best model based on validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-ca9d60c13454>\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[0;34m(net, testIter, lossFunc, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/site-packages/d2l/torch.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(y_hat, y)\u001b[0m\n\u001b[1;32m   3150\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3151\u001b[0m     \u001b[0mcmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3152\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msha1_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Train Model\n",
        "gc.collect()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverClassifier1\",\n",
        "            name=modelName,\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "train(net, trainIter, validationIter, epochs, startEpoch, learnRate, batchSize, device, startDim, epochsToDouble, fileSaveName, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=False, restartEpochs=cosineRestartEpochs, progressive=progressive, lossFunc=lossFunc)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Model\n",
        "print(f\"Model: {modelName}\")\n",
        "\n",
        "trainAcc, trainLoss = evaluate_accuracy(net, trainIter, lossFunc, device=device)\n",
        "print(f\"Train Accuracy: {trainAcc} Train Loss: {trainLoss}\")\n",
        "\n",
        "validationAcc, validationLoss = evaluate_accuracy(net, validationIter, lossFunc, device=device)\n",
        "print(f\"Validation Accuracy: {validationAcc} Validation Loss: {validationLoss}\")\n",
        "\n",
        "testAcc, testLoss = evaluate_accuracy(net, testIter, lossFunc, device=device)\n",
        "print(f\"Test Accuracy: {testAcc} Test Loss: {testLoss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1tLSjzH2F-Z",
        "outputId": "89bcc89e-3e9a-45de-e2c4-be7cc6511797"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LiverClassifierBaseline\n",
            "Train Accuracy: 0.4013722126929674 Train Loss: 0.07085686452584723\n",
            "Train Accuracy: 0.24496644295302014 Train Loss: 0.060490624390934646\n",
            "Test Accuracy: 0.5031766200762389 Test Loss: 0.07727372571073397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Close datasets\n",
        "trainDataset.closeFile()\n",
        "validationDataset.closeFile()\n",
        "testDataset.closeFile()"
      ],
      "metadata": {
        "id": "7LDAG1Pd2KXN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ea23a5d6ea5dd6b47a6bacc48f8acbc6e91dc182fa6b25270d70228f0691131c"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}