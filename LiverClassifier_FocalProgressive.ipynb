{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "###\n",
        "!pip install torch\n",
        "###\n",
        "!pip install torchvision\n",
        "!pip install d2l==1.0.0b0\n",
        "!conda install -c conda-forge torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y_BxamkKyQSd",
        "outputId": "d8639539-a74b-4f34-ead3-76ab959b1e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:30\n",
            "🔁 Restarting kernel...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch\n",
            "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
            "Installing collected packages: typing-extensions, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 typing-extensions-4.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.14.1-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from torchvision) (2.28.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/site-packages (from torchvision) (1.13.1)\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (65.5.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (1.26.13)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (2.1.1)\n",
            "Installing collected packages: pillow, numpy, torchvision\n",
            "Successfully installed numpy-1.24.2 pillow-9.4.0 torchvision-0.14.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l==1.0.0b0\n",
            "  Downloading d2l-1.0.0b0-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from d2l==1.0.0b0) (2.28.1)\n",
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.9.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting gym==0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from d2l==1.0.0b0) (1.24.2)\n",
            "Collecting cloudpickle>=1.2.0\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting linear-operator>=0.2.0\n",
            "  Downloading linear_operator-0.3.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-console\n",
            "  Downloading jupyter_console-6.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting nbconvert\n",
            "  Downloading nbconvert-7.2.9-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipykernel\n",
            "  Downloading ipykernel-6.21.2-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipywidgets\n",
            "  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.8/137.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting notebook\n",
            "  Downloading notebook-6.5.2-py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.1/439.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->d2l==1.0.0b0) (9.4.0)\n",
            "Collecting importlib-resources>=3.2.0\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting traitlets\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (2.1.1)\n",
            "Collecting zipp>=3.1.0\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/site-packages (from linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (1.13.1)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting comm>=0.1.1\n",
            "  Downloading comm-0.1.2-py3-none-any.whl (6.5 kB)\n",
            "Collecting pyzmq>=20\n",
            "  Downloading pyzmq-25.0.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado>=6.1\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12\n",
            "  Downloading jupyter_core-5.2.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.3/94.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy>=1.6.5\n",
            "  Downloading debugpy-1.6.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-8.0.3-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=7.23.1\n",
            "  Downloading ipython-8.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.3/793.3 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting jupyterlab-widgets~=3.0\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting widgetsnbextension~=4.0\n",
            "  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit>=3.0.30\n",
            "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tinycss2\n",
            "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
            "Collecting mistune<3,>=2.0.3\n",
            "  Downloading mistune-2.0.5-py2.py3-none-any.whl (24 kB)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting defusedxml\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting jupyterlab-pygments\n",
            "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting nbclient>=0.5.0\n",
            "  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbformat>=5.1\n",
            "  Downloading nbformat-5.7.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.1/78.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bleach\n",
            "  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.5/162.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markupsafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting importlib-metadata>=3.6\n",
            "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting pandocfilters>=1.4.1\n",
            "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argon2-cffi\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Collecting nbclassic>=0.4.7\n",
            "  Downloading nbclassic-0.5.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prometheus-client\n",
            "  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting terminado>=0.8.3\n",
            "  Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\n",
            "Collecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting Send2Trash>=1.8.0\n",
            "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting platformdirs>=2.5\n",
            "  Downloading platformdirs-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
            "Collecting jupyter-server>=1.8\n",
            "  Downloading jupyter_server-2.3.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.8/365.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema>=2.6\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastjsonschema\n",
            "  Downloading fastjsonschema-2.16.3-py3-none-any.whl (23 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting ptyprocess\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (8.5.0.96)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (65.5.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (0.38.4)\n",
            "Collecting argon2-cffi-bindings\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Collecting attrs>=17.4.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio>=3.1.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-events>=0.4.0\n",
            "  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-server-terminals\n",
            "  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (1.15.1)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (2.21)\n",
            "Collecting rfc3986-validator>=0.1.1\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting python-json-logger>=2.0.4\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Collecting pyyaml>=5.3\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616799 sha256=239cdfe93714f3735badbe80651c3f4a2b2e172a8fff5f3ef6e867fc87ce08db\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/2e/15/b9642e5913560f946cf8b27f8654e095437c17cada3d5b809e\n",
            "Successfully built gym\n",
            "Installing collected packages: webencodings, wcwidth, Send2Trash, pytz, pure-eval, ptyprocess, pickleshare, mistune, ipython-genutils, fastjsonschema, executing, backcall, zipp, widgetsnbextension, websocket-client, webcolors, uri-template, traitlets, tornado, tinycss2, threadpoolctl, soupsieve, sniffio, six, scipy, rfc3986-validator, pyzmq, pyyaml, python-json-logger, pyrsistent, pyparsing, pygments, psutil, prompt-toolkit, prometheus-client, platformdirs, pkgutil-resolve-name, pexpect, parso, pandocfilters, packaging, nest-asyncio, markupsafe, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, joblib, fqdn, fonttools, defusedxml, decorator, debugpy, cycler, contourpy, cloudpickle, attrs, terminado, scikit-learn, rfc3339-validator, qtpy, python-dateutil, matplotlib-inline, jupyter-core, jinja2, jedi, importlib-resources, importlib-metadata, gym, comm, bleach, beautifulsoup4, asttokens, argon2-cffi-bindings, anyio, stack-data, pandas, matplotlib, jupyter-server-terminals, jupyter-client, jsonschema, arrow, argon2-cffi, nbformat, linear-operator, isoduration, ipython, nbclient, ipykernel, gpytorch, qtconsole, nbconvert, jupyter-events, jupyter-console, ipywidgets, jupyter-server, notebook-shim, nbclassic, notebook, jupyter, d2l\n",
            "Successfully installed Send2Trash-1.8.0 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 asttokens-2.2.1 attrs-22.2.0 backcall-0.2.0 beautifulsoup4-4.11.2 bleach-6.0.0 cloudpickle-2.2.1 comm-0.1.2 contourpy-1.0.7 cycler-0.11.0 d2l-1.0.0b0 debugpy-1.6.6 decorator-5.1.1 defusedxml-0.7.1 executing-1.2.0 fastjsonschema-2.16.3 fonttools-4.38.0 fqdn-1.5.1 gpytorch-1.9.1 gym-0.21.0 importlib-metadata-6.0.0 importlib-resources-5.12.0 ipykernel-6.21.2 ipython-8.11.0 ipython-genutils-0.2.0 ipywidgets-8.0.4 isoduration-20.11.0 jedi-0.18.2 jinja2-3.1.2 joblib-1.2.0 jsonpointer-2.3 jsonschema-4.17.3 jupyter-1.0.0 jupyter-client-8.0.3 jupyter-console-6.6.2 jupyter-core-5.2.0 jupyter-events-0.6.3 jupyter-server-2.3.0 jupyter-server-terminals-0.4.4 jupyterlab-pygments-0.2.2 jupyterlab-widgets-3.0.5 kiwisolver-1.4.4 linear-operator-0.3.0 markupsafe-2.1.2 matplotlib-3.7.1 matplotlib-inline-0.1.6 mistune-2.0.5 nbclassic-0.5.2 nbclient-0.7.2 nbconvert-7.2.9 nbformat-5.7.3 nest-asyncio-1.5.6 notebook-6.5.2 notebook-shim-0.2.2 packaging-23.0 pandas-1.5.3 pandocfilters-1.5.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pkgutil-resolve-name-1.3.10 platformdirs-3.1.0 prometheus-client-0.16.0 prompt-toolkit-3.0.38 psutil-5.9.4 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.14.0 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2022.7.1 pyyaml-6.0 pyzmq-25.0.0 qtconsole-5.4.0 qtpy-2.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 scikit-learn-1.2.1 scipy-1.10.1 six-1.16.0 sniffio-1.3.0 soupsieve-2.4 stack-data-0.6.2 terminado-0.17.1 threadpoolctl-3.1.0 tinycss2-1.2.1 tornado-6.2 traitlets-5.9.0 uri-template-1.2.0 wcwidth-0.2.6 webcolors-1.12 webencodings-0.5.1 websocket-client-1.5.1 widgetsnbextension-4.0.5 zipp-3.15.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "defusedxml",
                  "ipython_genutils",
                  "kiwisolver",
                  "pexpect",
                  "pickleshare",
                  "tornado",
                  "wcwidth",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - torchmetrics\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       2_kmp_llvm           6 KB  conda-forge\n",
            "    ca-certificates-2022.12.7  |       ha878542_0         143 KB  conda-forge\n",
            "    certifi-2022.12.7          |     pyhd8ed1ab_0         147 KB  conda-forge\n",
            "    colorama-0.4.6             |     pyhd8ed1ab_0          25 KB  conda-forge\n",
            "    conda-23.1.0               |   py38h578d9bd_0         907 KB  conda-forge\n",
            "    cudatoolkit-11.8.0         |      h37601d7_11       635.9 MB  conda-forge\n",
            "    cudnn-8.4.1.50             |       hed8a83a_0       618.4 MB  conda-forge\n",
            "    libblas-3.9.0              |16_linux64_openblas          13 KB  conda-forge\n",
            "    libcblas-3.9.0             |16_linux64_openblas          13 KB  conda-forge\n",
            "    libgfortran-ng-12.2.0      |      h69a702a_19          22 KB  conda-forge\n",
            "    libgfortran5-12.2.0        |      h337968e_19         1.8 MB  conda-forge\n",
            "    libhwloc-2.9.0             |       hd6dc26d_0         2.4 MB  conda-forge\n",
            "    liblapack-3.9.0            |16_linux64_openblas          13 KB  conda-forge\n",
            "    libopenblas-0.3.21         |pthreads_h78a6416_3        10.1 MB  conda-forge\n",
            "    libprotobuf-3.21.12        |       h3eb15da_0         2.1 MB  conda-forge\n",
            "    llvm-openmp-15.0.7         |       h0cdce71_0         3.1 MB  conda-forge\n",
            "    magma-2.6.2                |       hc72dce7_0       231.5 MB  conda-forge\n",
            "    mkl-2022.2.1               |   h84fe81f_16997       157.3 MB  conda-forge\n",
            "    nccl-2.14.3.1              |       h0800d71_0       145.2 MB  conda-forge\n",
            "    ninja-1.11.1               |       h924138e_0         2.1 MB  conda-forge\n",
            "    numpy-1.24.2               |   py38h10c12cc_0         6.3 MB  conda-forge\n",
            "    openssl-3.0.8              |       h0b41bf4_0         2.5 MB  conda-forge\n",
            "    packaging-23.0             |     pyhd8ed1ab_0          40 KB  conda-forge\n",
            "    pluggy-1.0.0               |     pyhd8ed1ab_5          16 KB  conda-forge\n",
            "    pytorch-1.13.1             |cuda112py38hd94e077_200       362.3 MB  conda-forge\n",
            "    ruamel.yaml-0.17.21        |   py38h0a891b7_2         172 KB  conda-forge\n",
            "    ruamel.yaml.clib-0.2.7     |   py38h1de0b5d_1         143 KB  conda-forge\n",
            "    sleef-3.5.1                |       h9b69904_2         1.5 MB  conda-forge\n",
            "    tbb-2021.8.0               |       hf52228f_0         1.4 MB  conda-forge\n",
            "    torchmetrics-0.11.3        |     pyhd8ed1ab_0         213 KB  conda-forge\n",
            "    tqdm-4.65.0                |     pyhd8ed1ab_1          86 KB  conda-forge\n",
            "    typing_extensions-4.4.0    |     pyha770c72_0          29 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        2.13 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 None\n",
            "  cudatoolkit        conda-forge/linux-64::cudatoolkit-11.8.0-h37601d7_11 None\n",
            "  cudnn              conda-forge/linux-64::cudnn-8.4.1.50-hed8a83a_0 None\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_openblas None\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_openblas None\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19 None\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19 None\n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.9.0-hd6dc26d_0 None\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_openblas None\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.21-pthreads_h78a6416_3 None\n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-3.21.12-h3eb15da_0 None\n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.7-h0cdce71_0 None\n",
            "  magma              conda-forge/linux-64::magma-2.6.2-hc72dce7_0 None\n",
            "  mkl                conda-forge/linux-64::mkl-2022.2.1-h84fe81f_16997 None\n",
            "  nccl               conda-forge/linux-64::nccl-2.14.3.1-h0800d71_0 None\n",
            "  ninja              conda-forge/linux-64::ninja-1.11.1-h924138e_0 None\n",
            "  numpy              conda-forge/linux-64::numpy-1.24.2-py38h10c12cc_0 None\n",
            "  packaging          conda-forge/noarch::packaging-23.0-pyhd8ed1ab_0 None\n",
            "  pluggy             conda-forge/noarch::pluggy-1.0.0-pyhd8ed1ab_5 None\n",
            "  pytorch            conda-forge/linux-64::pytorch-1.13.1-cuda112py38hd94e077_200 None\n",
            "  ruamel.yaml        conda-forge/linux-64::ruamel.yaml-0.17.21-py38h0a891b7_2 None\n",
            "  ruamel.yaml.clib   conda-forge/linux-64::ruamel.yaml.clib-0.2.7-py38h1de0b5d_1 None\n",
            "  sleef              conda-forge/linux-64::sleef-3.5.1-h9b69904_2 None\n",
            "  tbb                conda-forge/linux-64::tbb-2021.8.0-hf52228f_0 None\n",
            "  torchmetrics       conda-forge/noarch::torchmetrics-0.11.3-pyhd8ed1ab_0 None\n",
            "  tqdm               conda-forge/noarch::tqdm-4.65.0-pyhd8ed1ab_1 None\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0 None\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2022.9.24-ha878542_0 --> 2022.12.7-ha878542_0 None\n",
            "  certifi                            2022.9.24-pyhd8ed1ab_0 --> 2022.12.7-pyhd8ed1ab_0 None\n",
            "  conda                               22.9.0-py38h578d9bd_2 --> 23.1.0-py38h578d9bd_0 None\n",
            "  openssl                                  3.0.7-h0b41bf4_1 --> 3.0.8-h0b41bf4_0 None\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-2_kmp_llvm None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "libopenblas-0.3.21   | 10.1 MB   | : 100% 1.0/1 [00:02<00:00,  2.16s/it]\n",
            "ninja-1.11.1         | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  9.16it/s]\n",
            "liblapack-3.9.0      | 13 KB     | : 100% 1.0/1 [00:00<00:00, 26.48it/s]\n",
            "libcblas-3.9.0       | 13 KB     | : 100% 1.0/1 [00:00<00:00, 28.40it/s]\n",
            "colorama-0.4.6       | 25 KB     | : 100% 1.0/1 [00:00<00:00, 22.56it/s]\n",
            "libprotobuf-3.21.12  | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  6.01it/s]\n",
            "libblas-3.9.0        | 13 KB     | : 100% 1.0/1 [00:00<00:00, 24.51it/s]\n",
            "cudatoolkit-11.8.0   | 635.9 MB  | : 100% 1.0/1 [00:16<00:00, 16.58s/it]               \n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.22it/s]                \n",
            "torchmetrics-0.11.3  | 213 KB    | : 100% 1.0/1 [00:00<00:00, 11.22it/s]\n",
            "libhwloc-2.9.0       | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  4.88it/s]\n",
            "certifi-2022.12.7    | 147 KB    | : 100% 1.0/1 [00:00<00:00, 35.84it/s]\n",
            "pluggy-1.0.0         | 16 KB     | : 100% 1.0/1 [00:00<00:00, 30.08it/s]\n",
            "cudnn-8.4.1.50       | 618.4 MB  | : 100% 1.0/1 [01:29<00:00, 89.76s/it]               \n",
            "libgfortran-ng-12.2. | 22 KB     | : 100% 1.0/1 [00:00<00:00, 24.05it/s]\n",
            "conda-23.1.0         | 907 KB    | : 100% 1.0/1 [00:00<00:00,  2.90it/s]\n",
            "libgfortran5-12.2.0  | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.31it/s]\n",
            "_openmp_mutex-4.5    | 6 KB      | : 100% 1.0/1 [00:00<00:00, 43.37it/s]\n",
            "sleef-3.5.1          | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  3.43it/s]\n",
            "typing_extensions-4. | 29 KB     | : 100% 1.0/1 [00:00<00:00, 32.02it/s]\n",
            "tqdm-4.65.0          | 86 KB     | : 100% 1.0/1 [00:00<00:00, 23.80it/s]\n",
            "magma-2.6.2          | 231.5 MB  | : 100% 1.0/1 [00:36<00:00, 36.21s/it]               \n",
            "packaging-23.0       | 40 KB     | : 100% 1.0/1 [00:00<00:00, 22.93it/s]\n",
            "ca-certificates-2022 | 143 KB    | : 100% 1.0/1 [00:00<00:00, 15.35it/s]\n",
            "nccl-2.14.3.1        | 145.2 MB  | : 100% 1.0/1 [00:19<00:00, 19.06s/it]               \n",
            "pytorch-1.13.1       | 362.3 MB  | : 100% 1.0/1 [00:12<00:00, 12.52s/it]               \n",
            "ruamel.yaml.clib-0.2 | 143 KB    | : 100% 1.0/1 [00:00<00:00, 23.50it/s]\n",
            "numpy-1.24.2         | 6.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.63it/s]\n",
            "tbb-2021.8.0         | 1.4 MB    | : 100% 1.0/1 [00:00<00:00, 15.24it/s]\n",
            "mkl-2022.2.1         | 157.3 MB  | : 100% 1.0/1 [00:08<00:00,  8.81s/it]               \n",
            "ruamel.yaml-0.17.21  | 172 KB    | : 100% 1.0/1 [00:00<00:00,  8.13it/s]\n",
            "openssl-3.0.8        | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  5.64it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
            "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "sbV9155tKF7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1db4f5-bd6f-4718-9e83-ccc6870425fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamoseley018\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl9Rf7gIC-Lb",
        "outputId": "d7d2098a-6e5d-400b-83df-89445b39e328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UySZvCsHhycT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb27349-f68c-41d4-904b-f20cc47492e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torchsummary import summary\n",
        "from d2l import torch as d2l\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import gc\n",
        "import skimage\n",
        "import h5py\n",
        "import math\n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight0=1, weight1=1, gamma=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.weight0 = weight0\n",
        "        self.weight1 = weight1\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        loss = 0\n",
        "        for i, el in enumerate(input):\n",
        "            if target[i] == 1:\n",
        "                loss += torch.log(el) * (abs(1 - el) ** self.gamma) * self.weight1\n",
        "            else:\n",
        "                loss += torch.log(1 - el) * (abs(0 - el) ** self.gamma) * self.weight0\n",
        "\n",
        "        return -1 * loss / len(input)"
      ],
      "metadata": {
        "id": "vBBsw05Qw7DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BalancedCELoss(nn.Module):\n",
        "    def __init__(self, weight0=1, weight1=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.weight0 = weight0\n",
        "        self.weight1 = weight1\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        loss = 0\n",
        "        for i, el in enumerate(input):\n",
        "            if target[i] == 1:\n",
        "                loss += torch.log(el) * self.weight1\n",
        "            else:\n",
        "                loss += torch.log(1 - el) * self.weight0\n",
        "\n",
        "        return -1 * loss / len(input)"
      ],
      "metadata": {
        "id": "IsZV06GU0ue3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LITSBinaryDataset(Dataset):\n",
        "    def __init__(self, fileName):\n",
        "        super().__init__()\n",
        "\n",
        "        self.file = h5py.File(fileName, 'r')\n",
        "\n",
        "        self.length = len(list(self.file.keys()))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.file[\"Slice\" + str(idx)][\"Slice\"]\n",
        "        label = self.file[\"Slice\" + str(idx)].attrs.get(\"ImageLabel\")\n",
        "\n",
        "        result = []\n",
        "\n",
        "        result.append(torch.Tensor(data[...]).unsqueeze(0))\n",
        "        result.append(torch.Tensor(label).squeeze(0))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def closeFile(self):\n",
        "        self.file.close()"
      ],
      "metadata": {
        "id": "8iO7WioSr-Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-kqO-PVhycU"
      },
      "outputs": [],
      "source": [
        "class convBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, batchNorm, strides, layerMean, layerDev) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inChannels, outChannels, kernel_size=3, padding=1, stride=strides)\n",
        "        self.conv2 = nn.Conv2d(outChannels, outChannels, kernel_size=3, padding=1)\n",
        "\n",
        "        nn.init.normal_(self.conv1.weight, mean=layerMean, std=layerDev)\n",
        "        nn.init.normal_(self.conv2.weight, mean=layerMean, std=layerDev)\n",
        "\n",
        "        if(batchNorm):\n",
        "            self.bn1 = nn.BatchNorm2d(outChannels)\n",
        "        else:\n",
        "            self.bn1 = False\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.conv1(X)\n",
        "\n",
        "        if(self.bn1):\n",
        "            Y = self.bn1(Y)\n",
        "\n",
        "        Y = F.relu(Y)\n",
        "\n",
        "        return torch.Tensor(F.relu(self.conv2(Y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0sgeg3EhycU"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, strides) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = convBlock(inChannels, outChannels, True, strides, 0, 0.025)\n",
        "        self.pool = nn.MaxPool2d(2, stride=strides)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        Y = self.conv.forward(X)\n",
        "\n",
        "        #return torch.Tensor(self.pool(Y)), Y\n",
        "        return self.pool(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rhGtpfGhycV"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, strides) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.convTrans = nn.ConvTranspose2d(inChannels, outChannels, 2, stride=strides, padding=1)\n",
        "        self.conv = convBlock(outChannels, outChannels, True, strides, 0, 0.25)\n",
        "\n",
        "    def forward(self, X, skipFeatures):\n",
        "        Y = self.convTrans(X)\n",
        "        Y = torch.cat(X, skipFeatures)\n",
        "        return self.conv(Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(net, testIter, lossFunc, device=None):\n",
        "    if isinstance(net, nn.Module):\n",
        "        net.eval()\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "\n",
        "    metric = d2l.Accumulator(3)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in testIter:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yhat = net(X)\n",
        "\n",
        "            prediction = torch.round(yhat).to(device)\n",
        "\n",
        "            metric.add(d2l.accuracy(prediction, y) / torch.numel(y), torch.numel(y), lossFunc(yhat, y))\n",
        "\n",
        "    return metric[0] / metric[1], metric[2] / len(testIter)"
      ],
      "metadata": {
        "id": "98eUKvAr2KPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZgVGj5whycV"
      },
      "outputs": [],
      "source": [
        "def train(net: nn.Sequential, trainIter, testIter, numEpochs, startEpoch, learnRate, batchSize, device: torch.device, startDim, epochsToDouble, modelFileName, epochsToSave, cosineAnnealing=True, progressive=False, lossFunc = nn.BCEWithLogitsLoss()):\n",
        "    print(f\"Training on {device}\")\n",
        "    \n",
        "    net.to(device)\n",
        "    #Adaptive learning w/ learning rate scheduler, can use Adam\n",
        "    #Cosine scheduler (can also use linear, not as widely used), cosine annealing w/ lr restart\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=learnRate)\n",
        "\n",
        "    if cosineAnnealing:\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 10, T_mult=1)\n",
        "        #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    numBatches = len(trainIter)\n",
        "\n",
        "    imageFunc = transforms.ToPILImage()\n",
        "    tensorFunc = transforms.ToTensor()\n",
        "\n",
        "    bestValLoss = float('inf')\n",
        "\n",
        "    currDim = startDim\n",
        "    for epoch in range(startEpoch, numEpochs):\n",
        "        if (epoch + 1) % epochsToDouble == 0 and progressive == 1:\n",
        "            currDim *= 2\n",
        "        elif (epoch + 1) % epochsToDouble == 0 and progressive == 2:\n",
        "            currDim /= 2\n",
        "        \n",
        "        net.train()\n",
        "        metric = d2l.Accumulator(2)\n",
        "\n",
        "        for i, (X, y) in enumerate(trainIter):\n",
        "            optimizer.zero_grad()\n",
        "            y = y.to(device)\n",
        "\n",
        "            if progressive > 0:\n",
        "                X = F.interpolate(X, size=int(currDim))\n",
        "\n",
        "            X = X.to(device)\n",
        "\n",
        "            yhat = net(X).squeeze(1)\n",
        "\n",
        "            prediction = torch.round(yhat).to(device)\n",
        "\n",
        "            l = lossFunc(yhat, y)\n",
        "\n",
        "            #print(f\"Loss: {l.item()} Predictions: {yhat.tolist()} Labels: {y.tolist()}\")\n",
        "\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if cosineAnnealing:\n",
        "                scheduler.step(epoch + i / numBatches)\n",
        "\n",
        "            metric.add(l, d2l.accuracy(prediction, y) / batchSize)\n",
        "\n",
        "        if (epoch + 1) % epochsToSave == 0:\n",
        "            torch.save(net.state_dict(), modelFileName + \"Epoch\" + str(epoch))\n",
        "\n",
        "        validationAcc, validationLoss = evaluate_accuracy(net, testIter, lossFunc, device=device)\n",
        "\n",
        "        if validationLoss < bestValLoss:\n",
        "            bestValLoss = validationLoss\n",
        "            torch.save(net.state_dict(), modelFileName + \"BestLoss\")\n",
        "\n",
        "        #Also save on accuracy, test if they're the same\n",
        "\n",
        "        print(f\"Train Acc: {metric[1] / numBatches} Validation Acc: {validationAcc} Train Loss: {metric[0] / numBatches} Validation Loss: {validationLoss}\")\n",
        "\n",
        "        wandb.log({\"Train Acc\": metric[1] / numBatches,\n",
        "                   \"Validation Acc\": validationAcc,\n",
        "                   \"Train Loss\": metric[0] / numBatches,\n",
        "                   \"Validation Loss\": validationLoss\n",
        "                  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YVz5cMohycW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9ff8d15ecf3647ef892e0fbb7bf1c2e8",
            "773fcf88a2ea44cbaafc1c653f209088",
            "15e864464408494181f05c4e2a67c170",
            "482e5a20616d4573aef6d8912c543e30",
            "aa0fab273f2545d0b709dd4f6872f717",
            "9247072928184d50898f37dc3b0b7f7d",
            "e440f01eb5824c1c87566ab3a38faf0f",
            "376c3f18b7d043719da8814eadbe6999"
          ]
        },
        "outputId": "e5ecc81f-cecb-4f4f-839b-21804434d194"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230306_015649-58t3yqk4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amoseley018/LiverClassifier1/runs/58t3yqk4' target=\"_blank\">ReverseProgressive10EpochRestarts</a></strong> to <a href='https://wandb.ai/amoseley018/LiverClassifier1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/amoseley018/LiverClassifier1' target=\"_blank\">https://wandb.ai/amoseley018/LiverClassifier1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/amoseley018/LiverClassifier1/runs/58t3yqk4' target=\"_blank\">https://wandb.ai/amoseley018/LiverClassifier1/runs/58t3yqk4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intialized model\n",
            "Dataset loaded\n",
            "Training on cuda\n",
            "Train Acc: 0.410958904109589 Validation Acc: 0.24496644295302014 Train Loss: 0.06974626597884583 Validation Loss: 0.06774948174624067\n",
            "Train Acc: 0.4006849315068493 Validation Acc: 0.24496644295302014 Train Loss: 0.06646110102126043 Validation Loss: 0.05990935097399511\n",
            "Train Acc: 0.4623287671232877 Validation Acc: 0.7550335570469798 Train Loss: 0.06071338261643501 Validation Loss: 7.455821351001137\n",
            "Train Acc: 0.6712328767123288 Validation Acc: 0.24496644295302014 Train Loss: 0.051581499102997454 Validation Loss: 0.14434785920342333\n",
            "Train Acc: 0.678082191780822 Validation Acc: 0.24496644295302014 Train Loss: 0.05000291550404405 Validation Loss: 0.2285755072677459\n",
            "Train Acc: 0.7106164383561644 Validation Acc: 0.7550335570469798 Train Loss: 0.04662974372710267 Validation Loss: 3.3278082044501054\n",
            "Train Acc: 0.6626712328767124 Validation Acc: 0.24496644295302014 Train Loss: 0.04700312447058012 Validation Loss: 0.20911707156215256\n",
            "Train Acc: 0.7842465753424658 Validation Acc: 0.24496644295302014 Train Loss: 0.03623331903339657 Validation Loss: 0.09810752558865045\n",
            "Train Acc: 0.8167808219178082 Validation Acc: 0.7550335570469798 Train Loss: 0.03406598227583382 Validation Loss: 5.667655656212254\n",
            "Train Acc: 0.8424657534246576 Validation Acc: 0.7550335570469798 Train Loss: 0.02971732470985145 Validation Loss: 4.246511544051923\n",
            "Train Acc: 0.8287671232876712 Validation Acc: 0.7550335570469798 Train Loss: 0.03334237678512318 Validation Loss: 0.7933287104661387\n",
            "Train Acc: 0.8578767123287672 Validation Acc: 0.7550335570469798 Train Loss: 0.02424559089010709 Validation Loss: 3.0869012851464124\n",
            "Train Acc: 0.8732876712328768 Validation Acc: 0.24496644295302014 Train Loss: 0.02571321443227209 Validation Loss: 0.11577511587988977\n",
            "Train Acc: 0.8818493150684932 Validation Acc: 0.7550335570469798 Train Loss: 0.021987259391159433 Validation Loss: 8.112853050231934\n",
            "Train Acc: 0.815068493150685 Validation Acc: 0.7550335570469798 Train Loss: 0.03348991067199777 Validation Loss: 1.4496431328193515\n",
            "Train Acc: 0.815068493150685 Validation Acc: 0.7550335570469798 Train Loss: 0.03308423294379593 Validation Loss: 1.74202984728357\n",
            "Train Acc: 0.8921232876712328 Validation Acc: 0.7516778523489933 Train Loss: 0.02006899677488111 Validation Loss: 0.10744357723677622\n",
            "Train Acc: 0.8578767123287672 Validation Acc: 0.7550335570469798 Train Loss: 0.027639046330515244 Validation Loss: 14.404960168035407\n",
            "Train Acc: 0.8938356164383562 Validation Acc: 0.5805369127516778 Train Loss: 0.022721054389664572 Validation Loss: 0.22002064024165616\n",
            "Train Acc: 0.8904109589041096 Validation Acc: 0.7550335570469798 Train Loss: 0.01732745183925208 Validation Loss: 8.714829890351547\n",
            "Train Acc: 0.9178082191780822 Validation Acc: 0.7550335570469798 Train Loss: 0.016970143611989404 Validation Loss: 1.7387677701685795\n",
            "Train Acc: 0.8801369863013698 Validation Acc: 0.7550335570469798 Train Loss: 0.022855465949436472 Validation Loss: 3.5576703203351876\n",
            "Train Acc: 0.8904109589041096 Validation Acc: 0.7550335570469798 Train Loss: 0.0210426830182694 Validation Loss: 1.9392628941866465\n",
            "Train Acc: 0.9041095890410958 Validation Acc: 0.7550335570469798 Train Loss: 0.02218777990153646 Validation Loss: 4.001805813688981\n",
            "Train Acc: 0.8304794520547946 Validation Acc: 0.7340604026845637 Train Loss: 0.03321018892225541 Validation Loss: 0.3180282294606992\n",
            "Train Acc: 0.8578767123287672 Validation Acc: 0.7550335570469798 Train Loss: 0.02591309732476836 Validation Loss: 1.2691351573711755\n",
            "Train Acc: 0.8647260273972602 Validation Acc: 0.4337248322147651 Train Loss: 0.021864199267751346 Validation Loss: 0.09385186825927935\n",
            "Train Acc: 0.898972602739726 Validation Acc: 0.7550335570469798 Train Loss: 0.019233162825837834 Validation Loss: 1.541814216308292\n",
            "Train Acc: 0.8955479452054794 Validation Acc: 0.7550335570469798 Train Loss: 0.018586363512241244 Validation Loss: 2.004591401038789\n",
            "Train Acc: 0.8818493150684932 Validation Acc: 0.4773489932885906 Train Loss: 0.022909247032159376 Validation Loss: 0.154009689534034\n",
            "Train Acc: 0.9126712328767124 Validation Acc: 0.7550335570469798 Train Loss: 0.01730190408543671 Validation Loss: 0.42959142506611225\n",
            "Train Acc: 0.9178082191780822 Validation Acc: 0.24496644295302014 Train Loss: 0.01591093605782913 Validation Loss: 0.08482755469403376\n",
            "Train Acc: 0.9023972602739726 Validation Acc: 0.7550335570469798 Train Loss: 0.01968086167072801 Validation Loss: 3.3132085674687435\n",
            "Train Acc: 0.9297945205479452 Validation Acc: 0.7550335570469798 Train Loss: 0.015324891331184604 Validation Loss: 0.517491605085716\n",
            "Train Acc: 0.9366438356164384 Validation Acc: 0.7340604026845637 Train Loss: 0.01201224310841086 Validation Loss: 0.24242698706437318\n",
            "Train Acc: 0.9212328767123288 Validation Acc: 0.7407718120805369 Train Loss: 0.01758629050502898 Validation Loss: 0.4213734162924391\n",
            "Train Acc: 0.9315068493150684 Validation Acc: 0.7550335570469798 Train Loss: 0.014835119143380362 Validation Loss: 3.373090558930447\n",
            "Train Acc: 0.9383561643835616 Validation Acc: 0.7550335570469798 Train Loss: 0.013550428626580445 Validation Loss: 0.8038437701014636\n",
            "Train Acc: 0.9195205479452054 Validation Acc: 0.7550335570469798 Train Loss: 0.018647310060085347 Validation Loss: 0.4530135865126412\n",
            "Train Acc: 0.934931506849315 Validation Acc: 0.5201342281879194 Train Loss: 0.013534761107309836 Validation Loss: 0.09494979343655455\n",
            "Train Acc: 0.9503424657534246 Validation Acc: 0.7550335570469798 Train Loss: 0.010288729861837952 Validation Loss: 0.5706464382986863\n",
            "Train Acc: 0.9178082191780822 Validation Acc: 0.14093959731543623 Train Loss: 0.016950569747491064 Validation Loss: 0.19522836167781957\n",
            "Train Acc: 0.9452054794520548 Validation Acc: 0.7550335570469798 Train Loss: 0.011625827155761702 Validation Loss: 0.9820053847668739\n",
            "Train Acc: 0.9263698630136986 Validation Acc: 0.7550335570469798 Train Loss: 0.014617587779792128 Validation Loss: 0.9852711386568153\n",
            "Train Acc: 0.9452054794520548 Validation Acc: 0.7550335570469798 Train Loss: 0.009842436851563621 Validation Loss: 1.2604498188307176\n",
            "Train Acc: 0.9417808219178082 Validation Acc: 0.7550335570469798 Train Loss: 0.010678260767161017 Validation Loss: 1.2193464800873948\n",
            "Train Acc: 0.9554794520547946 Validation Acc: 0.7550335570469798 Train Loss: 0.00798611950583968 Validation Loss: 3.2244198886971756\n",
            "Train Acc: 0.9332191780821918 Validation Acc: 0.5763422818791947 Train Loss: 0.014058807028847434 Validation Loss: 0.09325619568086327\n",
            "Train Acc: 0.9332191780821918 Validation Acc: 0.7550335570469798 Train Loss: 0.013966537944251697 Validation Loss: 0.5091202133040055\n",
            "Train Acc: 0.8818493150684932 Validation Acc: 0.7550335570469798 Train Loss: 0.0276386320602136 Validation Loss: 0.3297898000411662\n",
            "Train Acc: 0.9143835616438356 Validation Acc: 0.7550335570469798 Train Loss: 0.015867398953709547 Validation Loss: 0.4219254178660776\n",
            "Train Acc: 0.9623287671232876 Validation Acc: 0.7550335570469798 Train Loss: 0.007776897813453441 Validation Loss: 0.437257342149367\n",
            "Train Acc: 0.9486301369863014 Validation Acc: 0.32550335570469796 Train Loss: 0.009825751542238111 Validation Loss: 0.0796719046897794\n",
            "Train Acc: 0.9315068493150684 Validation Acc: 0.24496644295302014 Train Loss: 0.012590419608710513 Validation Loss: 0.30745474115323496\n",
            "Train Acc: 0.9571917808219178 Validation Acc: 0.7550335570469798 Train Loss: 0.010738831762167025 Validation Loss: 0.41375280412008625\n",
            "Train Acc: 0.958904109589041 Validation Acc: 0.6812080536912751 Train Loss: 0.008688831138735548 Validation Loss: 0.06506262886288919\n",
            "Train Acc: 0.9537671232876712 Validation Acc: 0.24496644295302014 Train Loss: 0.01158061786734161 Validation Loss: 0.10437752049122202\n",
            "Train Acc: 0.9417808219178082 Validation Acc: 0.7550335570469798 Train Loss: 0.012054605297871853 Validation Loss: 1.2337535403971545\n",
            "Train Acc: 0.9486301369863014 Validation Acc: 0.7550335570469798 Train Loss: 0.009789039206225425 Validation Loss: 0.23989781886714473\n",
            "Train Acc: 0.964041095890411 Validation Acc: 0.7231543624161074 Train Loss: 0.010050810554163684 Validation Loss: 0.3162852053960825\n",
            "Train Acc: 0.9708904109589042 Validation Acc: 0.7550335570469798 Train Loss: 0.0052159031034185715 Validation Loss: 0.9348219980702372\n",
            "Train Acc: 0.958904109589041 Validation Acc: 0.7550335570469798 Train Loss: 0.010255452151185425 Validation Loss: 0.5989755864572672\n",
            "Train Acc: 0.9606164383561644 Validation Acc: 0.8145973154362416 Train Loss: 0.008470205730465178 Validation Loss: 0.2450927835877076\n",
            "Train Acc: 0.964041095890411 Validation Acc: 0.7105704697986577 Train Loss: 0.007182300494655278 Validation Loss: 0.2817721396734037\n",
            "Train Acc: 0.9726027397260274 Validation Acc: 0.24496644295302014 Train Loss: 0.006738161032282658 Validation Loss: 0.08867248772692524\n",
            "Train Acc: 0.976027397260274 Validation Acc: 0.7550335570469798 Train Loss: 0.0038739682325921085 Validation Loss: 0.5229454045402153\n",
            "Train Acc: 0.9777397260273972 Validation Acc: 0.24496644295302014 Train Loss: 0.003823171743745549 Validation Loss: 0.1444530151171708\n",
            "Train Acc: 0.9554794520547946 Validation Acc: 0.7550335570469798 Train Loss: 0.008344423621079617 Validation Loss: 2.078541758816205\n",
            "Train Acc: 0.9708904109589042 Validation Acc: 0.24496644295302014 Train Loss: 0.006705304227405776 Validation Loss: 0.20829750406234157\n",
            "Train Acc: 0.9743150684931506 Validation Acc: 0.738255033557047 Train Loss: 0.0044695710549442005 Validation Loss: 0.4249397774254033\n",
            "Train Acc: 0.964041095890411 Validation Acc: 0.8045302013422819 Train Loss: 0.015287231307274229 Validation Loss: 0.19466578721914188\n",
            "Train Acc: 0.9691780821917808 Validation Acc: 0.7550335570469798 Train Loss: 0.00496312450688916 Validation Loss: 0.7287778380129747\n",
            "Train Acc: 0.988013698630137 Validation Acc: 0.7239932885906041 Train Loss: 0.002371114457412049 Validation Loss: 0.284778694916579\n",
            "Train Acc: 0.9777397260273972 Validation Acc: 0.24496644295302014 Train Loss: 0.003964302516915143 Validation Loss: 0.21983580452567703\n",
            "Train Acc: 0.4914383561643836 Validation Acc: 0.20385906040268456 Train Loss: 0.08681967613376575 Validation Loss: 0.06648031651581589\n",
            "Train Acc: 0.7397260273972602 Validation Acc: 0.24496644295302014 Train Loss: 0.042133750291923955 Validation Loss: 0.07687023546742766\n",
            "Train Acc: 0.851027397260274 Validation Acc: 0.7550335570469798 Train Loss: 0.02745060758244195 Validation Loss: 0.507569659407376\n",
            "Train Acc: 0.9212328767123288 Validation Acc: 0.7072147651006712 Train Loss: 0.016986653826092626 Validation Loss: 0.19504674328613633\n",
            "Train Acc: 0.8253424657534246 Validation Acc: 0.19463087248322147 Train Loss: 0.031508360512567404 Validation Loss: 0.06865171990112255\n",
            "Train Acc: 0.940068493150685 Validation Acc: 0.7172818791946308 Train Loss: 0.01599667780818928 Validation Loss: 0.08288369286119153\n",
            "Train Acc: 0.976027397260274 Validation Acc: 0.7550335570469798 Train Loss: 0.00537500952466946 Validation Loss: 2.333036262738256\n",
            "Train Acc: 0.9503424657534246 Validation Acc: 0.7550335570469798 Train Loss: 0.009278520690564271 Validation Loss: 1.1238691529433331\n",
            "Train Acc: 0.9417808219178082 Validation Acc: 0.24496644295302014 Train Loss: 0.012729908812317474 Validation Loss: 0.12202432303150233\n",
            "Train Acc: 0.9845890410958904 Validation Acc: 0.7550335570469798 Train Loss: 0.004681355913156924 Validation Loss: 1.222235381374403\n",
            "Train Acc: 0.9315068493150684 Validation Acc: 0.24496644295302014 Train Loss: 0.014101595043727797 Validation Loss: 0.10730020988634542\n",
            "Train Acc: 0.9554794520547946 Validation Acc: 0.7550335570469798 Train Loss: 0.01048294089071545 Validation Loss: 0.2882436028085067\n",
            "Train Acc: 0.9743150684931506 Validation Acc: 0.2348993288590604 Train Loss: 0.006950721887396992 Validation Loss: 0.09715377804087966\n",
            "Train Acc: 0.9708904109589042 Validation Acc: 0.47315436241610737 Train Loss: 0.005137877175500712 Validation Loss: 0.07359643956940425\n",
            "Train Acc: 0.988013698630137 Validation Acc: 0.6174496644295302 Train Loss: 0.0030207854824392637 Validation Loss: 0.08029562627014361\n",
            "Train Acc: 0.988013698630137 Validation Acc: 0.22902684563758388 Train Loss: 0.0017351014792762875 Validation Loss: 0.07689210684283783\n",
            "Train Acc: 0.9863013698630136 Validation Acc: 0.7348993288590604 Train Loss: 0.003885609442446142 Validation Loss: 0.22250607530096253\n",
            "Train Acc: 0.988013698630137 Validation Acc: 0.3263422818791946 Train Loss: 0.002625735082994951 Validation Loss: 0.07016084103011772\n",
            "Train Acc: 0.9126712328767124 Validation Acc: 0.24496644295302014 Train Loss: 0.019013663258292207 Validation Loss: 0.559486049594622\n",
            "Train Acc: 0.9486301369863014 Validation Acc: 0.7550335570469798 Train Loss: 0.010412615270007797 Validation Loss: 0.1801657823196269\n",
            "Train Acc: 0.9863013698630136 Validation Acc: 0.7550335570469798 Train Loss: 0.002910580199481146 Validation Loss: 0.41017750773052714\n",
            "Train Acc: 0.9794520547945206 Validation Acc: 0.6895973154362416 Train Loss: 0.0037619089987059205 Validation Loss: 0.05894548642007928\n",
            "Train Acc: 0.9897260273972602 Validation Acc: 0.785234899328859 Train Loss: 0.002941081672671871 Validation Loss: 0.11227924979175441\n",
            "Train Acc: 0.9811643835616438 Validation Acc: 0.2214765100671141 Train Loss: 0.004495576436514443 Validation Loss: 0.08804920992176783\n",
            "Train Acc: 0.9828767123287672 Validation Acc: 0.7550335570469798 Train Loss: 0.003215040498866049 Validation Loss: 1.4364834566958535\n",
            "Train Acc: 0.6541095890410958 Validation Acc: 0.7550335570469798 Train Loss: 0.06786559559149694 Validation Loss: 1.3224943629544033\n",
            "10 Epoch Restarts: Test Accuracy: 0.49682337992376113 Test Loss: 3.4070577627764327\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ff8d15ecf3647ef892e0fbb7bf1c2e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▂▅▆▆▇▆▆▇▇▆▇▇▇▇▇█▇▇▇▇▇████████▆▆███████▄</td></tr><tr><td>Train Loss</td><td>█▇▆▅▄▃▄▄▂▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▄▄▂▁▁▁▁▂▁█</td></tr><tr><td>Validation Acc</td><td>▂██▂█▂████████▇██████▂▇██▇▂▂█▂█▁██▁▆▃███</td></tr><tr><td>Validation Loss</td><td>▁▅▃▁▁▁▂█▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>0.65411</td></tr><tr><td>Train Loss</td><td>0.06787</td></tr><tr><td>Validation Acc</td><td>0.75503</td></tr><tr><td>Validation Loss</td><td>1.32249</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ReverseProgressive10EpochRestarts</strong> at: <a href='https://wandb.ai/amoseley018/LiverClassifier1/runs/58t3yqk4' target=\"_blank\">https://wandb.ai/amoseley018/LiverClassifier1/runs/58t3yqk4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230306_015649-58t3yqk4/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "gc.collect()\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "startEpoch = 0\n",
        "networkFileName = \"\"\n",
        "fileSaveName = \"/content/drive/MyDrive/ReverseProgressiveLiverClassifier10EpochRestarts\"\n",
        "\n",
        "batchSize = 8\n",
        "#Only use 0.01 with learning rate scheduler\n",
        "learnRate = 0.001\n",
        "epochs = 100\n",
        "startDim = 256\n",
        "epochsToDouble = 25\n",
        "epochsToSave = 10\n",
        "#0: not progressive, 1: progressive, 2: reverse progressive\n",
        "progressive = 2\n",
        "\n",
        "#lossFunc = BalancedCELoss(weight0=1, weight1=1.5)\n",
        "lossFunc = FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n",
        "#lossFunc = nn.BCEWithLogitsLoss()\n",
        "\n",
        "wandb.init(project=\"LiverClassifier1\",\n",
        "           name=\"ReverseProgressive10EpochRestarts\",\n",
        "           config={\n",
        "               \"BatchSize\":batchSize,\n",
        "               \"LearnRate\":learnRate,\n",
        "               \"Epochs\":epochs,\n",
        "               \"StartDimension\":startDim,\n",
        "               \"EpochsToDouble\":epochsToDouble\n",
        "           })\n",
        "\n",
        "#Can reduce number of channels to lessen memory usage\n",
        "block1 = EncoderBlock(1, 16, 1)\n",
        "block2 = EncoderBlock(16, 32, 1)\n",
        "block3 = EncoderBlock(32, 64, 1)\n",
        "block4 = EncoderBlock(64, 128, 1)\n",
        "block5 = EncoderBlock(128, 256, 1)\n",
        "\n",
        "net = nn.Sequential(block1, block2, block3, block4, block5, nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(256, 1), nn.Sigmoid())\n",
        "#print(summary(net, (1, 256, 256)))\n",
        "\n",
        "if networkFileName != \"\":\n",
        "    net.load_state_dict(torch.load(networkFileName))\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "print(\"Intialized model\")\n",
        "\n",
        "trainDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/PartialTrainDataset.hdf5\")\n",
        "validationDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/ValidationDataset.hdf5\")\n",
        "testDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/TestDataset.hdf5\")\n",
        "\n",
        "print(\"Dataset loaded\")\n",
        "\n",
        "trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "validationIter = DataLoader(validationDataset, batch_size=batchSize)\n",
        "testIter = DataLoader(testDataset, batch_size=batchSize)\n",
        "\n",
        "train(net, trainIter, validationIter, epochs, startEpoch, learnRate, batchSize, device, startDim, epochsToDouble, fileSaveName, epochsToSave, cosineAnnealing=False, progressive=progressive, lossFunc=lossFunc)\n",
        "\n",
        "testAcc, testLoss = evaluate_accuracy(net, testIter, lossFunc, device=device)\n",
        "print(f\"10 Epoch Restarts: Test Accuracy: {testAcc} Test Loss: {testLoss}\")\n",
        "\n",
        "trainDataset.closeFile()\n",
        "validationDataset.closeFile()\n",
        "testDataset.closeFile()\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ea23a5d6ea5dd6b47a6bacc48f8acbc6e91dc182fa6b25270d70228f0691131c"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ff8d15ecf3647ef892e0fbb7bf1c2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_773fcf88a2ea44cbaafc1c653f209088",
              "IPY_MODEL_15e864464408494181f05c4e2a67c170"
            ],
            "layout": "IPY_MODEL_482e5a20616d4573aef6d8912c543e30",
            "tabbable": null,
            "tooltip": null
          }
        },
        "773fcf88a2ea44cbaafc1c653f209088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "LabelView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_aa0fab273f2545d0b709dd4f6872f717",
            "placeholder": "​",
            "style": "IPY_MODEL_9247072928184d50898f37dc3b0b7f7d",
            "tabbable": null,
            "tooltip": null,
            "value": "0.022 MB of 0.022 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "15e864464408494181f05c4e2a67c170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e440f01eb5824c1c87566ab3a38faf0f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_376c3f18b7d043719da8814eadbe6999",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "482e5a20616d4573aef6d8912c543e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa0fab273f2545d0b709dd4f6872f717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9247072928184d50898f37dc3b0b7f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "LabelStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "e440f01eb5824c1c87566ab3a38faf0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "376c3f18b7d043719da8814eadbe6999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}