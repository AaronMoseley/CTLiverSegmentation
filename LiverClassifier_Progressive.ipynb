{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!pip install torch torchvision\n",
        "!pip install d2l==1.0.0b0\n",
        "!conda install -c conda-forge torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y_BxamkKyQSd",
        "outputId": "f79aa177-1676-4724-ced7-57e6b3496ac1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:35\n",
            "🔁 Restarting kernel...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch\n",
            "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.14.1-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from torchvision) (2.28.1)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (1.26.13)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (2.1.1)\n",
            "Installing collected packages: typing-extensions, pillow, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, nvidia-cudnn-cu11, torch, torchvision\n",
            "Successfully installed numpy-1.24.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pillow-9.4.0 torch-1.13.1 torchvision-0.14.1 typing-extensions-4.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l==1.0.0b0\n",
            "  Downloading d2l-1.0.0b0-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from d2l==1.0.0b0) (2.28.1)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from d2l==1.0.0b0) (1.24.2)\n",
            "Collecting gym==0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.9.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle>=1.2.0\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting linear-operator>=0.2.0\n",
            "  Downloading linear_operator-0.3.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m570.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting notebook\n",
            "  Downloading notebook-6.5.2-py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.1/439.1 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipykernel\n",
            "  Downloading ipykernel-6.21.2-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbconvert\n",
            "  Downloading nbconvert-7.2.9-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-console\n",
            "  Downloading jupyter_console-6.5.1-py3-none-any.whl (23 kB)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.8/137.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources>=3.2.0\n",
            "  Downloading importlib_resources-5.10.2-py3-none-any.whl (34 kB)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->d2l==1.0.0b0) (9.4.0)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->d2l==1.0.0b0) (3.4)\n",
            "Collecting zipp>=3.1.0\n",
            "  Downloading zipp-3.13.0-py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/site-packages (from linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (1.13.1)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-8.0.2-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting comm>=0.1.1\n",
            "  Downloading comm-0.1.2-py3-none-any.whl (6.5 kB)\n",
            "Collecting ipython>=7.23.1\n",
            "  Downloading ipython-8.10.0-py3-none-any.whl (784 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m784.3/784.3 kB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12\n",
            "  Downloading jupyter_core-5.2.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.3/94.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy>=1.6.5\n",
            "  Downloading debugpy-1.6.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting tornado>=6.1\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq>=20\n",
            "  Downloading pyzmq-25.0.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-widgets~=3.0\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting widgetsnbextension~=4.0\n",
            "  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit>=3.0.30\n",
            "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbclient>=0.5.0\n",
            "  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markupsafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mistune<3,>=2.0.3\n",
            "  Downloading mistune-2.0.5-py2.py3-none-any.whl (24 kB)\n",
            "Collecting nbformat>=5.1\n",
            "  Downloading nbformat-5.7.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.1/78.1 kB\u001b[0m \u001b[31m403.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata>=3.6\n",
            "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting bleach\n",
            "  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.5/162.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tinycss2\n",
            "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
            "Collecting jupyterlab-pygments\n",
            "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting pandocfilters>=1.4.1\n",
            "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting defusedxml\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting terminado>=0.8.3\n",
            "  Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\n",
            "Collecting prometheus-client\n",
            "  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbclassic>=0.4.7\n",
            "  Downloading nbclassic-0.5.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting argon2-cffi\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Collecting Send2Trash>=1.8.0\n",
            "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs>=2.5\n",
            "  Downloading platformdirs-3.0.0-py3-none-any.whl (14 kB)\n",
            "Collecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
            "Collecting jupyter-server>=1.8\n",
            "  Downloading jupyter_server-2.2.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema>=2.6\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastjsonschema\n",
            "  Downloading fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting ptyprocess\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (4.4.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (65.5.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->linear-operator>=0.2.0->gpytorch->d2l==1.0.0b0) (0.38.4)\n",
            "Collecting argon2-cffi-bindings\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=17.4.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Collecting anyio>=3.1.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-server-terminals\n",
            "  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
            "Collecting jupyter-events>=0.4.0\n",
            "  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (1.15.1)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (2.21)\n",
            "Collecting python-json-logger>=2.0.4\n",
            "  Downloading python_json_logger-2.0.5-py3-none-any.whl (7.8 kB)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting pyyaml>=5.3\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986-validator>=0.1.1\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616798 sha256=5a9bd77316133eacc88aafbf519b14d51b9744ff567f7f04bf6cc957ff61eff2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/2e/15/b9642e5913560f946cf8b27f8654e095437c17cada3d5b809e\n",
            "Successfully built gym\n",
            "Installing collected packages: webencodings, wcwidth, Send2Trash, pytz, pure-eval, ptyprocess, pickleshare, mistune, ipython-genutils, fastjsonschema, executing, backcall, zipp, widgetsnbextension, websocket-client, webcolors, uri-template, traitlets, tornado, tinycss2, threadpoolctl, soupsieve, sniffio, six, scipy, rfc3986-validator, pyzmq, pyyaml, python-json-logger, pyrsistent, pyparsing, pygments, psutil, prompt-toolkit, prometheus-client, platformdirs, pkgutil-resolve-name, pexpect, parso, pandocfilters, packaging, nest-asyncio, markupsafe, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, joblib, fqdn, fonttools, defusedxml, decorator, debugpy, cycler, contourpy, cloudpickle, attrs, terminado, scikit-learn, rfc3339-validator, qtpy, python-dateutil, matplotlib-inline, jupyter-core, jinja2, jedi, importlib-resources, importlib-metadata, gym, comm, bleach, beautifulsoup4, asttokens, argon2-cffi-bindings, anyio, stack-data, pandas, matplotlib, jupyter-server-terminals, jupyter-client, jsonschema, arrow, argon2-cffi, nbformat, linear-operator, isoduration, ipython, nbclient, ipykernel, gpytorch, qtconsole, nbconvert, jupyter-events, jupyter-console, ipywidgets, jupyter-server, notebook-shim, nbclassic, notebook, jupyter, d2l\n",
            "Successfully installed Send2Trash-1.8.0 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 asttokens-2.2.1 attrs-22.2.0 backcall-0.2.0 beautifulsoup4-4.11.2 bleach-6.0.0 cloudpickle-2.2.1 comm-0.1.2 contourpy-1.0.7 cycler-0.11.0 d2l-1.0.0b0 debugpy-1.6.6 decorator-5.1.1 defusedxml-0.7.1 executing-1.2.0 fastjsonschema-2.16.2 fonttools-4.38.0 fqdn-1.5.1 gpytorch-1.9.1 gym-0.21.0 importlib-metadata-6.0.0 importlib-resources-5.10.2 ipykernel-6.21.2 ipython-8.10.0 ipython-genutils-0.2.0 ipywidgets-8.0.4 isoduration-20.11.0 jedi-0.18.2 jinja2-3.1.2 joblib-1.2.0 jsonpointer-2.3 jsonschema-4.17.3 jupyter-1.0.0 jupyter-client-8.0.2 jupyter-console-6.5.1 jupyter-core-5.2.0 jupyter-events-0.6.3 jupyter-server-2.2.1 jupyter-server-terminals-0.4.4 jupyterlab-pygments-0.2.2 jupyterlab-widgets-3.0.5 kiwisolver-1.4.4 linear-operator-0.3.0 markupsafe-2.1.2 matplotlib-3.7.0 matplotlib-inline-0.1.6 mistune-2.0.5 nbclassic-0.5.1 nbclient-0.7.2 nbconvert-7.2.9 nbformat-5.7.3 nest-asyncio-1.5.6 notebook-6.5.2 notebook-shim-0.2.2 packaging-23.0 pandas-1.5.3 pandocfilters-1.5.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pkgutil-resolve-name-1.3.10 platformdirs-3.0.0 prometheus-client-0.16.0 prompt-toolkit-3.0.36 psutil-5.9.4 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.14.0 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 python-json-logger-2.0.5 pytz-2022.7.1 pyyaml-6.0 pyzmq-25.0.0 qtconsole-5.4.0 qtpy-2.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 scikit-learn-1.2.1 scipy-1.10.0 six-1.16.0 sniffio-1.3.0 soupsieve-2.3.2.post1 stack-data-0.6.2 terminado-0.17.1 threadpoolctl-3.1.0 tinycss2-1.2.1 tornado-6.2 traitlets-5.9.0 uri-template-1.2.0 wcwidth-0.2.6 webcolors-1.12 webencodings-0.5.1 websocket-client-1.5.1 widgetsnbextension-4.0.5 zipp-3.13.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "ipython_genutils",
                  "kiwisolver",
                  "pexpect",
                  "pickleshare",
                  "wcwidth",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - torchmetrics\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       2_kmp_llvm           6 KB  conda-forge\n",
            "    ca-certificates-2022.12.7  |       ha878542_0         143 KB  conda-forge\n",
            "    certifi-2022.12.7          |     pyhd8ed1ab_0         147 KB  conda-forge\n",
            "    colorama-0.4.6             |     pyhd8ed1ab_0          25 KB  conda-forge\n",
            "    conda-22.11.1              |   py38h578d9bd_1         905 KB  conda-forge\n",
            "    cudatoolkit-11.6.0         |      hecad31d_11       542.1 MB  conda-forge\n",
            "    cudnn-8.4.1.50             |       hed8a83a_0       618.4 MB  conda-forge\n",
            "    libblas-3.9.0              |16_linux64_openblas          13 KB  conda-forge\n",
            "    libcblas-3.9.0             |16_linux64_openblas          13 KB  conda-forge\n",
            "    libgfortran-ng-12.2.0      |      h69a702a_19          22 KB  conda-forge\n",
            "    libgfortran5-12.2.0        |      h337968e_19         1.8 MB  conda-forge\n",
            "    libhwloc-2.8.0             |       h32351e8_1         3.0 MB  conda-forge\n",
            "    liblapack-3.9.0            |16_linux64_openblas          13 KB  conda-forge\n",
            "    libopenblas-0.3.21         |pthreads_h78a6416_3        10.1 MB  conda-forge\n",
            "    libprotobuf-3.21.12        |       h3eb15da_0         2.1 MB  conda-forge\n",
            "    llvm-openmp-15.0.7         |       h0cdce71_0         3.1 MB  conda-forge\n",
            "    magma-2.6.2                |       hc72dce7_0       231.5 MB  conda-forge\n",
            "    mkl-2022.2.1               |   h84fe81f_16997       157.3 MB  conda-forge\n",
            "    nccl-2.14.3.1              |       h0800d71_0       145.2 MB  conda-forge\n",
            "    ninja-1.11.0               |       h924138e_0         2.8 MB  conda-forge\n",
            "    numpy-1.24.2               |   py38h10c12cc_0         6.3 MB  conda-forge\n",
            "    openssl-3.0.8              |       h0b41bf4_0         2.5 MB  conda-forge\n",
            "    packaging-23.0             |     pyhd8ed1ab_0          40 KB  conda-forge\n",
            "    pluggy-1.0.0               |     pyhd8ed1ab_5          16 KB  conda-forge\n",
            "    pytorch-1.13.1             |cuda112py38hd94e077_200       362.3 MB  conda-forge\n",
            "    ruamel.yaml-0.17.21        |   py38h0a891b7_2         172 KB  conda-forge\n",
            "    ruamel.yaml.clib-0.2.7     |   py38h1de0b5d_1         143 KB  conda-forge\n",
            "    sleef-3.5.1                |       h9b69904_2         1.5 MB  conda-forge\n",
            "    tbb-2021.7.0               |       h924138e_1         1.5 MB  conda-forge\n",
            "    torchmetrics-0.11.1        |     pyhd8ed1ab_0         213 KB  conda-forge\n",
            "    tqdm-4.64.1                |     pyhd8ed1ab_0          82 KB  conda-forge\n",
            "    typing_extensions-4.4.0    |     pyha770c72_0          29 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        2.04 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 None\n",
            "  cudatoolkit        conda-forge/linux-64::cudatoolkit-11.6.0-hecad31d_11 None\n",
            "  cudnn              conda-forge/linux-64::cudnn-8.4.1.50-hed8a83a_0 None\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_openblas None\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_openblas None\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19 None\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19 None\n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.8.0-h32351e8_1 None\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_openblas None\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.21-pthreads_h78a6416_3 None\n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-3.21.12-h3eb15da_0 None\n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.7-h0cdce71_0 None\n",
            "  magma              conda-forge/linux-64::magma-2.6.2-hc72dce7_0 None\n",
            "  mkl                conda-forge/linux-64::mkl-2022.2.1-h84fe81f_16997 None\n",
            "  nccl               conda-forge/linux-64::nccl-2.14.3.1-h0800d71_0 None\n",
            "  ninja              conda-forge/linux-64::ninja-1.11.0-h924138e_0 None\n",
            "  numpy              conda-forge/linux-64::numpy-1.24.2-py38h10c12cc_0 None\n",
            "  packaging          conda-forge/noarch::packaging-23.0-pyhd8ed1ab_0 None\n",
            "  pluggy             conda-forge/noarch::pluggy-1.0.0-pyhd8ed1ab_5 None\n",
            "  pytorch            conda-forge/linux-64::pytorch-1.13.1-cuda112py38hd94e077_200 None\n",
            "  ruamel.yaml        conda-forge/linux-64::ruamel.yaml-0.17.21-py38h0a891b7_2 None\n",
            "  ruamel.yaml.clib   conda-forge/linux-64::ruamel.yaml.clib-0.2.7-py38h1de0b5d_1 None\n",
            "  sleef              conda-forge/linux-64::sleef-3.5.1-h9b69904_2 None\n",
            "  tbb                conda-forge/linux-64::tbb-2021.7.0-h924138e_1 None\n",
            "  torchmetrics       conda-forge/noarch::torchmetrics-0.11.1-pyhd8ed1ab_0 None\n",
            "  tqdm               conda-forge/noarch::tqdm-4.64.1-pyhd8ed1ab_0 None\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0 None\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2022.9.24-ha878542_0 --> 2022.12.7-ha878542_0 None\n",
            "  certifi                            2022.9.24-pyhd8ed1ab_0 --> 2022.12.7-pyhd8ed1ab_0 None\n",
            "  conda                               22.9.0-py38h578d9bd_2 --> 22.11.1-py38h578d9bd_1 None\n",
            "  openssl                                  3.0.7-h0b41bf4_1 --> 3.0.8-h0b41bf4_0 None\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-2_kmp_llvm None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "sleef-3.5.1          | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.86it/s]\n",
            "mkl-2022.2.1         | 157.3 MB  | : 100% 1.0/1 [00:05<00:00,  5.15s/it]               \n",
            "torchmetrics-0.11.1  | 213 KB    | : 100% 1.0/1 [00:00<00:00,  7.11it/s]\n",
            "numpy-1.24.2         | 6.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.11it/s]\n",
            "ruamel.yaml-0.17.21  | 172 KB    | : 100% 1.0/1 [00:00<00:00,  9.94it/s]\n",
            "libgfortran5-12.2.0  | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.42it/s]\n",
            "ruamel.yaml.clib-0.2 | 143 KB    | : 100% 1.0/1 [00:00<00:00, 22.92it/s]\n",
            "ca-certificates-2022 | 143 KB    | : 100% 1.0/1 [00:00<00:00, 27.13it/s]\n",
            "libcblas-3.9.0       | 13 KB     | : 100% 1.0/1 [00:00<00:00, 12.36it/s]\n",
            "libhwloc-2.8.0       | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.59it/s]\n",
            "cudnn-8.4.1.50       | 618.4 MB  | : 100% 1.0/1 [01:27<00:00, 87.39s/it]               \n",
            "libopenblas-0.3.21   | 10.1 MB   | : 100% 1.0/1 [00:02<00:00,  2.33s/it]\n",
            "libgfortran-ng-12.2. | 22 KB     | : 100% 1.0/1 [00:00<00:00, 21.41it/s]\n",
            "certifi-2022.12.7    | 147 KB    | : 100% 1.0/1 [00:00<00:00, 24.86it/s]\n",
            "ninja-1.11.0         | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.67it/s]\n",
            "pluggy-1.0.0         | 16 KB     | : 100% 1.0/1 [00:00<00:00, 26.50it/s]\n",
            "llvm-openmp-15.0.7   | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  6.78it/s]\n",
            "typing_extensions-4. | 29 KB     | : 100% 1.0/1 [00:00<00:00, 26.31it/s]\n",
            "pytorch-1.13.1       | 362.3 MB  | : 100% 1.0/1 [00:11<00:00, 11.57s/it]               \n",
            "libprotobuf-3.21.12  | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  6.73it/s]\n",
            "openssl-3.0.8        | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  8.03it/s]\n",
            "tqdm-4.64.1          | 82 KB     | : 100% 1.0/1 [00:00<00:00, 17.41it/s]\n",
            "liblapack-3.9.0      | 13 KB     | : 100% 1.0/1 [00:00<00:00, 29.72it/s]\n",
            "nccl-2.14.3.1        | 145.2 MB  | : 100% 1.0/1 [00:19<00:00, 19.65s/it]               \n",
            "packaging-23.0       | 40 KB     | : 100% 1.0/1 [00:00<00:00, 19.87it/s]\n",
            "cudatoolkit-11.6.0   | 542.1 MB  | : 100% 1.0/1 [00:14<00:00, 14.52s/it]               \n",
            "conda-22.11.1        | 905 KB    | : 100% 1.0/1 [00:00<00:00,  4.93it/s]\n",
            "tbb-2021.7.0         | 1.5 MB    | : 100% 1.0/1 [00:00<00:00, 15.38it/s]\n",
            "_openmp_mutex-4.5    | 6 KB      | : 100% 1.0/1 [00:00<00:00, 33.75it/s]\n",
            "magma-2.6.2          | 231.5 MB  | : 100% 1.0/1 [00:29<00:00, 29.96s/it]              \n",
            "libblas-3.9.0        | 13 KB     | : 100% 1.0/1 [00:00<00:00, 21.51it/s]\n",
            "colorama-0.4.6       | 25 KB     | : 100% 1.0/1 [00:00<00:00, 24.68it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
            "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
            "\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbV9155tKF7w",
        "outputId": "d46be9f7-d144-456a-83cf-71705e8315e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamoseley018\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl9Rf7gIC-Lb",
        "outputId": "4d47b242-a88f-4155-d7cc-e136581f8360"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UySZvCsHhycT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2279637-55ff-4031-85d4-60fcf4b0a00b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import Optional, Sequence\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torchsummary import summary\n",
        "from d2l import torch as d2l\n",
        "from pathlib import Path\n",
        "from torchmetrics.classification import BinaryF1Score\n",
        "import sys\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import gc\n",
        "import skimage\n",
        "import h5py\n",
        "import math\n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    '''\n",
        "    Multi-class Focal Loss\n",
        "    '''\n",
        "    def __init__(self, gamma=2, weight=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "\n",
        "        if weight == None:\n",
        "            self.weight = [1, 1]\n",
        "        else:\n",
        "            self.weight = weight\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        \"\"\"\n",
        "        input: [N, C], float32\n",
        "        target: [N, ], int64\n",
        "        \"\"\"\n",
        "        logpt = F.log_softmax(input, dim=0)\n",
        "        pt = torch.exp(logpt)\n",
        "        logpt = (1-pt)**self.gamma * logpt\n",
        "        loss = F.nll_loss(logpt, target, self.weight)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "vBBsw05Qw7DO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BalancedCELoss(nn.Module):\n",
        "    def __init__(self, weight=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        loss = 0\n",
        "        for i, el in enumerate(input):\n",
        "            loss += (target[i] * torch.log(el) * self.weight) + ((1 - target[i]) * torch.log(1 - el) * (1 - self.weight))\n",
        "\n",
        "        return -1 * loss / len(input)"
      ],
      "metadata": {
        "id": "IsZV06GU0ue3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LITSBinaryDataset(Dataset):\n",
        "    def __init__(self, fileName):\n",
        "        super().__init__()\n",
        "\n",
        "        self.file = h5py.File(fileName, 'r')\n",
        "\n",
        "        self.length = 0\n",
        "\n",
        "        for scan in list(self.file.keys()):\n",
        "            self.length += len(list(self.file[scan].keys()))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scanNum = 0\n",
        "        currInd = 0\n",
        "        scan = list(self.file.keys())[0]\n",
        "        while currInd + len(list(self.file[scan].keys())) <= idx:\n",
        "            currInd += len(list(self.file[scan].keys()))\n",
        "            scanNum += 1\n",
        "            scan = list(self.file.keys())[scanNum]\n",
        "\n",
        "        sliceNum = idx - currInd\n",
        "\n",
        "        data = self.file[list(self.file.keys())[scanNum]][\"Slice\" + str(sliceNum)][\"Slice\"]\n",
        "        label = self.file[list(self.file.keys())[scanNum]][\"Slice\" + str(sliceNum)].attrs.get(\"ImageLabel\")\n",
        "\n",
        "        result = []\n",
        "\n",
        "        result.append(torch.Tensor(data[...]).unsqueeze(0))\n",
        "        result.append(torch.Tensor(label).squeeze(0))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def closeFile(self):\n",
        "        self.file.close()"
      ],
      "metadata": {
        "id": "8iO7WioSr-Yk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9-kqO-PVhycU"
      },
      "outputs": [],
      "source": [
        "class convBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, batchNorm, strides, layerMean, layerDev) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inChannels, outChannels, kernel_size=3, padding=1, stride=strides)\n",
        "        self.conv2 = nn.Conv2d(outChannels, outChannels, kernel_size=3, padding=1)\n",
        "\n",
        "        nn.init.normal_(self.conv1.weight, mean=layerMean, std=layerDev)\n",
        "        nn.init.normal_(self.conv2.weight, mean=layerMean, std=layerDev)\n",
        "\n",
        "        if(batchNorm):\n",
        "            self.bn1 = nn.BatchNorm2d(outChannels)\n",
        "        else:\n",
        "            self.bn1 = False\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.conv1(X)\n",
        "\n",
        "        if(self.bn1):\n",
        "            Y = self.bn1(Y)\n",
        "\n",
        "        Y = F.relu(Y)\n",
        "\n",
        "        return torch.Tensor(F.relu(self.conv2(Y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q0sgeg3EhycU"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, strides) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = convBlock(inChannels, outChannels, True, strides, 0, 0.01)\n",
        "        self.pool = nn.MaxPool2d(2, stride=strides)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        Y = self.conv.forward(X)\n",
        "\n",
        "        #return torch.Tensor(self.pool(Y)), Y\n",
        "        return self.pool(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_rhGtpfGhycV"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels, strides) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.convTrans = nn.ConvTranspose2d(inChannels, outChannels, 2, stride=strides, padding=1)\n",
        "        self.conv = convBlock(outChannels, outChannels, True, strides, 0, 0.25)\n",
        "\n",
        "    def forward(self, X, skipFeatures):\n",
        "        Y = self.convTrans(X)\n",
        "        Y = torch.cat(X, skipFeatures)\n",
        "        return self.conv(Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(net, testIter, device=None):\n",
        "    if isinstance(net, nn.Module):\n",
        "        net.eval()\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "\n",
        "    metric = d2l.Accumulator(2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in testIter:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            metric.add(d2l.accuracy(torch.round(torch.clamp(net(X).squeeze(1), min=0, max=1)), y), y.numel())\n",
        "\n",
        "    return metric[0] / metric[1]"
      ],
      "metadata": {
        "id": "98eUKvAr2KPz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7ZgVGj5whycV"
      },
      "outputs": [],
      "source": [
        "def train(net: nn.Sequential, trainIter, testIter, numEpochs, startEpoch, learnRate, batchSize, device: torch.device, startDim, epochsToDouble, modelFileName, lossFunc = nn.BCEWithLogitsLoss()):\n",
        "    print(f\"Training on {device}\")\n",
        "    \n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=learnRate)\n",
        "    numBatches = len(trainIter)\n",
        "\n",
        "    anim1 = d2l.Animator(xlabel=\"Epoch\", xlim=[0, numEpochs - 1], legend=[\"Train Accuracy\", \"Test Accuracy\"])\n",
        "    anim2 = d2l.Animator(xlabel=\"Epoch\", xlim=[0, numEpochs - 1], legend=[\"Loss\"])\n",
        "\n",
        "    imageFunc = transforms.ToPILImage()\n",
        "    tensorFunc = transforms.ToTensor()\n",
        "\n",
        "    currDim = startDim\n",
        "    for epoch in range(startEpoch, numEpochs):\n",
        "        if epoch != 0 and epoch % epochsToDouble == 0:\n",
        "            currDim *= 2\n",
        "        \n",
        "        net.train()\n",
        "        metric = d2l.Accumulator(2)\n",
        "\n",
        "        for i, (X, y) in enumerate(trainIter):\n",
        "            optimizer.zero_grad()\n",
        "            y = y.to(device)\n",
        "\n",
        "            realX = []\n",
        "\n",
        "            for slice in X:\n",
        "                slice = imageFunc(slice.squeeze(0)).resize((currDim, currDim), PIL.Image.BILINEAR)\n",
        "                slice = tensorFunc(slice).to(device)\n",
        "                realX.append(slice)\n",
        "\n",
        "            realX = torch.stack(realX).to(device)\n",
        "\n",
        "            yhat = torch.sigmoid(net(realX)).squeeze(1)\n",
        "\n",
        "            prediction = torch.round(torch.clamp(yhat, min=0, max=1)).to(device)\n",
        "\n",
        "            l = lossFunc(yhat, y.long())\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            metric.add(l, d2l.accuracy(prediction, y) / batchSize)\n",
        "\n",
        "        torch.save(net.state_dict(), modelFileName + \"Epoch\" + str(epoch))\n",
        "\n",
        "        testAcc = evaluate_accuracy(net, testIter, device)\n",
        "\n",
        "        #print(f\"Train Acc: {metric[1] / (numBatches * batchSize)} Test Acc: {testAcc} Loss: {metric[0] / (numBatches * batchSize)}\")\n",
        "\n",
        "        wandb.log({\"Train Acc\": metric[1] / (numBatches * batchSize),\n",
        "                   \"Test Acc\": testAcc,\n",
        "                   \"Loss\": (metric[0] / (numBatches * batchSize))\n",
        "                  })\n",
        "        anim1.add(epoch, ((metric[1] / (numBatches * batchSize)), testAcc))\n",
        "        anim2.add(epoch, (metric[0] / (numBatches * batchSize)))\n",
        "        #print(f\"Loss: {sumLoss / numBatches} Accuracy: {sumAcc / (numBatches * batchSize)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YVz5cMohycW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "f91c55ab-3f8d-4f45-bacb-cf64422aa988"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230214_032410-349vr05a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amoseley018/LiverClassifier/runs/349vr05a' target=\"_blank\">Run2</a></strong> to <a href='https://wandb.ai/amoseley018/LiverClassifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/amoseley018/LiverClassifier' target=\"_blank\">https://wandb.ai/amoseley018/LiverClassifier</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/amoseley018/LiverClassifier/runs/349vr05a' target=\"_blank\">https://wandb.ai/amoseley018/LiverClassifier/runs/349vr05a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intialized model\n",
            "Dataset loaded\n",
            "Training on cuda\n"
          ]
        }
      ],
      "source": [
        "gc.collect()\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "startEpoch = 0\n",
        "networkFileName = \"\"\n",
        "fileSaveName = \"/content/drive/MyDrive/LiverClassifierModelRun1\"\n",
        "\n",
        "batchSize = 3\n",
        "learnRate = 0.00001\n",
        "epochs = 100\n",
        "startDim = 32\n",
        "epochsToDouble = 25\n",
        "\n",
        "lossFunc = BalancedCELoss(weight=0.7)\n",
        "\n",
        "wandb.init(project=\"LiverClassifier\",\n",
        "           name=\"Run2\",\n",
        "           config={\n",
        "               \"BatchSize\":batchSize,\n",
        "               \"LearnRate\":learnRate,\n",
        "               \"Epochs\":epochs,\n",
        "               \"StartDimension\":startDim,\n",
        "               \"EpochsToDouble\":epochsToDouble\n",
        "           })\n",
        "\n",
        "block1 = EncoderBlock(1, 64, 1)\n",
        "block2 = EncoderBlock(64, 128, 1)\n",
        "block3 = EncoderBlock(128, 256, 1)\n",
        "block4 = EncoderBlock(256, 512, 1)\n",
        "block5 = EncoderBlock(512, 1024, 1)\n",
        "\n",
        "net = nn.Sequential(block1, block2, block3, block4, nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(512, 1))\n",
        "#print(summary(net, (1, 512, 512)))\n",
        "\n",
        "if networkFileName != \"\":\n",
        "    net.load_state_dict(torch.load(networkFileName))\n",
        "\n",
        "print(\"Intialized model\")\n",
        "\n",
        "trainDataset = LITSBinaryDataset(\"drive/MyDrive/TrainDataset.hdf5\")\n",
        "testDataset = LITSBinaryDataset(\"drive/MyDrive/TestDataset.hdf5\")\n",
        "\n",
        "print(\"Dataset loaded\")\n",
        "\n",
        "trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "testIter = DataLoader(testDataset, batch_size=batchSize)\n",
        "\n",
        "train(net, trainIter, testIter, epochs, startEpoch, learnRate, batchSize, device, startDim, epochsToDouble, fileSaveName, lossFunc=lossFunc)\n",
        "\n",
        "trainDataset.closeFile()\n",
        "testDataset.closeFile()\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ea23a5d6ea5dd6b47a6bacc48f8acbc6e91dc182fa6b25270d70228f0691131c"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}