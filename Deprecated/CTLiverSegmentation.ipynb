{"cells":[{"cell_type":"markdown","source":["# **Imports/Installs**"],"metadata":{"id":"yYxz4-bYq-nb"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"y_BxamkKyQSd","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1684379621084,"user_tz":240,"elapsed":199922,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}},"outputId":"916e98ce-72ac-4d3e-96af-37492e5c8004"},"outputs":[{"output_type":"stream","name":"stdout","text":["⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n","📦 Installing...\n","📌 Adjusting configuration...\n","🩹 Patching environment...\n","⏲ Done in 0:00:15\n","🔁 Restarting kernel...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting networkx\n","  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting filelock\n","  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jinja2\n","  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==2.0.0\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sympy\n","  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n","Collecting cmake\n","  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lit\n","  Downloading lit-16.0.5.tar.gz (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting MarkupSafe>=2.0\n","  Downloading MarkupSafe-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Collecting mpmath>=0.19\n","  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: lit\n","  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-16.0.5-py3-none-any.whl size=88175 sha256=070de4edc4621b1e8df7136b173174bc1ffeb53921639eca924fbfce5fbf40d6\n","  Stored in directory: /root/.cache/pip/wheels/eb/02/84/d82f0b1a6098209edf7e3607be6cc592ebbc015a8a3127c68d\n","Successfully built lit\n","Installing collected packages: mpmath, lit, cmake, typing-extensions, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, MarkupSafe, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, triton, torch\n","Successfully installed MarkupSafe-2.1.2 cmake-3.26.3 filelock-3.12.0 jinja2-3.1.2 lit-16.0.5 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0 typing-extensions-4.5.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchvision\n","  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy\n","  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/site-packages (from torchvision) (2.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from torchvision) (2.28.2)\n","Collecting pillow!=8.3.*,>=5.3.0\n","  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (10.9.0.58)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (4.5.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.14.3)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.4.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.12.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (1.12)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.4.91)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (8.5.0.96)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.101)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.10.3.66)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (10.2.10.91)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.91)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (0.40.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (65.6.3)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.26.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n","Installing collected packages: pillow, numpy, torchvision\n","Successfully installed numpy-1.24.3 pillow-9.5.0 torchvision-0.15.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting d2l==1.0.0b0\n","  Downloading d2l-1.0.0b0-py3-none-any.whl (141 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from d2l==1.0.0b0) (1.24.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from d2l==1.0.0b0) (2.28.2)\n","Collecting jupyter\n","  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n","Collecting matplotlib-inline\n","  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n","Collecting matplotlib\n","  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy\n","  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gpytorch\n","  Downloading gpytorch-1.10-py3-none-any.whl (255 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandas\n","  Downloading pandas-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gym==0.21.0\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting cloudpickle>=1.2.0\n","  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n","Collecting linear-operator>=0.4.0\n","  Downloading linear_operator-0.4.0-py3-none-any.whl (156 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.7/156.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn\n","  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nbconvert\n","  Downloading nbconvert-7.4.0-py3-none-any.whl (285 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.9/285.9 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting qtconsole\n","  Downloading qtconsole-5.4.3-py3-none-any.whl (121 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipykernel\n","  Downloading ipykernel-6.23.1-py3-none-any.whl (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.2/152.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipywidgets\n","  Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyter-console\n","  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n","Collecting notebook\n","  Downloading notebook-6.5.4-py3-none-any.whl (529 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.8/529.8 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fonttools>=4.22.0\n","  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler>=0.10\n","  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->d2l==1.0.0b0) (9.5.0)\n","Collecting pyparsing>=2.3.1\n","  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kiwisolver>=1.0.1\n","  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting packaging>=20.0\n","  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting contourpy>=1.0.1\n","  Downloading contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dateutil>=2.7\n","  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting traitlets\n","  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytz>=2020.1\n","  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tzdata>=2022.1\n","  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->d2l==1.0.0b0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->d2l==1.0.0b0) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->d2l==1.0.0b0) (1.26.15)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->d2l==1.0.0b0) (3.1.0)\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/site-packages (from linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (2.0.1)\n","Collecting six>=1.5\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting jupyter-core!=5.0.*,>=4.12\n","  Downloading jupyter_core-5.3.0-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting comm>=0.1.1\n","  Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n","Collecting jupyter-client>=6.1.12\n","  Downloading jupyter_client-8.2.0-py3-none-any.whl (103 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipython>=7.23.1\n","  Downloading ipython-8.13.2-py3-none-any.whl (797 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.7/797.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nest-asyncio\n","  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n","Collecting psutil\n","  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tornado>=6.1\n","  Downloading tornado-6.3.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.9/426.9 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting debugpy>=1.6.5\n","  Downloading debugpy-1.6.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyzmq>=20\n","  Downloading pyzmq-25.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting widgetsnbextension~=4.0.7\n","  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyterlab-widgets~=3.0.7\n","  Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.2/198.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting prompt-toolkit>=3.0.30\n","  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygments\n","  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandocfilters>=1.4.1\n","  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n","Collecting beautifulsoup4\n","  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tinycss2\n","  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n","Collecting nbclient>=0.5.0\n","  Downloading nbclient-0.7.4-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nbformat>=5.1\n","  Downloading nbformat-5.8.0-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyterlab-pygments\n","  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n","Collecting mistune<3,>=2.0.3\n","  Downloading mistune-2.0.5-py2.py3-none-any.whl (24 kB)\n","Collecting defusedxml\n","  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0b0) (3.1.2)\n","Collecting bleach\n","  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.5/162.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter->d2l==1.0.0b0) (2.1.2)\n","Collecting nbclassic>=0.4.7\n","  Downloading nbclassic-1.0.0-py3-none-any.whl (10.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting terminado>=0.8.3\n","  Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\n","Collecting prometheus-client\n","  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipython-genutils\n","  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n","Collecting argon2-cffi\n","  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n","Collecting Send2Trash>=1.8.0\n","  Downloading Send2Trash-1.8.2-py3-none-any.whl (18 kB)\n","Collecting qtpy>=2.0.1\n","  Downloading QtPy-2.3.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting joblib>=1.1.1\n","  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","Collecting stack-data\n","  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n","Collecting backcall\n","  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n","Collecting decorator\n","  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n","Collecting pickleshare\n","  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n","Collecting jedi>=0.16\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pexpect>4.3\n","  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting platformdirs>=2.5\n","  Downloading platformdirs-3.5.1-py3-none-any.whl (15 kB)\n","Collecting notebook-shim>=0.2.3\n","  Downloading notebook_shim-0.2.3-py3-none-any.whl (13 kB)\n","Collecting jupyter-server>=1.8\n","  Downloading jupyter_server-2.5.0-py3-none-any.whl (366 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.8/366.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonschema>=2.6\n","  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastjsonschema\n","  Downloading fastjsonschema-2.16.3-py3-none-any.whl (23 kB)\n","Collecting wcwidth\n","  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n","Collecting ptyprocess\n","  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (8.5.0.96)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (10.2.10.91)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (1.12)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (11.4.0.1)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (11.7.101)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (10.9.0.58)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (2.14.3)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (11.7.4.91)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (3.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (65.6.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (0.40.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (16.0.5)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (3.26.3)\n","Collecting argon2-cffi-bindings\n","  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting soupsieve>1.2\n","  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n","Collecting webencodings\n","  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n","Collecting parso<0.9.0,>=0.8.0\n","  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n","  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting attrs>=17.4.0\n","  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websocket-client\n","  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting anyio>=3.1.0\n","  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyter-events>=0.4.0\n","  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n","Collecting jupyter-server-terminals\n","  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (1.15.1)\n","Collecting asttokens>=2.1.0\n","  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n","Collecting executing>=1.2.0\n","  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n","Collecting pure-eval\n","  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.11->linear-operator>=0.4.0->gpytorch->d2l==1.0.0b0) (1.3.0)\n","Collecting sniffio>=1.1\n","  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (2.21)\n","Collecting rfc3339-validator\n","  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n","Collecting rfc3986-validator>=0.1.1\n","  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting pyyaml>=5.3\n","  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-json-logger>=2.0.4\n","  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n","Collecting fqdn\n","  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n","Collecting isoduration\n","  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n","Collecting uri-template\n","  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n","Collecting webcolors>=1.11\n","  Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n","Collecting jsonpointer>1.13\n","  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n","Collecting arrow>=0.15.0\n","  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: gym\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for gym (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for gym\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for gym\n","Failed to build gym\n","Installing collected packages: webencodings, wcwidth, pytz, pure-eval, ptyprocess, pickleshare, mistune, ipython-genutils, fastjsonschema, executing, backcall, widgetsnbextension, websocket-client, webcolors, uri-template, tzdata, traitlets, tornado, tinycss2, threadpoolctl, soupsieve, sniffio, six, Send2Trash, scipy, rfc3986-validator, pyzmq, pyyaml, python-json-logger, pyrsistent, pyparsing, pygments, psutil, prompt-toolkit, prometheus-client, platformdirs, pexpect, parso, pandocfilters, packaging, nest-asyncio, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, joblib, fqdn, fonttools, defusedxml, decorator, debugpy, cycler, contourpy, cloudpickle, attrs, terminado, scikit-learn, rfc3339-validator, qtpy, python-dateutil, matplotlib-inline, jupyter-core, jsonschema, jedi, gym, comm, bleach, beautifulsoup4, asttokens, argon2-cffi-bindings, anyio, stack-data, pandas, nbformat, matplotlib, jupyter-server-terminals, jupyter-client, arrow, argon2-cffi, nbclient, isoduration, ipython, nbconvert, ipykernel, qtconsole, jupyter-events, jupyter-console, ipywidgets, jupyter-server, notebook-shim, nbclassic, notebook, jupyter, linear-operator, gpytorch, d2l\n","  Running setup.py install for gym ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  DEPRECATION: gym was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. pip 23.1 will enforce this behaviour change. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n","\u001b[0mSuccessfully installed Send2Trash-1.8.2 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 asttokens-2.2.1 attrs-23.1.0 backcall-0.2.0 beautifulsoup4-4.12.2 bleach-6.0.0 cloudpickle-2.2.1 comm-0.1.3 contourpy-1.0.7 cycler-0.11.0 d2l-1.0.0b0 debugpy-1.6.7 decorator-5.1.1 defusedxml-0.7.1 executing-1.2.0 fastjsonschema-2.16.3 fonttools-4.39.4 fqdn-1.5.1 gpytorch-1.10 gym-0.21.0 ipykernel-6.23.1 ipython-8.13.2 ipython-genutils-0.2.0 ipywidgets-8.0.6 isoduration-20.11.0 jedi-0.18.2 joblib-1.2.0 jsonpointer-2.3 jsonschema-4.17.3 jupyter-1.0.0 jupyter-client-8.2.0 jupyter-console-6.6.3 jupyter-core-5.3.0 jupyter-events-0.6.3 jupyter-server-2.5.0 jupyter-server-terminals-0.4.4 jupyterlab-pygments-0.2.2 jupyterlab-widgets-3.0.7 kiwisolver-1.4.4 linear-operator-0.4.0 matplotlib-3.7.1 matplotlib-inline-0.1.6 mistune-2.0.5 nbclassic-1.0.0 nbclient-0.7.4 nbconvert-7.4.0 nbformat-5.8.0 nest-asyncio-1.5.6 notebook-6.5.4 notebook-shim-0.2.3 packaging-23.1 pandas-2.0.1 pandocfilters-1.5.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 platformdirs-3.5.1 prometheus-client-0.16.0 prompt-toolkit-3.0.38 psutil-5.9.5 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.15.1 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3 pyyaml-6.0 pyzmq-25.0.2 qtconsole-5.4.3 qtpy-2.3.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 scikit-learn-1.2.2 scipy-1.10.1 six-1.16.0 sniffio-1.3.0 soupsieve-2.4.1 stack-data-0.6.2 terminado-0.17.1 threadpoolctl-3.1.0 tinycss2-1.2.1 tornado-6.3.2 traitlets-5.9.0 tzdata-2023.3 uri-template-1.2.0 wcwidth-0.2.6 webcolors-1.13 webencodings-0.5.1 websocket-client-1.5.1 widgetsnbextension-4.0.7\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cycler","dateutil","defusedxml","ipython_genutils","kiwisolver","matplotlib","matplotlib_inline","mpl_toolkits","pexpect","pickleshare","prompt_toolkit","psutil","six","wcwidth"]}}},"metadata":{}}],"source":["!pip install -q condacolab\n","import condacolab\n","condacolab.install()\n","!pip install torch\n","!pip install torchvision\n","!pip install d2l==1.0.0b0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbV9155tKF7w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683589422891,"user_tz":240,"elapsed":5355,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}},"outputId":"2f70abef-f597-48fe-b05a-60e8f6a0399d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamoseley018\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["!pip install wandb -qU\n","import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Xl9Rf7gIC-Lb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684379636455,"user_tz":240,"elapsed":15380,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}},"outputId":"deb8ec90-3e10-49e3-8996-ac062c618d31"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"UySZvCsHhycT","executionInfo":{"status":"ok","timestamp":1684379649690,"user_tz":240,"elapsed":5306,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["import os\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch import nn, Tensor\n","from torch.nn import functional as F\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","from torchsummary import summary\n","from d2l import torch as d2l\n","from pathlib import Path\n","import sys\n","import nibabel as nib\n","import numpy as np\n","import gc\n","import skimage\n","import h5py\n","import math\n","import PIL\n","from PIL import Image"]},{"cell_type":"markdown","source":["# **Loss Functions**"],"metadata":{"id":"IGcZ_Vm5n5Yv"}},{"cell_type":"code","source":["def dice_loss(pred, target, smooth = 1.):\n","    target = torch.clamp(target, min=0, max=1)\n","\n","    pred = pred.contiguous()\n","    target = target.contiguous()    \n","\n","    intersection = (pred.mul(target)).sum(dim=2).sum(dim=2)\n","    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n","\n","    roundedPreds = torch.round(pred)\n","\n","    intersectionRounded = (roundedPreds.mul(target)).sum(dim=2).sum(dim=2)\n","    roundedLoss = ((2. * intersectionRounded + smooth) / (roundedPreds.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth))\n","\n","    return loss.mean(), roundedLoss.mean()"],"metadata":{"id":"6p7aAli6D06P","executionInfo":{"status":"ok","timestamp":1684379649690,"user_tz":240,"elapsed":3,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"vBBsw05Qw7DO","executionInfo":{"status":"ok","timestamp":1684379649691,"user_tz":240,"elapsed":3,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, weight0=1, weight1=1, gamma=0):\n","        super().__init__()\n","\n","        self.weight0 = weight0\n","        self.weight1 = weight1\n","        self.gamma = gamma\n","\n","    def forward(self, input, target):\n","        loss = 0\n","\n","        predictions = torch.round(input)\n","        accuratePreds = 0\n","\n","        #Takes negative average loss over each element of input\n","        #Loss = ln(prediction) * (absolute loss ^ gamma) * class weight\n","        #prediction is the predicted likelihood that the correct label is true\n","        for i, el in enumerate(input):\n","            #print(f\"{predictions[i]} {el}\")\n","\n","            if predictions[i] == target[i]:\n","                accuratePreds += 1\n","\n","            if target[i] == 1:\n","                loss += torch.log(el) * (abs(1 - el) ** self.gamma) * self.weight1\n","            else:\n","                loss += torch.log(1 - el) * (abs(0 - el) ** self.gamma) * self.weight0\n","\n","        return -1 * loss / len(input), accuratePreds / input.size()[0]"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"IsZV06GU0ue3","executionInfo":{"status":"ok","timestamp":1684379649691,"user_tz":240,"elapsed":3,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["class BalancedCELoss(nn.Module):\n","    def __init__(self, weight0=1, weight1=1):\n","        super().__init__()\n","\n","        self.weight0 = weight0\n","        self.weight1 = weight1\n","\n","    def forward(self, input, target):\n","        loss = 0\n","\n","        predictions = torch.round(input)\n","        accuratePreds = 0\n","\n","        #Takes negative average loss over each element of input\n","        #Loss = ln(prediction) * class weight\n","        #prediction is the predicted likelihood that the correct label is true\n","        for i, el in enumerate(input):\n","            if predictions[i] == target[i]:\n","                accuratePreds += 1\n","\n","            if target[i] == 1:\n","                loss += torch.log(el) * self.weight1\n","            else:\n","                loss += torch.log(1 - el) * self.weight0\n","\n","        return -1 * loss / len(input), accuratePreds / input.size()[0]"]},{"cell_type":"markdown","source":["# **Data Handling**"],"metadata":{"id":"6g1MsLCCoDhb"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"8iO7WioSr-Yk","executionInfo":{"status":"ok","timestamp":1684379649944,"user_tz":240,"elapsed":256,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["class LITSBinaryDataset(Dataset):\n","    def __init__(self, fileName):\n","        super().__init__()\n","\n","        #Keeps a file pointer open throughout use\n","        self.file = h5py.File(fileName, 'r')\n","\n","        #Precalculates length to reduce training computations\n","        self.length = len(list(self.file.keys()))\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        data = self.file[\"Slice\" + str(idx)][\"Slice\"]\n","        segmentation = self.file[\"Slice\" + str(idx)][\"Segmentation\"]\n","        label = self.file[\"Slice\" + str(idx)].attrs.get(\"ImageLabel\")\n","\n","        result = []\n","\n","        #Returns list containing slice data and image label\n","        #Does not currently return segmentation data, will need to implement for decoder\n","        result.append(torch.Tensor(data[...]).unsqueeze(0))\n","        result.append(torch.Tensor(segmentation[...]).unsqueeze(0))\n","        result.append(torch.Tensor(label).squeeze(0))\n","\n","        return result\n","\n","    def closeFile(self):\n","        #Closes file once dataset is no longer being used\n","        #Do not use class instance after this function is called\n","        self.file.close()"]},{"cell_type":"markdown","source":["# **Network**"],"metadata":{"id":"6adquwMWoH0B"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"9-kqO-PVhycU","executionInfo":{"status":"ok","timestamp":1684379649944,"user_tz":240,"elapsed":3,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["class convBlock(nn.Module):\n","    def __init__(self, inChannels, outChannels, strides, dropout) -> None:\n","        super().__init__()\n","\n","        batchNorm = True\n","        layerMean = 1.5\n","        layerDev = 0.1\n","\n","        #Uses 2 convolutional layers for each block\n","        self.conv1 = nn.Conv2d(inChannels, outChannels, kernel_size=3, padding=1, stride=strides)\n","        self.conv2 = nn.Conv2d(outChannels, outChannels, kernel_size=3, padding=1)\n","\n","        #Initializes convolutional layers using hyperparameters for mean and standard deviation\n","        nn.init.normal_(self.conv1.weight, mean=layerMean, std=layerDev)\n","        nn.init.normal_(self.conv2.weight, mean=layerMean, std=layerDev)\n","\n","        self.dropout = nn.Dropout(dropout).to(device)\n","\n","        if(batchNorm):\n","            self.bn1 = nn.BatchNorm2d(outChannels)\n","        else:\n","            self.bn1 = False\n","\n","    def forward(self, X):\n","        Y = self.conv1(X)\n","        if self.bn1:\n","            Y = self.bn1(Y)\n","        Y = F.relu(Y)\n","\n","        Y = self.conv2(Y)\n","        if self.bn1:\n","            Y = self.bn1(Y)\n","        Y = F.relu(Y)\n","\n","        Y = self.dropout(Y)\n","\n","        return Y"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"_rhGtpfGhycV","executionInfo":{"status":"ok","timestamp":1684379649944,"user_tz":240,"elapsed":2,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","    def __init__(self, inChannels, outChannels, strides, dropout) -> None:\n","        super().__init__()\n","\n","        self.convTrans = nn.ConvTranspose2d(inChannels, outChannels, 2, stride=2, padding=0)\n","        self.conv = convBlock(inChannels, outChannels, strides, dropout)\n","\n","    def forward(self, X, skipConn):\n","        Y = self.convTrans(X)\n","        Y = torch.cat((Y, skipConn), dim=1)\n","\n","        return self.conv(Y)"]},{"cell_type":"code","source":["class DecoderNetwork(nn.Module):\n","        def __init__(self, strides, dropout, device) -> None:\n","            super().__init__()\n","\n","            self.device = device\n","            \n","            self.block1 = DecoderBlock(256, 128, strides, dropout)\n","            self.block2 = DecoderBlock(128, 64, strides, dropout)\n","            self.block3 = DecoderBlock(64, 32, strides, dropout)\n","            self.block4 = DecoderBlock(32, 16, strides, dropout)\n","\n","            self.endBlock = nn.Conv2d(16, 1, kernel_size=1, padding=0, stride=1)\n","\n","            self.sigm = nn.Sigmoid()\n","\n","        def forward(self, X, skipConn):\n","            y = X\n","\n","            y = self.block1(y, skipConn[-1])\n","            y = self.block2(y, skipConn[-2])\n","            y = self.block3(y, skipConn[-3])\n","            y = self.block4(y, skipConn[-4])\n","            y = self.endBlock(y)\n","\n","            return self.sigm(y)"],"metadata":{"id":"zFdMolDN9_Q3","executionInfo":{"status":"ok","timestamp":1684379649944,"user_tz":240,"elapsed":2,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uBhZXZ3x8mnJ","executionInfo":{"status":"ok","timestamp":1684379650099,"user_tz":240,"elapsed":157,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["class EncoderNetwork(nn.Module):\n","    def __init__(self, strides, dropout, device) -> None:\n","        super().__init__()\n","\n","        self.device = device\n","\n","        #Creates a list of encoder blocks w/ in and out channels specified by parameter\n","        self.block1 = convBlock(1, 16, strides, dropout)\n","        self.block2 = convBlock(16, 32, strides, dropout)\n","        self.block3 = convBlock(32, 64, strides, dropout)\n","        self.block4 = convBlock(64, 128, strides, dropout)\n","        self.block5 = convBlock(128, 256, strides, dropout)\n","\n","        self.pool = nn.MaxPool2d(2)\n","\n","        #Creates classification branch as sequential\n","        #Try without using sequential, use each layer separately\n","        #Can use without Flatten, average pool does the same thing\n","        #Follow MultiMix code\n","        self.classification = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(256, 1), nn.Sigmoid()).to(device)\n","\n","    def forward(self, X):\n","        y = X.to(self.device)\n","\n","        skipConnections = []\n","\n","        y = self.block1(y)\n","        skipConnections.append(y)\n","        y = self.pool(y)\n","\n","        y = self.block2(y)\n","        skipConnections.append(y)\n","        y = self.pool(y)\n","\n","        y = self.block3(y)\n","        skipConnections.append(y)\n","        y = self.pool(y)\n","\n","        y = self.block4(y)\n","        skipConnections.append(y)\n","        y = self.pool(y)\n","\n","        y = self.block5(y)\n","\n","        return self.classification(y), skipConnections, y"]},{"cell_type":"code","source":["class SegmentationNetwork(nn.Module):\n","    def __init__(self, encoder, decoder, dropout, device) -> None:\n","        super().__init__()\n","\n","        self.device = device\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, X):\n","        _, skip, y = self.encoder(X)\n","\n","        y = self.decoder(y, skip)\n","\n","        return y"],"metadata":{"id":"pdQpz5tB_4Tl","executionInfo":{"status":"ok","timestamp":1684379650099,"user_tz":240,"elapsed":3,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# **Multi Mix Code**"],"metadata":{"id":"D2RziTUxY8jV"}},{"cell_type":"code","source":["def double_conv(in_channels, out_channels):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","        nn.InstanceNorm2d(out_channels),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n","        nn.InstanceNorm2d(in_channels),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Dropout(0.25)\n","    )   \n","\n","class MultiMix(nn.Module):\n","\n","    def __init__(self, n_class = 1, encoder=None):\n","        super().__init__()\n","\n","        if encoder == None:\n","            self.encoder = Encoder(1)\n","        else:\n","            self.encoder = encoder\n","\n","        self.decoder = Decoder(1)\n","        \n","\n","    def forward(self, x):\n","        outC, conv5, conv4, conv3, conv2, conv1 = self.encoder(x)\n","        outSeg = self.decoder(x, conv5, conv4, conv3, conv2, conv1)\n","\n","        # return outSeg, outC, saliency\n","        return outSeg, outC\n","\n","    def freezeEncoder(self):\n","        for param in self.encoder.parameters():\n","            param.requires_grad = False\n","\n","class Encoder(nn.Module):\n","\n","    def __init__(self, n_class = 1):\n","        super().__init__()\n","                \n","        self.dconv_down1 = double_conv(1, 16)\n","        self.dconv_down2 = double_conv(16, 32)\n","        self.dconv_down3 = double_conv(32, 64)\n","        self.dconv_down4 = double_conv(64, 128)\n","        self.dconv_down5 = double_conv(128, 256)      \n","        self.avgpool = nn.AdaptiveAvgPool2d((1,1))       \n","        self.fc = nn.Linear(256, 1) \n","        self.sigm = nn.Sigmoid()\n","\n","        self.maxpool = nn.MaxPool2d(2)\n","\n","    def forward(self, x):\n","        conv1 = self.dconv_down1(x)\n","        x = self.maxpool(conv1)\n","\n","        conv2 = self.dconv_down2(x)\n","        x = self.maxpool(conv2)\n","        \n","        conv3 = self.dconv_down3(x)\n","        x = self.maxpool(conv3)   \n","\n","        conv4 = self.dconv_down4(x)\n","        x = self.maxpool(conv4)\n","\n","        conv5 = self.dconv_down5(x)\n","        x1 = self.maxpool(conv5)\n","        \n","        avgpool = self.avgpool(x1)\n","        avgpool = avgpool.view(avgpool.size(0), -1)\n","        outC = self.fc(avgpool)\n","        \n","        return self.sigm(outC), conv5, conv4, conv3, conv2, conv1\n","\n","class Decoder(nn.Module):\n","\n","    def __init__(self, n_class = 1, nonlocal_mode='concatenation', attention_dsample = (2,2)):\n","        super().__init__()\n","\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        self.dconv_up4 = double_conv(256 + 128, 128)\n","        self.dconv_up3 = double_conv(128 + 64, 64)\n","        self.dconv_up2 = double_conv(64 + 32, 32)\n","        self.dconv_up1 = double_conv(32 + 16, 16)\n","        self.conv_last = nn.Conv2d(16, n_class, 1)\n","\n","        self.conv_last_saliency = nn.Conv2d(17, n_class, 1)\n","\n","        self.sigm = nn.Sigmoid()\n","        \n","        \n","    def forward(self, input, conv5, conv4, conv3, conv2, conv1):\n","  \n","        x = self.upsample(conv5)        \n","        x = torch.cat([x, conv4], dim=1)\n","\n","        x = self.dconv_up4(x)\n","        x = self.upsample(x)        \n","        x = torch.cat([x, conv3], dim=1)       \n","\n","        x = self.dconv_up3(x)\n","        x = self.upsample(x)        \n","        # pdb.set_trace()\n","        x = torch.cat([x, conv2], dim=1)\n","\n","        x = self.dconv_up2(x)\n","        x = self.upsample(x)        \n","        x = torch.cat([x, conv1], dim=1) \n","\n","        x = self.dconv_up1(x)\n","        \n","        out = self.conv_last(x)\n","        \n","        return self.sigm(out)"],"metadata":{"id":"02mGdufeZBCI","executionInfo":{"status":"ok","timestamp":1684379650099,"user_tz":240,"elapsed":2,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# **Training**"],"metadata":{"id":"s4TpJ7zaoLed"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"98eUKvAr2KPz","executionInfo":{"status":"ok","timestamp":1684379650099,"user_tz":240,"elapsed":2,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["def evaluate_accuracy(net, testIter, lossFunc, classification=True, device=None):\n","    net.eval()\n","\n","    #Accuracy, loss\n","    metric = d2l.Accumulator(2)\n","\n","    segmentationMask = []\n","\n","    with torch.no_grad():\n","        for i, (X, y1, y2) in enumerate(testIter):\n","            X = X.to(device)\n","            y1 = y1.to(device)\n","            y2 = y2.to(device)\n","\n","            yhat = net(X)\n","\n","            if isinstance(yhat, tuple):\n","                yhat = yhat[0]\n","\n","            if classification:\n","                loss, accuracy = lossFunc(yhat, y2)\n","            else:\n","                loss, accuracy = lossFunc(yhat, y1)\n","\n","            metric.add(accuracy, loss)\n","\n","            segmentationMask.append(torch.round(yhat).tolist())\n","\n","    return metric[0] / len(testIter), metric[1] / len(testIter)"]},{"cell_type":"code","source":["def final_eval_get_mask(net, testIter, lossFunc1, lossFunc2, device=None):\n","    net.eval()\n","\n","    #Accuracy, loss\n","    segmentMetric = d2l.Accumulator(2)\n","    classificationMetric = d2l.Accumulator(2)\n","\n","    segmentationMask = []\n","\n","    with torch.no_grad():\n","        for i, (X, y1, y2) in enumerate(testIter):\n","            X = X.to(device)\n","            y1 = y1.to(device)\n","            y2 = y2.to(device)\n","\n","            segment, classPred = net(X)\n","\n","            loss1, acc1 = lossFunc1(segment, y1)\n","            loss2, acc2 = lossFunc2(classPred, y2)\n","\n","            segmentMetric.add(acc1, loss1)\n","            classificationMetric.add(acc2, loss2)\n","\n","            segmentationMask.append(torch.round(segment).squeeze(0).squeeze(0).tolist())\n","\n","    return segmentMetric[0] / len(testIter), segmentMetric[1] / len(testIter), classificationMetric[0] / len(testIter), classificationMetric[1] / len(testIter), segmentationMask"],"metadata":{"id":"j4zERK2pZGW0","executionInfo":{"status":"ok","timestamp":1684379650319,"user_tz":240,"elapsed":222,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def joint_eval(net, testIter, classLossFunc, segmentLossFunc, device=None):\n","    net.eval()\n","\n","    #Accuracy, loss\n","    metric = d2l.Accumulator(4)\n","\n","    segmentationMask = []\n","\n","    with torch.no_grad():\n","        for i, (X, y1, y2) in enumerate(testIter):\n","            X = X.to(device)\n","            y1 = y1.to(device)\n","            y2 = y2.to(device)\n","\n","            yhat = net(X)\n","\n","            classLoss, classAccuracy = classLossFunc(yhat[1], y2)\n","            segmentLoss, segmentAccuracy = segmentLossFunc(yhat[0], y1)\n","\n","            metric.add(classAccuracy, classLoss, segmentAccuracy, segmentLoss)\n","\n","    return metric[0] / len(testIter), metric[1] / len(testIter), metric[2] / len(testIter), metric[3] / len(testIter)"],"metadata":{"id":"IDaDIi2xuLBX","executionInfo":{"status":"ok","timestamp":1684379650319,"user_tz":240,"elapsed":9,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"7ZgVGj5whycV","executionInfo":{"status":"ok","timestamp":1684379650320,"user_tz":240,"elapsed":8,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["def train(net: nn.Module, trainIter, testIter, numEpochs, startEpoch, learnRate, batchSize, device: torch.device, startDim, epochsToDouble, modelFileName, epochsToSave, \n","          useWandB=False, cosineAnnealing=True, restartEpochs=-1, progressive=False, lossFunc = nn.BCEWithLogitsLoss(), classification=True):\n","    print(f\"Training on {device}\")\n","    \n","    net.to(device)\n","    optimizer = torch.optim.Adam(net.parameters(), lr=learnRate)\n","\n","    #Setting restartEpochs to a negative will use no warm restarts, otherwise will use warm restarts \n","    if cosineAnnealing:\n","        if restartEpochs < 0:\n","            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n","        else:\n","            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, restartEpochs, T_mult=1)\n","\n","    numBatches = len(trainIter)\n","    bestValLoss = float('inf')\n","\n","    currDim = startDim\n","    for epoch in range(startEpoch, numEpochs):\n","        net.train()\n","        \n","        #Loss, accuracy\n","        metric = d2l.Accumulator(2)\n","\n","        for i, (X, y1, y2) in enumerate(trainIter):\n","            optimizer.zero_grad()\n","            y1 = y1.to(device)\n","            y2 = y2.to(device)\n","\n","            if progressive > 0:\n","                #If using progressive learning, downsamples image to the current dimension\n","                X = F.interpolate(X, size=int(currDim))\n","\n","            X = X.to(device)\n","            \n","            yhat = net(X)\n","\n","            if isinstance(yhat, tuple):\n","                yhat = yhat[0]\n","\n","            if classification:\n","                l, accuracy = lossFunc(yhat, y2)\n","            else:\n","                l, accuracy = lossFunc(yhat, y1)\n","\n","            #print(f\"Loss: {l.item()} Predictions: {yhat.tolist()} Labels: {y.tolist()}\")\n","\n","            l.backward()\n","            optimizer.step()\n","\n","            if cosineAnnealing:\n","                scheduler.step(epoch + i / numBatches)\n","\n","            metric.add(l, accuracy)\n","\n","        #Progressive learning\n","        if (epoch + 1) % epochsToDouble == 0 and progressive == 1:\n","            currDim *= 2\n","        #Reverse progressive learning\n","        elif (epoch + 1) % epochsToDouble == 0 and progressive == 2:\n","            currDim /= 2\n","\n","        #Checkpoints model\n","        if (epoch + 1) % epochsToSave == 0:\n","            torch.save(net.state_dict(), modelFileName + \"Epoch\" + str(epoch))\n","\n","        validationAcc, validationLoss = evaluate_accuracy(net, testIter, lossFunc, classification=classification, device=device)\n","\n","        #Overwrites previous best model based on validation accuracy\n","        if validationLoss < bestValLoss:\n","            bestValLoss = validationLoss\n","            torch.save(net.state_dict(), modelFileName + \"BestLoss\")\n","\n","        print(f\"Epoch {epoch}:\\nTrain Acc: {metric[1] / numBatches} Validation Acc: {validationAcc} Train Loss: {metric[0] / numBatches} Validation Loss: {validationLoss}\")\n","\n","        #Externally logs epoch info to WandB\n","        if useWandB:\n","            wandb.log({\"Train Acc\": metric[1] / numBatches,\n","                    \"Validation Acc\": validationAcc,\n","                    \"Train Loss\": metric[0] / numBatches,\n","                    \"Validation Loss\": validationLoss\n","                    })"]},{"cell_type":"code","source":["def joint_train(net: nn.Module, trainIter, testIter, numEpochs, startEpoch, learnRate, batchSize, device: torch.device, modelFileName, epochsToSave, \n","          useWandB=False, cosineAnnealing=True, restartEpochs=-1, classLossFunc = None, segmentLossFunc = None, weights = [0.5, 0.5]):\n","    print(f\"Training on {device}\")\n","    \n","    net.to(device)\n","    optimizer = torch.optim.Adam(net.parameters(), lr=learnRate)\n","\n","    #Setting restartEpochs to a negative will use no warm restarts, otherwise will use warm restarts \n","    if cosineAnnealing:\n","        if restartEpochs < 0:\n","            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n","        else:\n","            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, restartEpochs, T_mult=1)\n","\n","    numBatches = len(trainIter)\n","    bestValLoss = float('inf')\n","\n","    currDim = startDim\n","    for epoch in range(startEpoch, numEpochs):\n","        net.train()\n","        \n","        #Loss, accuracy\n","        metric = d2l.Accumulator(2)\n","\n","        for i, (X, y1, y2) in enumerate(trainIter):\n","            optimizer.zero_grad()\n","            y1 = y1.to(device)\n","            y2 = y2.to(device)\n","            X = X.to(device)\n","            \n","            yhat = net(X)\n","\n","            segmentLoss, segmentAcc = segmentLossFunc(yhat[0], y1)\n","            classLoss, classAcc = classLossFunc(yhat[1], y2)\n","\n","            #print(f\"Loss: {l.item()} Predictions: {yhat.tolist()} Labels: {y.tolist()}\")\n","\n","            l = (weights[0] * segmentLoss) + (weights[1] * classLoss)\n","\n","            l.backward()\n","            optimizer.step()\n","\n","            if cosineAnnealing:\n","                scheduler.step(epoch + i / numBatches)\n","\n","            metric.add(l, segmentAcc)\n","\n","        #Progressive learning\n","        if (epoch + 1) % epochsToDouble == 0 and progressive == 1:\n","            currDim *= 2\n","        #Reverse progressive learning\n","        elif (epoch + 1) % epochsToDouble == 0 and progressive == 2:\n","            currDim /= 2\n","\n","        #Checkpoints model\n","        if (epoch + 1) % epochsToSave == 0:\n","            torch.save(net.state_dict(), modelFileName + \"Epoch\" + str(epoch))\n","\n","        validationAcc, validationLoss = evaluate_accuracy(net, testIter, segmentLossFunc, classification=False, device=device)\n","\n","        #Overwrites previous best model based on validation accuracy\n","        if validationLoss < bestValLoss:\n","            bestValLoss = validationLoss\n","            torch.save(net.state_dict(), modelFileName + \"BestLoss\")\n","\n","        print(f\"Epoch {epoch}:\\nTrain Acc: {metric[1] / numBatches} Validation Acc: {validationAcc} Train Loss: {metric[0] / numBatches} Validation Loss: {validationLoss}\")\n","\n","        #Externally logs epoch info to WandB\n","        if useWandB:\n","            wandb.log({\"Train Acc\": metric[1] / numBatches,\n","                    \"Validation Acc\": validationAcc,\n","                    \"Train Loss\": metric[0] / numBatches,\n","                    \"Validation Loss\": validationLoss\n","                    })"],"metadata":{"id":"_W7zeQw93ObQ","executionInfo":{"status":"ok","timestamp":1684379650498,"user_tz":240,"elapsed":184,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# **Setup**"],"metadata":{"id":"Oa5VBt2woQSZ"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"tbHyODbs1XNH","executionInfo":{"status":"ok","timestamp":1684379650500,"user_tz":240,"elapsed":7,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[],"source":["#Hyperparameters and training modifications\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","#device = torch.device(\"cpu\")\n","\n","modelName = \"StandardUNet\"\n","fileSaveName = \"/content/drive/MyDrive/\" + modelName\n","\n","#Use if starting from a checkpoint\n","startEpoch = 0\n","\n","useWandB = False\n","\n","batchSize = 6\n","learnRate = 0.008\n","epochs = 100\n","dropout = 0.3\n","\n","#Progressive training parameters\n","startDim = 32\n","epochsToDouble = 25\n","\n","#0: not progressive, 1: progressive, 2: reverse progressive\n","progressive = 0\n","\n","#Checkpointing\n","epochsToSave = 10\n","\n","#Learn rate scheduling parameters\n","cosineAnnealing = True\n","cosineRestartEpochs = 10\n","\n","#lossFunc = BalancedCELoss(weight0=1, weight1=1.5)\n","#lossFunc = FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n","#lossFunc = nn.BCEWithLogitsLoss()\n","#lossFunc = WeightedDiceLoss(weight0=0.2, weight1=0.8)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"o0JenAeF1rFu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684379664043,"user_tz":240,"elapsed":13394,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}},"outputId":"cfa27150-7236-40f2-ac04-f7babcee52a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset loaded\n"]}],"source":["#Load Datasets\n","trainDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/FullTrainDataset.hdf5\")\n","validationDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/ValidationDataset.hdf5\")\n","testDataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/TestDataset.hdf5\")\n","\n","trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n","validationIter = DataLoader(validationDataset, batch_size=batchSize)\n","testIter = DataLoader(testDataset, batch_size=batchSize)\n","\n","print(\"Dataset loaded\")"]},{"cell_type":"markdown","source":["# **Standard Training**"],"metadata":{"id":"blz2NJ-mo_vJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvELD2iw1fgj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683601193083,"user_tz":240,"elapsed":254,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}},"outputId":"f177e2e7-9382-4335-f9b2-247aed63209b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Intialized joint training model\n"]}],"source":["#Load model\n","jointTrainingFileName = \"\"\n","\n","#lossFunc = WeightedDiceLoss(weight0=0.2, weight1=0.8)\n","lossFunc = dice_loss\n","\n","#encoder = EncoderNetwork(1, dropout, device).to(device)\n","#decoder = DecoderNetwork(1, dropout, device).to(device)\n","#segmenter = SegmentationNetwork(encoder, decoder, dropout, device)\n","segmenter = MultiMix()\n","#print(summary(net, (1, 256, 256)))\n","\n","#Loads model from file if using a pretrained version\n","if jointTrainingFileName != \"\":\n","    segmenter.load_state_dict(torch.load(jointTrainingFileName))\n","\n","segmenter = segmenter.to(device)\n","\n","print(\"Intialized joint training model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YVz5cMohycW"},"outputs":[],"source":["#Train Model\n","\n","\"\"\"\n","if useWandB:\n","    wandb.init(project=\"LiverSegmentation\",\n","            name=modelName,\n","            config={\n","                \"BatchSize\":batchSize,\n","                \"LearnRate\":learnRate,\n","                \"Epochs\":epochs,\n","                \"StartDimension\":startDim,\n","                \"EpochsToDouble\":epochsToDouble\n","            })\n","\"\"\"\n","\n","train(segmenter, trainIter, validationIter, epochs, startEpoch, learnRate, batchSize, device, startDim, epochsToDouble, fileSaveName, epochsToSave, useWandB=useWandB, \n","      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0, lossFunc=lossFunc, classification=False)\n","\n","if useWandB:\n","    wandb.finish()"]},{"cell_type":"markdown","source":["# **Pre-Training**"],"metadata":{"id":"UMT_AzWypZdL"}},{"cell_type":"code","source":["lossFunc = FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n","\n","encoderFileName = \"\"\n","encoderFileSaveName = \"/content/drive/MyDrive/MachineLearningResearch/ProgressiveEncoders/ProgressiveEncoder4\"\n","\n","#encoder = EncoderNetwork(1, dropout, device).to(device)\n","encoder = Encoder(1)\n","\n","if encoderFileName != \"\":\n","    encoder.load_state_dict(torch.load(encoderFileName))\n","\n","encoder = encoder.to(device)"],"metadata":{"id":"JsMuX0NYpYxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Train Model\n","gc.collect()\n","\n","if useWandB:\n","    wandb.init(project=\"Pre-TrainedEncoder\",\n","            name=\"ReverseProgressiveUNetEncoder\",\n","            config={\n","                \"BatchSize\":batchSize,\n","                \"LearnRate\":learnRate,\n","                \"Epochs\":epochs,\n","                \"StartDimension\":startDim,\n","                \"EpochsToDouble\":epochsToDouble,\n","                \"Dropout\":dropout,\n","            })\n","\n","train(encoder, trainIter, validationIter, epochs, startEpoch, learnRate, batchSize, device, startDim, epochsToDouble, encoderFileSaveName, epochsToSave, useWandB=useWandB, \n","      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive, lossFunc=lossFunc, classification=True)\n","\n","if useWandB:\n","    wandb.finish()"],"metadata":{"id":"NR1JX1AeqQAO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lossFunc = dice_loss\n","\n","encoder.load_state_dict(torch.load(encoderFileSaveName))\n","#decoder = DecoderNetwork(1, dropout, device).to(device)\n","#segmenter = SegmentationNetwork(encoder, decoder, dropout, device)\n","\n","segmenter = MultiMix(encoder=encoder)\n","\n","segmenter = segmenter.to(device)"],"metadata":{"id":"PLEB6MZfqk4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Train Model\n","gc.collect()\n","\n","if useWandB:\n","    wandb.init(project=\"LiverSegmentationJointTraining\",\n","            name=\"NoWeights\",\n","            config={\n","                \"BatchSize\":batchSize,\n","                \"LearnRate\":learnRate,\n","                \"Epochs\":epochs,\n","                \"StartDimension\":startDim,\n","                \"EpochsToDouble\":epochsToDouble\n","            })\n","\n","train(segmenter, trainIter, validationIter, epochs, startEpoch, learnRate, batchSize, device, startDim, epochsToDouble, fileSaveName, epochsToSave, useWandB=useWandB, \n","      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0, lossFunc=lossFunc, classification=False)\n","\n","if useWandB:\n","    wandb.finish()"],"metadata":{"id":"ti-Rck8Xq3sj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Joint Training**"],"metadata":{"id":"JH2TvySW9ux8"}},{"cell_type":"code","source":["segmenter = MultiMix()\n","\n","\"\"\"\n","if useWandB:\n","    wandb.init(project=\"LiverSegmentationJointTraining\",\n","            name=\"Weights:0.5,0.5#2\",\n","            config={\n","                \"BatchSize\":batchSize,\n","                \"LearnRate\":learnRate,\n","                \"Epochs\":epochs,\n","                \"StartDimension\":startDim,\n","                \"EpochsToDouble\":epochsToDouble\n","            })\n","\"\"\"\n","\n","classLossFunc = FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n","\n","joint_train(segmenter, trainIter, validationIter, epochs, startEpoch, learnRate, batchSize, device, fileSaveName, epochsToSave, useWandB=useWandB, \n","      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, segmentLossFunc=dice_loss, classLossFunc=classLossFunc, weights=[0.5, 0.5])\n","\n","if useWandB:\n","    wandb.finish()"],"metadata":{"id":"st2leTac4VsP","colab":{"base_uri":"https://localhost:8080/","height":814},"executionInfo":{"status":"error","timestamp":1684381265030,"user_tz":240,"elapsed":313912,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}},"outputId":"0ee0bbc1-6d44-4e32-8cfa-d737f988c191"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on cuda\n","Epoch 0:\n","Train Acc: 0.2664094201874649 Validation Acc: 0.14966454745066585 Train Loss: 0.41529309519117685 Validation Loss: 0.8589106948673725\n","Epoch 1:\n","Train Acc: 0.3604078584535109 Validation Acc: 0.1618151319056051 Train Loss: 0.3464082794920575 Validation Loss: 0.8398429675400257\n","Epoch 2:\n","Train Acc: 0.39480577577944015 Validation Acc: 0.2058338455390185 Train Loss: 0.3172740226062082 Validation Loss: 0.7970126536488533\n","Epoch 3:\n","Train Acc: 0.4264376039031337 Validation Acc: 0.510195766503457 Train Loss: 0.30079778807787155 Validation Loss: 0.7401450663805008\n","Epoch 4:\n","Train Acc: 0.691575181342179 Validation Acc: 0.933587880237028 Train Loss: 0.2857940602216789 Validation Loss: 0.4253993382304907\n","Epoch 5:\n","Train Acc: 0.8092614019678223 Validation Acc: 0.9005903452634811 Train Loss: 0.2730942838724783 Validation Loss: 0.16638283707201482\n","Epoch 6:\n","Train Acc: 0.8959559991205339 Validation Acc: 0.9446448827814311 Train Loss: 0.1664362837888783 Validation Loss: 0.0664386067353189\n","Epoch 7:\n","Train Acc: 0.9337056510740047 Validation Acc: 0.9433877969812602 Train Loss: 0.10321578763344948 Validation Loss: 0.06722284687682986\n","Epoch 8:\n","Train Acc: 0.9510752138474005 Validation Acc: 0.9422112334799021 Train Loss: 0.08286652770295418 Validation Loss: 0.06817062863148748\n","Epoch 9:\n","Train Acc: 0.954884122601516 Validation Acc: 0.9430510438513011 Train Loss: 0.07809486655558613 Validation Loss: 0.06388861286453902\n","Epoch 10:\n","Train Acc: 0.5605199590381679 Validation Acc: 0.7510322906496003 Train Loss: 0.26284663511855566 Validation Loss: 0.250556657561101\n","Epoch 11:\n","Train Acc: 0.5189806653017919 Validation Acc: 0.7510322906496003 Train Loss: 0.25264634174736983 Validation Loss: 0.24946649960242212\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-2db654aeb49d>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mclassLossFunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFocalLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m joint_train(segmenter, trainIter, validationIter, epochs, startEpoch, learnRate, batchSize, device, fileSaveName, epochsToSave, useWandB=useWandB, \n\u001b[0m\u001b[1;32m     19\u001b[0m       cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, segmentLossFunc=dice_loss, classLossFunc=classLossFunc, weights=[0.5, 0.5])\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-a552902aa1c0>\u001b[0m in \u001b[0;36mjoint_train\u001b[0;34m(net, trainIter, testIter, numEpochs, startEpoch, learnRate, batchSize, device, modelFileName, epochsToSave, useWandB, cosineAnnealing, restartEpochs, classLossFunc, segmentLossFunc, weights)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumBatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegmentAcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#Progressive learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/d2l/torch.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   3134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/d2l/torch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# **Evaluation/Ending**"],"metadata":{"id":"iipij4bjp9hs"}},{"cell_type":"code","execution_count":33,"metadata":{"id":"h1tLSjzH2F-Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f548a4b-f201-45cc-e02e-1c90911370e8","executionInfo":{"status":"ok","timestamp":1684381311976,"user_tz":240,"elapsed":4135,"user":{"displayName":"Aaron Moseley","userId":"07867806947769443420"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: Pre-Trained then Joint Trained UNet\n","Classification Accuracy: 0.861111111111111 Classification Loss: 0.05684027758913792\n","Segmentation Dice: 0.8773960446825103 Segmentation Loss: 0.12693572284964225\n"]}],"source":["modelName = \"Pre-Trained then Joint Trained UNet\"\n","classification = False\n","fileSaveName = \"/content/drive/MyDrive/StandardUNetBestLossBestLossBestLoss\"\n","segmentLossFunc = dice_loss\n","classossFunc = FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n","\n","if classification:\n","    net = encoder\n","    net.load_state_dict(torch.load(encoderFileSaveName + \"BestLoss\"))\n","else:\n","    net = segmenter\n","    net.load_state_dict(torch.load(fileSaveName))\n","\n","#Evaluate Model\n","print(f\"Model: {modelName}\")\n","\n","classAcc, classLoss, segmentAcc, segmentLoss = joint_eval(net, testIter, classLossFunc, segmentLossFunc, device=device)\n","print(f\"Classification Accuracy: {classAcc} Classification Loss: {classLoss}\")\n","print(f\"Segmentation Dice: {segmentAcc} Segmentation Loss: {segmentLoss}\")"]},{"cell_type":"code","source":["fileSaveName = \"drive/MyDrive/MachineLearningResearch/Standard UNets/StandardUNet3\"\n","dataset = LITSBinaryDataset(\"drive/MyDrive/MachineLearningResearch/Datasets/Scan1Dataset.hdf5\")\n","iter = DataLoader(dataset, batch_size=batchSize)\n","lossFunc1 = dice_loss\n","lossFunc2 = FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n","\n","net = MultiMix()\n","net.load_state_dict(torch.load(fileSaveName))\n","\n","net.to(device)\n","\n","#acc, loss, _ = evaluate_accuracy(net, iter, lossFunc2, classification=True, device=device)\n","\n","#print(f\"Acc {acc} Loss {loss}\")\n","\n","segmentAcc, segmentLoss, classAcc, classLoss, segmentationMask = final_eval(net, iter, lossFunc1, lossFunc2, device=device)\n","print(f\"Test Accuracy: {segmentAcc} Test Loss: {segmentLoss}\")\n","print(f\"Test Accuracy: {classAcc} Test Loss: {classLoss}\")\n","print(len(segmentationMask[0][0]))\n","\n","\n","fileName = \"drive/MyDrive/Scan1SegmentationMap1.hdf5\"\n","wFile = h5py.File(fileName, \"w\")\n","\n","for i, slice in enumerate(segmentationMask):\n","    wFile.create_dataset(\"Slice\" + str(i), data=slice)\n","\n","wFile.close()"],"metadata":{"id":"KI_1aq7_VJ01"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LDAG1Pd2KXN"},"outputs":[],"source":["#Close datasets\n","trainDataset.closeFile()\n","validationDataset.closeFile()\n","testDataset.closeFile()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["IGcZ_Vm5n5Yv","6g1MsLCCoDhb","6adquwMWoH0B","D2RziTUxY8jV","s4TpJ7zaoLed","blz2NJ-mo_vJ","UMT_AzWypZdL"]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"ea23a5d6ea5dd6b47a6bacc48f8acbc6e91dc182fa6b25270d70228f0691131c"}}},"nbformat":4,"nbformat_minor":0}