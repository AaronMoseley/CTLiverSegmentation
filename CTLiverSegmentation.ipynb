{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbV9155tKF7w",
        "outputId": "2f70abef-f597-48fe-b05a-60e8f6a0399d"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UySZvCsHhycT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "#from torchsummary import summary\n",
        "import gc\n",
        "import h5py\n",
        "from UNet import UNet, Encoder, ContrastiveEncoder, ResNetBlock, ResidualBlock\n",
        "from LITSDataset import LITSBinaryDataset, LITSContDataset, LITSMultiClassDataset\n",
        "import LossFunctions\n",
        "import TrainingEval\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tbHyODbs1XNH"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters and training modifications\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "modelName = \"StandardUNet10\"\n",
        "modelFile = \"UsedModels/\" + modelName\n",
        "#configFile = \"evalConfig.txt\"\n",
        "configFile = \"ContrastiveModels/contFineTuneConfig.txt\"\n",
        "\n",
        "startEpoch = 0\n",
        "useWandB = 0\n",
        "batchSize = 0\n",
        "learnRate = 0\n",
        "epochs = 0\n",
        "startDim = 0\n",
        "epochsToDouble = 0\n",
        "progressive = 0\n",
        "epochsToSave = 0\n",
        "cosineAnnealing = 0\n",
        "cosineRestartEpochs = 0\n",
        "\n",
        "varDict = {\n",
        "    \"startEpoch\":startEpoch,\n",
        "    \"useWandB\":useWandB,\n",
        "    \"batchSize\":batchSize,\n",
        "    \"learnRate\":learnRate,\n",
        "    \"epochs\":epochs,\n",
        "    \"startDim\":startDim,\n",
        "    \"epochsToDouble\":epochsToDouble,\n",
        "    \"progressive\":progressive,\n",
        "    \"epochsToSave\":epochsToSave,\n",
        "    \"cosineAnnealing\":cosineAnnealing,\n",
        "    \"cosineRestartEpochs\":cosineRestartEpochs,\n",
        "}\n",
        "\n",
        "TrainingEval.ParseConfig(configFile, varDict)\n",
        "\n",
        "for key in varDict:\n",
        "    if varDict[key].is_integer():\n",
        "        locals()[key] = int(varDict[key])\n",
        "    else:\n",
        "        locals()[key] = varDict[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0JenAeF1rFu",
        "outputId": "cfa27150-7236-40f2-ac04-f7babcee52a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets loaded\n"
          ]
        }
      ],
      "source": [
        "#Load Datasets\n",
        "#trainDataset = LITSBinaryDataset(\"Datasets/StandardDatasets/FullTrainDataset.hdf5\")\n",
        "trainDataset = LITSBinaryDataset(\"Datasets/StandardDatasets/FullTrainDataset.hdf5\")\n",
        "validationDataset = LITSBinaryDataset(\"Datasets/StandardDatasets/ValidationDataset.hdf5\")\n",
        "testDataset = LITSBinaryDataset(\"Datasets/StandardDatasets/TestDataset.hdf5\")\n",
        "\n",
        "trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "validationIter = DataLoader(validationDataset, batch_size=batchSize)\n",
        "testIter = DataLoader(testDataset, batch_size=batchSize)\n",
        "\n",
        "print(\"Datasets loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trainDataset = LITSMultiClassDataset(\"Datasets/MultiClass/MultiClassTrainingDataset.hdf5\")\n",
        "#validationDataset = LITSMultiClassDataset(\"Datasets/MultiClass/MultiClassValidationDataset.hdf5\")\n",
        "testDataset = LITSMultiClassDataset(\"Datasets/MultiClass/MultiClassTestingDataset.hdf5\")\n",
        "\n",
        "#trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "#validationIter = DataLoader(validationDataset, batch_size=batchSize)\n",
        "testIter = DataLoader(testDataset, batch_size=batchSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testDataset = LITSBinaryDataset(\"Datasets/TotalSegmentator/TotalSegmentatorTesting.hdf5\")\n",
        "testIter = DataLoader(testDataset, batch_size=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "blz2NJ-mo_vJ"
      },
      "source": [
        "# **Standard Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvELD2iw1fgj",
        "outputId": "f177e2e7-9382-4335-f9b2-247aed63209b"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "initModel = \"\"\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]\n",
        "\n",
        "segmenter = UNet(device=device, n_class=1)\n",
        "#print(summary(net, (1, 256, 256)))\n",
        "\n",
        "#Loads model from file if using a pretrained version\n",
        "if initModel != \"\":\n",
        "    segmenter.load_state_dict(torch.load(initModel))\n",
        "\n",
        "segmenter = segmenter.to(device)\n",
        "\n",
        "print(\"Intialized standard UNet model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YVz5cMohycW"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentation\",\n",
        "            name=modelName,\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainDataset = LITSMultiClassDataset(\"Datasets/MultiClass/MultiClassTrainingDataset.hdf5\")\n",
        "validationDataset = LITSMultiClassDataset(\"Datasets/MultiClass/MultiClassValidationDataset.hdf5\")\n",
        "testDataset = LITSMultiClassDataset(\"Datasets/MultiClass/MultiClassTestingDataset.hdf5\")\n",
        "\n",
        "trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "validationIter = DataLoader(validationDataset, batch_size=batchSize)\n",
        "testIter = DataLoader(testDataset, batch_size=batchSize)\n",
        "\n",
        "#Load model\n",
        "initModel = \"\"\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]\n",
        "\n",
        "for modelNum in range(10):\n",
        "    modelFile = \"MultiClassUNet\" + str(modelNum)\n",
        "    segmenter = UNet(device=device, n_class=2)\n",
        "    #print(summary(net, (1, 256, 256)))\n",
        "\n",
        "    #Loads model from file if using a pretrained version\n",
        "    if initModel != \"\":\n",
        "        segmenter.load_state_dict(torch.load(initModel))\n",
        "\n",
        "    segmenter = segmenter.to(device)\n",
        "\n",
        "    print(\"Intialized standard UNet model\")\n",
        "\n",
        "    #Train Model\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.init(project=\"LiverSegmentation\",\n",
        "                name=modelName,\n",
        "                config={\n",
        "                    \"BatchSize\":batchSize,\n",
        "                    \"LearnRate\":learnRate,\n",
        "                    \"Epochs\":epochs,\n",
        "                    \"StartDimension\":startDim,\n",
        "                    \"EpochsToDouble\":epochsToDouble\n",
        "                })\n",
        "\n",
        "    TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "        cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive)\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UMT_AzWypZdL"
      },
      "source": [
        "# **Pre-Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsMuX0NYpYxZ"
      },
      "outputs": [],
      "source": [
        "focal = LossFunctions.FocalLoss(weight0=0.1, weight1=0.9, gamma=2)\n",
        "\n",
        "lossFuncs = [[], [focal, LossFunctions.accuracy, LossFunctions.f1]]\n",
        "weights = [[], [1, 0, 0]]\n",
        "\n",
        "initEncoder = \"Run 2/Progressive Encoders/ProgEncoder10\"\n",
        "encoderFile = \"UsedModels/Encoder1\"\n",
        "\n",
        "encoder = Encoder(1)\n",
        "\n",
        "if initEncoder != \"\":\n",
        "    encoder.load_state_dict(torch.load(initEncoder))\n",
        "\n",
        "encoder = encoder.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR1JX1AeqQAO"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "gc.collect()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"PreTrainedEncoder\",\n",
        "            name=\"UNetEncoder\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble,\n",
        "            })\n",
        "\n",
        "print(TrainingEval.train(encoder, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, encoderFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive, encoder=True))\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLEB6MZfqk4d"
      },
      "outputs": [],
      "source": [
        "segmenter = UNet(encoder=encoder)\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti-Rck8Xq3sj"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "gc.collect()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentationPreTraining\",\n",
        "            name=\"NoWeights\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JH2TvySW9ux8"
      },
      "source": [
        "# **Joint Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "st2leTac4VsP",
        "outputId": "0ee0bbc1-6d44-4e32-8cfa-d737f988c191"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(range(10)):\n",
        "    modelFile = \"ContJoint\" + str(i)\n",
        "    initEncoder = \"ContrastiveModels/Encoders/ContrastiveEncoder\" + str(i)\n",
        "\n",
        "    encoder = Encoder()\n",
        "    encoder.load_state_dict(torch.load(initEncoder), strict=False)\n",
        "\n",
        "    segmenter = UNet(device, encoder=encoder)\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.init(project=\"LiverSegmentationJointTraining\",\n",
        "                name=\"Weights:\",\n",
        "                config={\n",
        "                    \"BatchSize\":batchSize,\n",
        "                    \"LearnRate\":learnRate,\n",
        "                    \"Epochs\":epochs,\n",
        "                    \"StartDimension\":startDim,\n",
        "                    \"EpochsToDouble\":epochsToDouble\n",
        "                })\n",
        "\n",
        "    classLossFunc = LossFunctions.FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n",
        "\n",
        "    lossFuncs = [[LossFunctions.dice_score, LossFunctions.dice_loss], [LossFunctions.accuracy, classLossFunc]]\n",
        "    weights = [[0, 0.6], [0, 0.4]]\n",
        "\n",
        "    TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "        cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive)\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Contrastive Pre-Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "contTrainDataset = LITSContDataset(\"Datasets/ContrastiveDatasets/ScanBased/RandContrastiveTrainDataset.hdf5\")\n",
        "contValDataset = LITSContDataset(\"Datasets/ContrastiveDatasets/ScanBased/RandContrastiveValidationDataset.hdf5\")\n",
        "contTestDataset = LITSContDataset(\"Datasets/ContrastiveDatasets/ScanBased/RandContrastiveTestDataset.hdf5\")\n",
        "\n",
        "contTrainIter = DataLoader(contTrainDataset, batch_size=batchSize, shuffle=True)\n",
        "contValidationIter = DataLoader(contValDataset, batch_size=batchSize)\n",
        "contTestIter = DataLoader(contTestDataset, batch_size=batchSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in tqdm(range(10)):\n",
        "    modelName = \"RandContrastiveEncoder\" + str(i)\n",
        "    modelFile = \"UsedModels/\" + modelName\n",
        "    encoder = ContrastiveEncoder()\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.init(project=\"LITSEncoderContrastive\",\n",
        "                name=\"Weights:\",\n",
        "                config={\n",
        "                    \"BatchSize\":batchSize,\n",
        "                    \"LearnRate\":learnRate,\n",
        "                    \"Epochs\":epochs,\n",
        "                    \"StartDimension\":startDim,\n",
        "                    \"EpochsToDouble\":epochsToDouble\n",
        "                })\n",
        "        \n",
        "    #lossFunc = LossFunctions.ContrastiveLossEuclidean\n",
        "    lossFunc = LossFunctions.ContrastiveLossCosine(temp=(1 / batchSize))\n",
        "\n",
        "    TrainingEval.contrastiveTrain(encoder, lossFunc, contTrainIter, contValidationIter, epochs, startEpoch, learnRate, device, modelFile, epochsToSave, useWandB=useWandB, \n",
        "        cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, isDist=False)\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.finish()\n",
        "\n",
        "    print(\"Model: \" + str(i) + \" finished\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "initEncoder = \"ContrastiveTest/ContrastiveTest1Encoder\"\n",
        "\n",
        "encoder = ContrastiveEncoder()\n",
        "encoder.load_state_dict(torch.load(initEncoder), strict=False)\n",
        "\n",
        "segmenter = UNet(device, encoder=encoder)\n",
        "#segmenter.freezeEncoder()\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UsedModels/RandContFineTune5\n",
            "Training on cuda\n",
            "Epoch 0:\n",
            "Train Loss: 0.8849958181381226 Validation Loss: 0.9758964776992798 dice_loss: tensor(0.9759, device='cuda:0') dice_score: tensor(0.0711, device='cuda:0') \n",
            "Epoch 1:\n",
            "Train Loss: 0.826005220413208 Validation Loss: 0.96075040102005 dice_loss: tensor(0.9608, device='cuda:0') dice_score: tensor(0.0777, device='cuda:0') \n",
            "Epoch 2:\n",
            "Train Loss: 0.7761727571487427 Validation Loss: 0.9325522780418396 dice_loss: tensor(0.9326, device='cuda:0') dice_score: tensor(0.1660, device='cuda:0') \n",
            "Epoch 3:\n",
            "Train Loss: 0.7367934584617615 Validation Loss: 0.9049058556556702 dice_loss: tensor(0.9049, device='cuda:0') dice_score: tensor(0.1931, device='cuda:0') \n",
            "Epoch 4:\n",
            "Train Loss: 0.7085496783256531 Validation Loss: 0.8832738995552063 dice_loss: tensor(0.8833, device='cuda:0') dice_score: tensor(0.2010, device='cuda:0') \n",
            "Epoch 5:\n",
            "Train Loss: 0.6881203651428223 Validation Loss: 0.8756838440895081 dice_loss: tensor(0.8757, device='cuda:0') dice_score: tensor(0.1809, device='cuda:0') \n",
            "Epoch 6:\n",
            "Train Loss: 0.6761708855628967 Validation Loss: 0.8573693633079529 dice_loss: tensor(0.8574, device='cuda:0') dice_score: tensor(0.2183, device='cuda:0') \n",
            "Epoch 7:\n",
            "Train Loss: 0.6684284806251526 Validation Loss: 0.852599024772644 dice_loss: tensor(0.8526, device='cuda:0') dice_score: tensor(0.2158, device='cuda:0') \n",
            "Epoch 8:\n",
            "Train Loss: 0.6648423671722412 Validation Loss: 0.8493791222572327 dice_loss: tensor(0.8494, device='cuda:0') dice_score: tensor(0.2183, device='cuda:0') \n",
            "Epoch 9:\n",
            "Train Loss: 0.6637622714042664 Validation Loss: 0.8490650653839111 dice_loss: tensor(0.8491, device='cuda:0') dice_score: tensor(0.2168, device='cuda:0') \n",
            "Epoch 10:\n",
            "Train Loss: 0.6728213429450989 Validation Loss: 0.850981593132019 dice_loss: tensor(0.8510, device='cuda:0') dice_score: tensor(0.1823, device='cuda:0') \n",
            "Epoch 11:\n",
            "Train Loss: 0.6443821787834167 Validation Loss: 0.8182967901229858 dice_loss: tensor(0.8183, device='cuda:0') dice_score: tensor(0.2172, device='cuda:0') \n",
            "Epoch 12:\n",
            "Train Loss: 0.6282875537872314 Validation Loss: 0.8114549517631531 dice_loss: tensor(0.8115, device='cuda:0') dice_score: tensor(0.2151, device='cuda:0') \n",
            "Epoch 13:\n",
            "Train Loss: 0.6200459003448486 Validation Loss: 0.7987950444221497 dice_loss: tensor(0.7988, device='cuda:0') dice_score: tensor(0.2222, device='cuda:0') \n",
            "Epoch 14:\n",
            "Train Loss: 0.6118878126144409 Validation Loss: 0.7947497963905334 dice_loss: tensor(0.7947, device='cuda:0') dice_score: tensor(0.2218, device='cuda:0') \n",
            "Epoch 15:\n",
            "Train Loss: 0.6027955412864685 Validation Loss: 0.7921316027641296 dice_loss: tensor(0.7921, device='cuda:0') dice_score: tensor(0.2222, device='cuda:0') \n",
            "Epoch 16:\n",
            "Train Loss: 0.6003977656364441 Validation Loss: 0.7892890572547913 dice_loss: tensor(0.7893, device='cuda:0') dice_score: tensor(0.2242, device='cuda:0') \n",
            "Epoch 17:\n",
            "Train Loss: 0.597686767578125 Validation Loss: 0.7868664264678955 dice_loss: tensor(0.7869, device='cuda:0') dice_score: tensor(0.2269, device='cuda:0') \n",
            "Epoch 18:\n",
            "Train Loss: 0.5973688960075378 Validation Loss: 0.7865261435508728 dice_loss: tensor(0.7865, device='cuda:0') dice_score: tensor(0.2264, device='cuda:0') \n",
            "Epoch 19:\n",
            "Train Loss: 0.5971688628196716 Validation Loss: 0.7874119281768799 dice_loss: tensor(0.7874, device='cuda:0') dice_score: tensor(0.2251, device='cuda:0') \n",
            "Epoch 20:\n",
            "Train Loss: 0.6088905334472656 Validation Loss: 0.7998268008232117 dice_loss: tensor(0.7998, device='cuda:0') dice_score: tensor(0.2078, device='cuda:0') \n",
            "Epoch 21:\n",
            "Train Loss: 0.5968304872512817 Validation Loss: 0.7828423976898193 dice_loss: tensor(0.7828, device='cuda:0') dice_score: tensor(0.2248, device='cuda:0') \n",
            "Epoch 22:\n",
            "Train Loss: 0.5873663425445557 Validation Loss: 0.7806503176689148 dice_loss: tensor(0.7807, device='cuda:0') dice_score: tensor(0.2253, device='cuda:0') \n",
            "Epoch 23:\n",
            "Train Loss: 0.5805060267448425 Validation Loss: 0.7786400318145752 dice_loss: tensor(0.7786, device='cuda:0') dice_score: tensor(0.2259, device='cuda:0') \n",
            "Epoch 24:\n",
            "Train Loss: 0.5775548219680786 Validation Loss: 0.7773399949073792 dice_loss: tensor(0.7773, device='cuda:0') dice_score: tensor(0.2270, device='cuda:0') \n",
            "Epoch 25:\n",
            "Train Loss: 0.5745434761047363 Validation Loss: 0.7753892540931702 dice_loss: tensor(0.7754, device='cuda:0') dice_score: tensor(0.2285, device='cuda:0') \n",
            "Epoch 26:\n",
            "Train Loss: 0.5711519122123718 Validation Loss: 0.774738609790802 dice_loss: tensor(0.7747, device='cuda:0') dice_score: tensor(0.2288, device='cuda:0') \n",
            "Epoch 27:\n",
            "Train Loss: 0.5715087652206421 Validation Loss: 0.7751953601837158 dice_loss: tensor(0.7752, device='cuda:0') dice_score: tensor(0.2280, device='cuda:0') \n",
            "Epoch 28:\n",
            "Train Loss: 0.5677089691162109 Validation Loss: 0.7746877074241638 dice_loss: tensor(0.7747, device='cuda:0') dice_score: tensor(0.2287, device='cuda:0') \n",
            "Epoch 29:\n",
            "Train Loss: 0.5677878856658936 Validation Loss: 0.7740636467933655 dice_loss: tensor(0.7741, device='cuda:0') dice_score: tensor(0.2294, device='cuda:0') \n",
            "Epoch 30:\n",
            "Train Loss: 0.5748862028121948 Validation Loss: 0.7802312970161438 dice_loss: tensor(0.7802, device='cuda:0') dice_score: tensor(0.2221, device='cuda:0') \n",
            "Epoch 31:\n",
            "Train Loss: 0.5725116729736328 Validation Loss: 0.7759799361228943 dice_loss: tensor(0.7760, device='cuda:0') dice_score: tensor(0.2261, device='cuda:0') \n",
            "Epoch 32:\n",
            "Train Loss: 0.5647078156471252 Validation Loss: 0.7740049362182617 dice_loss: tensor(0.7740, device='cuda:0') dice_score: tensor(0.2287, device='cuda:0') \n",
            "Epoch 33:\n",
            "Train Loss: 0.5630894899368286 Validation Loss: 0.7706818580627441 dice_loss: tensor(0.7707, device='cuda:0') dice_score: tensor(0.2321, device='cuda:0') \n",
            "Epoch 34:\n",
            "Train Loss: 0.5586997270584106 Validation Loss: 0.7726876735687256 dice_loss: tensor(0.7727, device='cuda:0') dice_score: tensor(0.2284, device='cuda:0') \n",
            "Epoch 35:\n",
            "Train Loss: 0.5557755827903748 Validation Loss: 0.7673371434211731 dice_loss: tensor(0.7673, device='cuda:0') dice_score: tensor(0.2346, device='cuda:0') \n",
            "Epoch 36:\n",
            "Train Loss: 0.5536159873008728 Validation Loss: 0.768968403339386 dice_loss: tensor(0.7690, device='cuda:0') dice_score: tensor(0.2328, device='cuda:0') \n",
            "Epoch 37:\n",
            "Train Loss: 0.5519019961357117 Validation Loss: 0.7644264101982117 dice_loss: tensor(0.7644, device='cuda:0') dice_score: tensor(0.2392, device='cuda:0') \n",
            "Epoch 38:\n",
            "Train Loss: 0.5522046089172363 Validation Loss: 0.7606825232505798 dice_loss: tensor(0.7607, device='cuda:0') dice_score: tensor(0.2429, device='cuda:0') \n",
            "Epoch 39:\n",
            "Train Loss: 0.5508513450622559 Validation Loss: 0.7627261877059937 dice_loss: tensor(0.7627, device='cuda:0') dice_score: tensor(0.2401, device='cuda:0') \n",
            "Epoch 40:\n",
            "Train Loss: 0.556507408618927 Validation Loss: 0.7578752636909485 dice_loss: tensor(0.7579, device='cuda:0') dice_score: tensor(0.2461, device='cuda:0') \n",
            "Epoch 41:\n",
            "Train Loss: 0.555902361869812 Validation Loss: 0.7725985050201416 dice_loss: tensor(0.7726, device='cuda:0') dice_score: tensor(0.2280, device='cuda:0') \n",
            "Epoch 42:\n",
            "Train Loss: 0.5504944324493408 Validation Loss: 0.7530855536460876 dice_loss: tensor(0.7531, device='cuda:0') dice_score: tensor(0.2791, device='cuda:0') \n",
            "Epoch 43:\n",
            "Train Loss: 0.5510579347610474 Validation Loss: 0.7627627849578857 dice_loss: tensor(0.7628, device='cuda:0') dice_score: tensor(0.2417, device='cuda:0') \n",
            "Epoch 44:\n",
            "Train Loss: 0.5446655750274658 Validation Loss: 0.6691239476203918 dice_loss: tensor(0.6691, device='cuda:0') dice_score: tensor(0.6358, device='cuda:0') \n",
            "Epoch 45:\n",
            "Train Loss: 0.5434495210647583 Validation Loss: 0.6297643780708313 dice_loss: tensor(0.6298, device='cuda:0') dice_score: tensor(0.8508, device='cuda:0') \n",
            "Epoch 46:\n",
            "Train Loss: 0.5356168746948242 Validation Loss: 0.5505583882331848 dice_loss: tensor(0.5506, device='cuda:0') dice_score: tensor(0.8811, device='cuda:0') \n",
            "Epoch 47:\n",
            "Train Loss: 0.5313755869865417 Validation Loss: 0.5359990000724792 dice_loss: tensor(0.5360, device='cuda:0') dice_score: tensor(0.9362, device='cuda:0') \n",
            "Epoch 48:\n",
            "Train Loss: 0.5292865037918091 Validation Loss: 0.5284722447395325 dice_loss: tensor(0.5285, device='cuda:0') dice_score: tensor(0.8721, device='cuda:0') \n",
            "Epoch 49:\n",
            "Train Loss: 0.5271490812301636 Validation Loss: 0.5216835737228394 dice_loss: tensor(0.5217, device='cuda:0') dice_score: tensor(0.8997, device='cuda:0') \n",
            "Epoch 50:\n",
            "Train Loss: 0.5372235178947449 Validation Loss: 0.6475094556808472 dice_loss: tensor(0.6475, device='cuda:0') dice_score: tensor(0.4627, device='cuda:0') \n",
            "Epoch 51:\n",
            "Train Loss: 0.5385118126869202 Validation Loss: 0.4415445327758789 dice_loss: tensor(0.4415, device='cuda:0') dice_score: tensor(0.8092, device='cuda:0') \n",
            "Epoch 52:\n",
            "Train Loss: 0.5224075317382812 Validation Loss: 0.3570932149887085 dice_loss: tensor(0.3571, device='cuda:0') dice_score: tensor(0.7868, device='cuda:0') \n",
            "Epoch 53:\n",
            "Train Loss: 0.5142605304718018 Validation Loss: 0.19255279004573822 dice_loss: tensor(0.1926, device='cuda:0') dice_score: tensor(0.9308, device='cuda:0') \n",
            "Epoch 54:\n",
            "Train Loss: 0.4986392855644226 Validation Loss: 0.13899847865104675 dice_loss: tensor(0.1390, device='cuda:0') dice_score: tensor(0.9501, device='cuda:0') \n",
            "Epoch 55:\n",
            "Train Loss: 0.5021119713783264 Validation Loss: 0.15270601212978363 dice_loss: tensor(0.1527, device='cuda:0') dice_score: tensor(0.9384, device='cuda:0') \n",
            "Epoch 56:\n",
            "Train Loss: 0.4836597144603729 Validation Loss: 0.09725701808929443 dice_loss: tensor(0.0973, device='cuda:0') dice_score: tensor(0.9653, device='cuda:0') \n",
            "Epoch 57:\n",
            "Train Loss: 0.4785238206386566 Validation Loss: 0.09527216106653214 dice_loss: tensor(0.0953, device='cuda:0') dice_score: tensor(0.9616, device='cuda:0') \n",
            "Epoch 58:\n",
            "Train Loss: 0.4735370874404907 Validation Loss: 0.11803369224071503 dice_loss: tensor(0.1180, device='cuda:0') dice_score: tensor(0.9326, device='cuda:0') \n",
            "Epoch 59:\n",
            "Train Loss: 0.4723605513572693 Validation Loss: 0.10428500920534134 dice_loss: tensor(0.1043, device='cuda:0') dice_score: tensor(0.9481, device='cuda:0') \n",
            "Epoch 60:\n",
            "Train Loss: 0.4740452766418457 Validation Loss: 0.4097311496734619 dice_loss: tensor(0.4097, device='cuda:0') dice_score: tensor(0.6201, device='cuda:0') \n",
            "Epoch 61:\n",
            "Train Loss: 0.4730449914932251 Validation Loss: 0.05503275990486145 dice_loss: tensor(0.0550, device='cuda:0') dice_score: tensor(0.9768, device='cuda:0') \n",
            "Epoch 62:\n",
            "Train Loss: 0.4412297010421753 Validation Loss: 0.07101435959339142 dice_loss: tensor(0.0710, device='cuda:0') dice_score: tensor(0.9544, device='cuda:0') \n",
            "Epoch 63:\n",
            "Train Loss: 0.4242013096809387 Validation Loss: 0.044035494327545166 dice_loss: tensor(0.0440, device='cuda:0') dice_score: tensor(0.9731, device='cuda:0') \n",
            "Epoch 64:\n",
            "Train Loss: 0.39448586106300354 Validation Loss: 0.06261944770812988 dice_loss: tensor(0.0626, device='cuda:0') dice_score: tensor(0.9529, device='cuda:0') \n",
            "Epoch 65:\n",
            "Train Loss: 0.36100876331329346 Validation Loss: 0.0463026762008667 dice_loss: tensor(0.0463, device='cuda:0') dice_score: tensor(0.9649, device='cuda:0') \n",
            "Epoch 66:\n",
            "Train Loss: 0.31286171078681946 Validation Loss: 0.0414094477891922 dice_loss: tensor(0.0414, device='cuda:0') dice_score: tensor(0.9639, device='cuda:0') \n",
            "Epoch 67:\n",
            "Train Loss: 0.2829629182815552 Validation Loss: 0.03917263075709343 dice_loss: tensor(0.0392, device='cuda:0') dice_score: tensor(0.9670, device='cuda:0') \n",
            "Epoch 68:\n",
            "Train Loss: 0.2620934247970581 Validation Loss: 0.036866750568151474 dice_loss: tensor(0.0369, device='cuda:0') dice_score: tensor(0.9697, device='cuda:0') \n",
            "Epoch 69:\n",
            "Train Loss: 0.25707724690437317 Validation Loss: 0.03558465838432312 dice_loss: tensor(0.0356, device='cuda:0') dice_score: tensor(0.9700, device='cuda:0') \n",
            "Epoch 70:\n",
            "Train Loss: 0.23168526589870453 Validation Loss: 0.1534229815006256 dice_loss: tensor(0.1534, device='cuda:0') dice_score: tensor(0.8501, device='cuda:0') \n",
            "Epoch 71:\n",
            "Train Loss: 0.5033562779426575 Validation Loss: 0.25047674775123596 dice_loss: tensor(0.2505, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 72:\n",
            "Train Loss: 0.6073306202888489 Validation Loss: 0.2498992383480072 dice_loss: tensor(0.2499, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 73:\n",
            "Train Loss: 0.586479663848877 Validation Loss: 0.24969612061977386 dice_loss: tensor(0.2497, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 74:\n",
            "Train Loss: 0.5741098523139954 Validation Loss: 0.2495337724685669 dice_loss: tensor(0.2495, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 75:\n",
            "Train Loss: 0.5643858313560486 Validation Loss: 0.2494407743215561 dice_loss: tensor(0.2494, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 76:\n",
            "Train Loss: 0.5574401617050171 Validation Loss: 0.24939551949501038 dice_loss: tensor(0.2494, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 77:\n",
            "Train Loss: 0.5547343492507935 Validation Loss: 0.24936038255691528 dice_loss: tensor(0.2494, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 78:\n",
            "Train Loss: 0.5561790466308594 Validation Loss: 0.24936635792255402 dice_loss: tensor(0.2494, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 79:\n",
            "Train Loss: 0.5544748902320862 Validation Loss: 0.24935278296470642 dice_loss: tensor(0.2494, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 80:\n",
            "Train Loss: 0.5508102774620056 Validation Loss: 0.24929334223270416 dice_loss: tensor(0.2493, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 81:\n",
            "Train Loss: 0.5390678644180298 Validation Loss: 0.24923661351203918 dice_loss: tensor(0.2492, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 82:\n",
            "Train Loss: 0.5330296754837036 Validation Loss: 0.2492082715034485 dice_loss: tensor(0.2492, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 83:\n",
            "Train Loss: 0.528328001499176 Validation Loss: 0.2491605579853058 dice_loss: tensor(0.2492, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 84:\n",
            "Train Loss: 0.5246826410293579 Validation Loss: 0.2491437941789627 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 85:\n",
            "Train Loss: 0.5223274827003479 Validation Loss: 0.24914021790027618 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 86:\n",
            "Train Loss: 0.5195799469947815 Validation Loss: 0.24910509586334229 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 87:\n",
            "Train Loss: 0.5197921991348267 Validation Loss: 0.2491052895784378 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 88:\n",
            "Train Loss: 0.5189129114151001 Validation Loss: 0.24909906089305878 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 89:\n",
            "Train Loss: 0.5181235671043396 Validation Loss: 0.24909785389900208 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 90:\n",
            "Train Loss: 0.5155606269836426 Validation Loss: 0.2490914762020111 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 91:\n",
            "Train Loss: 0.5105559825897217 Validation Loss: 0.24907726049423218 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 92:\n",
            "Train Loss: 0.5061601400375366 Validation Loss: 0.2490541785955429 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 93:\n",
            "Train Loss: 0.5042357444763184 Validation Loss: 0.24905914068222046 dice_loss: tensor(0.2491, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 94:\n",
            "Train Loss: 0.5029605627059937 Validation Loss: 0.2490403801202774 dice_loss: tensor(0.2490, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 95:\n",
            "Train Loss: 0.5018458962440491 Validation Loss: 0.24903184175491333 dice_loss: tensor(0.2490, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 96:\n",
            "Train Loss: 0.5005794763565063 Validation Loss: 0.24902719259262085 dice_loss: tensor(0.2490, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 97:\n",
            "Train Loss: 0.5001922249794006 Validation Loss: 0.24902182817459106 dice_loss: tensor(0.2490, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "Epoch 98:\n",
            "Train Loss: 0.49903568625450134 Validation Loss: 0.24902112782001495 dice_loss: tensor(0.2490, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [32:07<32:07, 1927.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99:\n",
            "Train Loss: 0.500690758228302 Validation Loss: 0.24902032315731049 dice_loss: tensor(0.2490, device='cuda:0') dice_score: tensor(0.7510, device='cuda:0') \n",
            "UsedModels/RandContFineTune8\n",
            "Training on cuda\n",
            "Epoch 0:\n",
            "Train Loss: 0.8926879167556763 Validation Loss: 0.9816311001777649 dice_loss: tensor(0.9816, device='cuda:0') dice_score: tensor(0.0242, device='cuda:0') \n",
            "Epoch 1:\n",
            "Train Loss: 0.8585518598556519 Validation Loss: 0.9746121168136597 dice_loss: tensor(0.9746, device='cuda:0') dice_score: tensor(0.0594, device='cuda:0') \n",
            "Epoch 2:\n",
            "Train Loss: 0.8273155689239502 Validation Loss: 0.9670119881629944 dice_loss: tensor(0.9670, device='cuda:0') dice_score: tensor(0.0621, device='cuda:0') \n",
            "Epoch 3:\n",
            "Train Loss: 0.7933850884437561 Validation Loss: 0.9526105523109436 dice_loss: tensor(0.9526, device='cuda:0') dice_score: tensor(0.1110, device='cuda:0') \n",
            "Epoch 4:\n",
            "Train Loss: 0.7647485136985779 Validation Loss: 0.9409874677658081 dice_loss: tensor(0.9410, device='cuda:0') dice_score: tensor(0.1202, device='cuda:0') \n",
            "Epoch 5:\n",
            "Train Loss: 0.7493376135826111 Validation Loss: 0.9345309138298035 dice_loss: tensor(0.9345, device='cuda:0') dice_score: tensor(0.1223, device='cuda:0') \n",
            "Epoch 6:\n",
            "Train Loss: 0.731846809387207 Validation Loss: 0.9099031090736389 dice_loss: tensor(0.9099, device='cuda:0') dice_score: tensor(0.1662, device='cuda:0') \n",
            "Epoch 7:\n",
            "Train Loss: 0.7105356454849243 Validation Loss: 0.9024263024330139 dice_loss: tensor(0.9024, device='cuda:0') dice_score: tensor(0.1721, device='cuda:0') \n",
            "Epoch 8:\n",
            "Train Loss: 0.7062898278236389 Validation Loss: 0.8960825204849243 dice_loss: tensor(0.8961, device='cuda:0') dice_score: tensor(0.1937, device='cuda:0') \n",
            "Epoch 9:\n",
            "Train Loss: 0.7019743323326111 Validation Loss: 0.8956306576728821 dice_loss: tensor(0.8956, device='cuda:0') dice_score: tensor(0.1931, device='cuda:0') \n",
            "Epoch 10:\n",
            "Train Loss: 0.7011085748672485 Validation Loss: 0.8822004795074463 dice_loss: tensor(0.8822, device='cuda:0') dice_score: tensor(0.1707, device='cuda:0') \n",
            "Epoch 11:\n",
            "Train Loss: 0.6760202050209045 Validation Loss: 0.8571351170539856 dice_loss: tensor(0.8571, device='cuda:0') dice_score: tensor(0.2016, device='cuda:0') \n",
            "Epoch 12:\n",
            "Train Loss: 0.6561228036880493 Validation Loss: 0.8432348966598511 dice_loss: tensor(0.8432, device='cuda:0') dice_score: tensor(0.2002, device='cuda:0') \n",
            "Epoch 13:\n",
            "Train Loss: 0.6458282470703125 Validation Loss: 0.8330013155937195 dice_loss: tensor(0.8330, device='cuda:0') dice_score: tensor(0.2014, device='cuda:0') \n",
            "Epoch 14:\n",
            "Train Loss: 0.6361719965934753 Validation Loss: 0.8197530508041382 dice_loss: tensor(0.8198, device='cuda:0') dice_score: tensor(0.2123, device='cuda:0') \n",
            "Epoch 15:\n",
            "Train Loss: 0.6262853145599365 Validation Loss: 0.8150902390480042 dice_loss: tensor(0.8151, device='cuda:0') dice_score: tensor(0.2141, device='cuda:0') \n",
            "Epoch 16:\n",
            "Train Loss: 0.6215535402297974 Validation Loss: 0.8102591037750244 dice_loss: tensor(0.8103, device='cuda:0') dice_score: tensor(0.2164, device='cuda:0') \n",
            "Epoch 17:\n",
            "Train Loss: 0.6189926266670227 Validation Loss: 0.807989239692688 dice_loss: tensor(0.8080, device='cuda:0') dice_score: tensor(0.2185, device='cuda:0') \n",
            "Epoch 18:\n",
            "Train Loss: 0.6149327158927917 Validation Loss: 0.8061332702636719 dice_loss: tensor(0.8061, device='cuda:0') dice_score: tensor(0.2204, device='cuda:0') \n",
            "Epoch 19:\n",
            "Train Loss: 0.6168438792228699 Validation Loss: 0.80636066198349 dice_loss: tensor(0.8064, device='cuda:0') dice_score: tensor(0.2197, device='cuda:0') \n",
            "Epoch 20:\n",
            "Train Loss: 0.6324204802513123 Validation Loss: 0.8057060837745667 dice_loss: tensor(0.8057, device='cuda:0') dice_score: tensor(0.2133, device='cuda:0') \n",
            "Epoch 21:\n",
            "Train Loss: 0.610901951789856 Validation Loss: 0.7990486025810242 dice_loss: tensor(0.7990, device='cuda:0') dice_score: tensor(0.2151, device='cuda:0') \n",
            "Epoch 22:\n",
            "Train Loss: 0.6014062762260437 Validation Loss: 0.7947884202003479 dice_loss: tensor(0.7948, device='cuda:0') dice_score: tensor(0.2183, device='cuda:0') \n",
            "Epoch 23:\n",
            "Train Loss: 0.5965986847877502 Validation Loss: 0.7900751233100891 dice_loss: tensor(0.7901, device='cuda:0') dice_score: tensor(0.2201, device='cuda:0') \n",
            "Epoch 24:\n",
            "Train Loss: 0.5904942750930786 Validation Loss: 0.7869749069213867 dice_loss: tensor(0.7870, device='cuda:0') dice_score: tensor(0.2221, device='cuda:0') \n",
            "Epoch 25:\n",
            "Train Loss: 0.5879104137420654 Validation Loss: 0.7845982909202576 dice_loss: tensor(0.7846, device='cuda:0') dice_score: tensor(0.2239, device='cuda:0') \n",
            "Epoch 26:\n",
            "Train Loss: 0.5835117101669312 Validation Loss: 0.7838159203529358 dice_loss: tensor(0.7838, device='cuda:0') dice_score: tensor(0.2239, device='cuda:0') \n",
            "Epoch 27:\n",
            "Train Loss: 0.5804591178894043 Validation Loss: 0.783967137336731 dice_loss: tensor(0.7840, device='cuda:0') dice_score: tensor(0.2235, device='cuda:0') \n",
            "Epoch 28:\n",
            "Train Loss: 0.5810787081718445 Validation Loss: 0.7857885956764221 dice_loss: tensor(0.7858, device='cuda:0') dice_score: tensor(0.2206, device='cuda:0') \n",
            "Epoch 29:\n",
            "Train Loss: 0.5814579129219055 Validation Loss: 0.7838139533996582 dice_loss: tensor(0.7838, device='cuda:0') dice_score: tensor(0.2231, device='cuda:0') \n",
            "Epoch 30:\n",
            "Train Loss: 0.5926604866981506 Validation Loss: 0.8162858486175537 dice_loss: tensor(0.8163, device='cuda:0') dice_score: tensor(0.1872, device='cuda:0') \n",
            "Epoch 31:\n",
            "Train Loss: 0.5846946835517883 Validation Loss: 0.7824321389198303 dice_loss: tensor(0.7824, device='cuda:0') dice_score: tensor(0.2222, device='cuda:0') \n",
            "Epoch 32:\n",
            "Train Loss: 0.5773622393608093 Validation Loss: 0.7836966514587402 dice_loss: tensor(0.7837, device='cuda:0') dice_score: tensor(0.2210, device='cuda:0') \n",
            "Epoch 33:\n",
            "Train Loss: 0.5716431140899658 Validation Loss: 0.7813904285430908 dice_loss: tensor(0.7814, device='cuda:0') dice_score: tensor(0.2217, device='cuda:0') \n",
            "Epoch 34:\n",
            "Train Loss: 0.5711706280708313 Validation Loss: 0.7797473073005676 dice_loss: tensor(0.7797, device='cuda:0') dice_score: tensor(0.2231, device='cuda:0') \n",
            "Epoch 35:\n",
            "Train Loss: 0.566312313079834 Validation Loss: 0.7796414494514465 dice_loss: tensor(0.7796, device='cuda:0') dice_score: tensor(0.2230, device='cuda:0') \n",
            "Epoch 36:\n",
            "Train Loss: 0.5668646097183228 Validation Loss: 0.7758632898330688 dice_loss: tensor(0.7759, device='cuda:0') dice_score: tensor(0.2269, device='cuda:0') \n",
            "Epoch 37:\n",
            "Train Loss: 0.5639213919639587 Validation Loss: 0.7758994698524475 dice_loss: tensor(0.7759, device='cuda:0') dice_score: tensor(0.2268, device='cuda:0') \n",
            "Epoch 38:\n",
            "Train Loss: 0.5624518990516663 Validation Loss: 0.7771251797676086 dice_loss: tensor(0.7771, device='cuda:0') dice_score: tensor(0.2253, device='cuda:0') \n",
            "Epoch 39:\n",
            "Train Loss: 0.5636956691741943 Validation Loss: 0.7770763039588928 dice_loss: tensor(0.7771, device='cuda:0') dice_score: tensor(0.2254, device='cuda:0') \n",
            "Epoch 40:\n",
            "Train Loss: 0.5746297240257263 Validation Loss: 0.7816489934921265 dice_loss: tensor(0.7816, device='cuda:0') dice_score: tensor(0.2206, device='cuda:0') \n",
            "Epoch 41:\n",
            "Train Loss: 0.5738821029663086 Validation Loss: 0.7771058678627014 dice_loss: tensor(0.7771, device='cuda:0') dice_score: tensor(0.2247, device='cuda:0') \n",
            "Epoch 42:\n",
            "Train Loss: 0.5634846687316895 Validation Loss: 0.7753972411155701 dice_loss: tensor(0.7754, device='cuda:0') dice_score: tensor(0.2266, device='cuda:0') \n",
            "Epoch 43:\n",
            "Train Loss: 0.5599521398544312 Validation Loss: 0.776589572429657 dice_loss: tensor(0.7766, device='cuda:0') dice_score: tensor(0.2247, device='cuda:0') \n",
            "Epoch 44:\n",
            "Train Loss: 0.5580043196678162 Validation Loss: 0.7766228318214417 dice_loss: tensor(0.7766, device='cuda:0') dice_score: tensor(0.2246, device='cuda:0') \n",
            "Epoch 45:\n",
            "Train Loss: 0.5570138692855835 Validation Loss: 0.7767353653907776 dice_loss: tensor(0.7767, device='cuda:0') dice_score: tensor(0.2244, device='cuda:0') \n",
            "Epoch 46:\n",
            "Train Loss: 0.5546585321426392 Validation Loss: 0.772698700428009 dice_loss: tensor(0.7727, device='cuda:0') dice_score: tensor(0.2287, device='cuda:0') \n",
            "Epoch 47:\n",
            "Train Loss: 0.5526221394538879 Validation Loss: 0.7731661796569824 dice_loss: tensor(0.7732, device='cuda:0') dice_score: tensor(0.2281, device='cuda:0') \n",
            "Epoch 48:\n",
            "Train Loss: 0.553905189037323 Validation Loss: 0.7732083797454834 dice_loss: tensor(0.7732, device='cuda:0') dice_score: tensor(0.2279, device='cuda:0') \n",
            "Epoch 49:\n",
            "Train Loss: 0.5527723431587219 Validation Loss: 0.7726197838783264 dice_loss: tensor(0.7726, device='cuda:0') dice_score: tensor(0.2287, device='cuda:0') \n",
            "Epoch 50:\n",
            "Train Loss: 0.5654601454734802 Validation Loss: 0.7758966684341431 dice_loss: tensor(0.7759, device='cuda:0') dice_score: tensor(0.2250, device='cuda:0') \n",
            "Epoch 51:\n",
            "Train Loss: 0.5555284023284912 Validation Loss: 0.7734313607215881 dice_loss: tensor(0.7734, device='cuda:0') dice_score: tensor(0.2278, device='cuda:0') \n",
            "Epoch 52:\n",
            "Train Loss: 0.5545685887336731 Validation Loss: 0.7751865386962891 dice_loss: tensor(0.7752, device='cuda:0') dice_score: tensor(0.2255, device='cuda:0') \n",
            "Epoch 53:\n",
            "Train Loss: 0.5520375370979309 Validation Loss: 0.7753651142120361 dice_loss: tensor(0.7754, device='cuda:0') dice_score: tensor(0.2252, device='cuda:0') \n",
            "Epoch 54:\n",
            "Train Loss: 0.5518926382064819 Validation Loss: 0.7724251747131348 dice_loss: tensor(0.7724, device='cuda:0') dice_score: tensor(0.2283, device='cuda:0') \n",
            "Epoch 55:\n",
            "Train Loss: 0.5472040176391602 Validation Loss: 0.7726911306381226 dice_loss: tensor(0.7727, device='cuda:0') dice_score: tensor(0.2280, device='cuda:0') \n",
            "Epoch 56:\n",
            "Train Loss: 0.5471174716949463 Validation Loss: 0.768639087677002 dice_loss: tensor(0.7686, device='cuda:0') dice_score: tensor(0.2322, device='cuda:0') \n",
            "Epoch 57:\n",
            "Train Loss: 0.5457514524459839 Validation Loss: 0.7688242197036743 dice_loss: tensor(0.7688, device='cuda:0') dice_score: tensor(0.2320, device='cuda:0') \n",
            "Epoch 58:\n",
            "Train Loss: 0.5453941226005554 Validation Loss: 0.7706557512283325 dice_loss: tensor(0.7707, device='cuda:0') dice_score: tensor(0.2301, device='cuda:0') \n",
            "Epoch 59:\n",
            "Train Loss: 0.5450328588485718 Validation Loss: 0.770025372505188 dice_loss: tensor(0.7700, device='cuda:0') dice_score: tensor(0.2307, device='cuda:0') \n",
            "Epoch 60:\n",
            "Train Loss: 0.5582711100578308 Validation Loss: 0.7801197171211243 dice_loss: tensor(0.7801, device='cuda:0') dice_score: tensor(0.2202, device='cuda:0') \n",
            "Epoch 61:\n",
            "Train Loss: 0.5515470504760742 Validation Loss: 0.7760184407234192 dice_loss: tensor(0.7760, device='cuda:0') dice_score: tensor(0.2245, device='cuda:0') \n",
            "Epoch 62:\n",
            "Train Loss: 0.5460805892944336 Validation Loss: 0.7731772661209106 dice_loss: tensor(0.7732, device='cuda:0') dice_score: tensor(0.2276, device='cuda:0') \n",
            "Epoch 63:\n",
            "Train Loss: 0.5508649945259094 Validation Loss: 0.7738087177276611 dice_loss: tensor(0.7738, device='cuda:0') dice_score: tensor(0.2266, device='cuda:0') \n",
            "Epoch 64:\n",
            "Train Loss: 0.5453358888626099 Validation Loss: 0.7683289051055908 dice_loss: tensor(0.7683, device='cuda:0') dice_score: tensor(0.2324, device='cuda:0') \n",
            "Epoch 65:\n",
            "Train Loss: 0.5432561039924622 Validation Loss: 0.7772702574729919 dice_loss: tensor(0.7773, device='cuda:0') dice_score: tensor(0.2231, device='cuda:0') \n",
            "Epoch 66:\n",
            "Train Loss: 0.5418500304222107 Validation Loss: 0.7664284706115723 dice_loss: tensor(0.7664, device='cuda:0') dice_score: tensor(0.2344, device='cuda:0') \n",
            "Epoch 67:\n",
            "Train Loss: 0.5411350131034851 Validation Loss: 0.7667792439460754 dice_loss: tensor(0.7668, device='cuda:0') dice_score: tensor(0.2339, device='cuda:0') \n",
            "Epoch 68:\n",
            "Train Loss: 0.5399210453033447 Validation Loss: 0.765932023525238 dice_loss: tensor(0.7659, device='cuda:0') dice_score: tensor(0.2348, device='cuda:0') \n",
            "Epoch 69:\n",
            "Train Loss: 0.5395137667655945 Validation Loss: 0.7653830647468567 dice_loss: tensor(0.7654, device='cuda:0') dice_score: tensor(0.2355, device='cuda:0') \n",
            "Epoch 70:\n",
            "Train Loss: 0.5536485910415649 Validation Loss: 0.773618221282959 dice_loss: tensor(0.7736, device='cuda:0') dice_score: tensor(0.2268, device='cuda:0') \n",
            "Epoch 71:\n",
            "Train Loss: 0.5494009852409363 Validation Loss: 0.7725950479507446 dice_loss: tensor(0.7726, device='cuda:0') dice_score: tensor(0.2276, device='cuda:0') \n",
            "Epoch 72:\n",
            "Train Loss: 0.5467758178710938 Validation Loss: 0.7693362236022949 dice_loss: tensor(0.7693, device='cuda:0') dice_score: tensor(0.2309, device='cuda:0') \n",
            "Epoch 73:\n",
            "Train Loss: 0.545304536819458 Validation Loss: 0.768349826335907 dice_loss: tensor(0.7683, device='cuda:0') dice_score: tensor(0.2325, device='cuda:0') \n",
            "Epoch 74:\n",
            "Train Loss: 0.5408101677894592 Validation Loss: 0.7660453915596008 dice_loss: tensor(0.7660, device='cuda:0') dice_score: tensor(0.2347, device='cuda:0') \n",
            "Epoch 75:\n",
            "Train Loss: 0.5388453602790833 Validation Loss: 0.7658690810203552 dice_loss: tensor(0.7659, device='cuda:0') dice_score: tensor(0.2347, device='cuda:0') \n",
            "Epoch 76:\n",
            "Train Loss: 0.5384815335273743 Validation Loss: 0.7665082812309265 dice_loss: tensor(0.7665, device='cuda:0') dice_score: tensor(0.2340, device='cuda:0') \n",
            "Epoch 77:\n",
            "Train Loss: 0.535941481590271 Validation Loss: 0.7646497488021851 dice_loss: tensor(0.7646, device='cuda:0') dice_score: tensor(0.2358, device='cuda:0') \n",
            "Epoch 78:\n",
            "Train Loss: 0.5342464447021484 Validation Loss: 0.7628794312477112 dice_loss: tensor(0.7629, device='cuda:0') dice_score: tensor(0.2380, device='cuda:0') \n",
            "Epoch 79:\n",
            "Train Loss: 0.5353400111198425 Validation Loss: 0.7626792788505554 dice_loss: tensor(0.7627, device='cuda:0') dice_score: tensor(0.2380, device='cuda:0') \n",
            "Epoch 80:\n",
            "Train Loss: 0.5437976121902466 Validation Loss: 0.7692844867706299 dice_loss: tensor(0.7693, device='cuda:0') dice_score: tensor(0.2314, device='cuda:0') \n",
            "Epoch 81:\n",
            "Train Loss: 0.5409082174301147 Validation Loss: 0.7760047316551208 dice_loss: tensor(0.7760, device='cuda:0') dice_score: tensor(0.2242, device='cuda:0') \n",
            "Epoch 82:\n",
            "Train Loss: 0.5421531200408936 Validation Loss: 0.7741118669509888 dice_loss: tensor(0.7741, device='cuda:0') dice_score: tensor(0.2261, device='cuda:0') \n",
            "Epoch 83:\n",
            "Train Loss: 0.5366050601005554 Validation Loss: 0.7620063424110413 dice_loss: tensor(0.7620, device='cuda:0') dice_score: tensor(0.2388, device='cuda:0') \n",
            "Epoch 84:\n",
            "Train Loss: 0.5354755520820618 Validation Loss: 0.7772332429885864 dice_loss: tensor(0.7772, device='cuda:0') dice_score: tensor(0.2229, device='cuda:0') \n",
            "Epoch 85:\n",
            "Train Loss: 0.5353987812995911 Validation Loss: 0.7620585560798645 dice_loss: tensor(0.7621, device='cuda:0') dice_score: tensor(0.2386, device='cuda:0') \n",
            "Epoch 86:\n",
            "Train Loss: 0.5366020202636719 Validation Loss: 0.7578239440917969 dice_loss: tensor(0.7578, device='cuda:0') dice_score: tensor(0.2442, device='cuda:0') \n",
            "Epoch 87:\n",
            "Train Loss: 0.5321507453918457 Validation Loss: 0.7568314075469971 dice_loss: tensor(0.7568, device='cuda:0') dice_score: tensor(0.2470, device='cuda:0') \n",
            "Epoch 88:\n",
            "Train Loss: 0.5312598347663879 Validation Loss: 0.7498929500579834 dice_loss: tensor(0.7499, device='cuda:0') dice_score: tensor(0.2585, device='cuda:0') \n",
            "Epoch 89:\n",
            "Train Loss: 0.5305696129798889 Validation Loss: 0.7469095587730408 dice_loss: tensor(0.7469, device='cuda:0') dice_score: tensor(0.2608, device='cuda:0') \n",
            "Epoch 90:\n",
            "Train Loss: 0.5378249287605286 Validation Loss: 0.7630200982093811 dice_loss: tensor(0.7630, device='cuda:0') dice_score: tensor(0.2518, device='cuda:0') \n",
            "Epoch 91:\n",
            "Train Loss: 0.5400328040122986 Validation Loss: 0.5923702120780945 dice_loss: tensor(0.5924, device='cuda:0') dice_score: tensor(0.5375, device='cuda:0') \n",
            "Epoch 92:\n",
            "Train Loss: 0.5340232849121094 Validation Loss: 0.197551429271698 dice_loss: tensor(0.1976, device='cuda:0') dice_score: tensor(0.9092, device='cuda:0') \n",
            "Epoch 93:\n",
            "Train Loss: 0.49144887924194336 Validation Loss: 0.12277848273515701 dice_loss: tensor(0.1228, device='cuda:0') dice_score: tensor(0.9620, device='cuda:0') \n",
            "Epoch 94:\n",
            "Train Loss: 0.48852211236953735 Validation Loss: 0.12258900701999664 dice_loss: tensor(0.1226, device='cuda:0') dice_score: tensor(0.9566, device='cuda:0') \n",
            "Epoch 95:\n",
            "Train Loss: 0.43832746148109436 Validation Loss: 0.11038100719451904 dice_loss: tensor(0.1104, device='cuda:0') dice_score: tensor(0.9504, device='cuda:0') \n",
            "Epoch 96:\n",
            "Train Loss: 0.4187205135822296 Validation Loss: 0.13072136044502258 dice_loss: tensor(0.1307, device='cuda:0') dice_score: tensor(0.9344, device='cuda:0') \n",
            "Epoch 97:\n",
            "Train Loss: 0.40625038743019104 Validation Loss: 0.11068414896726608 dice_loss: tensor(0.1107, device='cuda:0') dice_score: tensor(0.9491, device='cuda:0') \n",
            "Epoch 98:\n",
            "Train Loss: 0.3986644446849823 Validation Loss: 0.09464867413043976 dice_loss: tensor(0.0946, device='cuda:0') dice_score: tensor(0.9574, device='cuda:0') \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [1:03:52<00:00, 1916.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99:\n",
            "Train Loss: 0.39651235938072205 Validation Loss: 0.09555500000715256 dice_loss: tensor(0.0956, device='cuda:0') dice_score: tensor(0.9568, device='cuda:0') \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm([5, 8]):\n",
        "    initEncoder = \"ContrastiveModels/Unsupervised/Encoders/RandContrastiveEncoder\" + str(i)\n",
        "    modelFile = \"UsedModels/RandContFineTune\" + str(i)\n",
        "\n",
        "    print(modelFile)\n",
        "\n",
        "    encoder = ContrastiveEncoder()\n",
        "    encoder.load_state_dict(torch.load(initEncoder), strict=False)\n",
        "\n",
        "    segmenter = UNet(device, n_class=1 , encoder=encoder)\n",
        "    #segmenter.freezeEncoder()\n",
        "\n",
        "    lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "    weights = [[1, 0], []]\n",
        "\n",
        "    #Train Model\n",
        "    gc.collect()\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.init(project=\"LiverSegmentationPreTraining\",\n",
        "                name=\"NoWeights\",\n",
        "                config={\n",
        "                    \"BatchSize\":batchSize,\n",
        "                    \"LearnRate\":learnRate,\n",
        "                    \"Epochs\":epochs,\n",
        "                    \"StartDimension\":startDim,\n",
        "                    \"EpochsToDouble\":epochsToDouble\n",
        "                })\n",
        "\n",
        "    TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "        cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0)\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in tqdm(range(10)):\n",
        "    initEncoder = \"ContrastiveModels/Unsupervised/Encoders/RandContrastiveEncoder\" + str(i)\n",
        "    modelFile = \"UsedModels/RandContFineTuneMultiClass\" + str(i)\n",
        "\n",
        "    print(modelFile)\n",
        "\n",
        "    encoder = ContrastiveEncoder()\n",
        "    encoder.load_state_dict(torch.load(initEncoder), strict=False)\n",
        "\n",
        "    segmenter = UNet(device, n_class=2, encoder=encoder)\n",
        "    #segmenter.freezeEncoder()\n",
        "\n",
        "    lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "    weights = [[1, 0], []]\n",
        "\n",
        "    #Train Model\n",
        "    gc.collect()\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.init(project=\"LiverSegmentationPreTraining\",\n",
        "                name=\"NoWeights\",\n",
        "                config={\n",
        "                    \"BatchSize\":batchSize,\n",
        "                    \"LearnRate\":learnRate,\n",
        "                    \"Epochs\":epochs,\n",
        "                    \"StartDimension\":startDim,\n",
        "                    \"EpochsToDouble\":epochsToDouble\n",
        "                })\n",
        "\n",
        "    TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "        cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0)\n",
        "\n",
        "    if useWandB:\n",
        "        wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iipij4bjp9hs"
      },
      "source": [
        "# **Evaluation/Ending**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1tLSjzH2F-Z",
        "outputId": "2f548a4b-f201-45cc-e02e-1c90911370e8"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'list' object cannot be interpreted as an integer",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\GitHub\\CTLiverSegmentation\\CTLiverSegmentation.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/CTLiverSegmentation/CTLiverSegmentation.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m([\u001b[39m4\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m9\u001b[39;49m]):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/CTLiverSegmentation/CTLiverSegmentation.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     modelName \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBaselineTotalSeg\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(q)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/CTLiverSegmentation/CTLiverSegmentation.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     classification \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
          ]
        }
      ],
      "source": [
        "for q in [4, 5, 8, 9]:\n",
        "    modelName = \"BaselineTotalSeg\" + str(q)\n",
        "    classification = False\n",
        "    modelFile = \"UsedModels/RandContFineTune\" + str(q) + \"BestLoss\"\n",
        "    classLossFunc = LossFunctions.FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n",
        "\n",
        "    lossFuncs = [[LossFunctions.dice_score, LossFunctions.hausdorff], []]\n",
        "    #lossFuncs = [[LossFunctions.dice_score, LossFunctions.hausdorff], [LossFunctions.accuracy, LossFunctions.f1]]\n",
        "\n",
        "    if classification:\n",
        "        net = encoder\n",
        "        net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "    else:\n",
        "        net = UNet(device, n_class=1, multiTask=False).to(device)\n",
        "        net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "\n",
        "    #Evaluate Model\n",
        "    print(f\"Model: {modelName}\")\n",
        "\n",
        "    losses = TrainingEval.evaluate(net, testIter, lossFuncs, device=device, encoder=classification)\n",
        "    logStr = \"\"\n",
        "    for i, arr in enumerate(losses):\n",
        "        for j, val in enumerate(arr):\n",
        "            logStr += (lossFuncs[i][j].__name__ if str(type(lossFuncs[i][j])) == \"<class 'function'>\" else type(lossFuncs[i][j]).__name__) + \": \" + str(val) + \" \"\n",
        "\n",
        "    print(logStr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelName = \"\"\n",
        "modelFile = \"UsedModels/ContrastiveTest1BestLoss\"\n",
        "\n",
        "net = ContrastiveEncoder().to(device)\n",
        "net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "\n",
        "lossFunc = LossFunctions.ContrastiveLossCosine\n",
        "\n",
        "loss = TrainingEval.contrastiveEval(net, contTestIter, lossFunc, device=device, isDist=False)\n",
        "print(str(lossFunc) + \" \" + str(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI_1aq7_VJ01"
      },
      "outputs": [],
      "source": [
        "#modelFile = \"Run 2/Standard Pre-Training/PretrainedUNet7\"\n",
        "modelFile = \"Run 2/Standard Pre-Training/PretrainedUNet6\"\n",
        "dataset = LITSBinaryDataset(\"Datasets/Scan1Dataset.hdf5\")\n",
        "iter = DataLoader(dataset, batch_size=batchSize)\n",
        "\n",
        "net = UNet(0)\n",
        "net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "segmentationMask = TrainingEval.getMasks(net, iter, device=device)\n",
        "\n",
        "masksFile = \"PretrainMasksScan1\"\n",
        "wFile = h5py.File(masksFile, \"w\")\n",
        "\n",
        "for i, slice in enumerate(segmentationMask):\n",
        "    wFile.create_dataset(\"Slice\" + str(i), data=slice)\n",
        "\n",
        "wFile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LDAG1Pd2KXN"
      },
      "outputs": [],
      "source": [
        "#Close datasets\n",
        "trainDataset.closeFile()\n",
        "validationDataset.closeFile()\n",
        "testDataset.closeFile()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IGcZ_Vm5n5Yv",
        "6g1MsLCCoDhb",
        "6adquwMWoH0B",
        "D2RziTUxY8jV",
        "s4TpJ7zaoLed",
        "blz2NJ-mo_vJ",
        "UMT_AzWypZdL"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "ea23a5d6ea5dd6b47a6bacc48f8acbc6e91dc182fa6b25270d70228f0691131c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
