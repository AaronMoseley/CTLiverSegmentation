{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbV9155tKF7w",
        "outputId": "2f70abef-f597-48fe-b05a-60e8f6a0399d"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UySZvCsHhycT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\amose\\anaconda3\\envs\\MedicalImaging\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "#from torchsummary import summary\n",
        "import gc\n",
        "import h5py\n",
        "from UNet import UNet, Encoder\n",
        "from LITSDataset import LITSBinaryDataset\n",
        "import LossFunctions\n",
        "import TrainingEval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tbHyODbs1XNH"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters and training modifications\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "modelName = \"MultiTaskW=0.9-0.1,T=0\"\n",
        "modelFile = \"UsedModels/\" + modelName\n",
        "configFile = \"Run 2\\Joint Training Models\\jointConfigRun2.txt\"\n",
        "\n",
        "startEpoch = 0\n",
        "useWandB = 0\n",
        "batchSize = 0\n",
        "learnRate = 0\n",
        "epochs = 0\n",
        "startDim = 0\n",
        "epochsToDouble = 0\n",
        "progressive = 0\n",
        "epochsToSave = 0\n",
        "cosineAnnealing = 0\n",
        "cosineRestartEpochs = 0\n",
        "\n",
        "varDict = {\n",
        "    \"startEpoch\":startEpoch,\n",
        "    \"useWandB\":useWandB,\n",
        "    \"batchSize\":batchSize,\n",
        "    \"learnRate\":learnRate,\n",
        "    \"epochs\":epochs,\n",
        "    \"startDim\":startDim,\n",
        "    \"epochsToDouble\":epochsToDouble,\n",
        "    \"progressive\":progressive,\n",
        "    \"epochsToSave\":epochsToSave,\n",
        "    \"cosineAnnealing\":cosineAnnealing,\n",
        "    \"cosineRestartEpochs\":cosineRestartEpochs,\n",
        "}\n",
        "\n",
        "TrainingEval.ParseConfig(configFile, varDict)\n",
        "\n",
        "for key in varDict:\n",
        "    if varDict[key].is_integer():\n",
        "        locals()[key] = int(varDict[key])\n",
        "    else:\n",
        "        locals()[key] = varDict[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0JenAeF1rFu",
        "outputId": "cfa27150-7236-40f2-ac04-f7babcee52a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets loaded\n"
          ]
        }
      ],
      "source": [
        "#Load Datasets\n",
        "trainDataset = LITSBinaryDataset(\"Datasets/FullTrainDataset.hdf5\")\n",
        "validationDataset = LITSBinaryDataset(\"Datasets/ValidationDataset.hdf5\")\n",
        "testDataset = LITSBinaryDataset(\"Datasets/TestDataset.hdf5\")\n",
        "\n",
        "trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "validationIter = DataLoader(validationDataset, batch_size=batchSize)\n",
        "testIter = DataLoader(testDataset, batch_size=batchSize)\n",
        "\n",
        "print(\"Datasets loaded\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "blz2NJ-mo_vJ"
      },
      "source": [
        "# **Standard Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvELD2iw1fgj",
        "outputId": "f177e2e7-9382-4335-f9b2-247aed63209b"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "initModel = \"\"\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]\n",
        "\n",
        "segmenter = UNet(1)\n",
        "#print(summary(net, (1, 256, 256)))\n",
        "\n",
        "#Loads model from file if using a pretrained version\n",
        "if initModel != \"\":\n",
        "    segmenter.load_state_dict(torch.load(initModel))\n",
        "\n",
        "segmenter = segmenter.to(device)\n",
        "\n",
        "print(\"Intialized standard UNet model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YVz5cMohycW"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentation\",\n",
        "            name=modelName,\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UMT_AzWypZdL"
      },
      "source": [
        "# **Pre-Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsMuX0NYpYxZ"
      },
      "outputs": [],
      "source": [
        "focal = LossFunctions.FocalLoss(weight0=0.1, weight1=0.9, gamma=2)\n",
        "\n",
        "lossFuncs = [[], [focal, LossFunctions.accuracy, LossFunctions.f1]]\n",
        "weights = [[], [1, 0, 0]]\n",
        "\n",
        "initEncoder = \"Run 2/Progressive Encoders/ProgEncoder10\"\n",
        "encoderFile = \"UsedModels/Encoder1\"\n",
        "\n",
        "encoder = Encoder(1)\n",
        "\n",
        "if initEncoder != \"\":\n",
        "    encoder.load_state_dict(torch.load(initEncoder))\n",
        "\n",
        "encoder = encoder.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR1JX1AeqQAO"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "gc.collect()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"PreTrainedEncoder\",\n",
        "            name=\"UNetEncoder\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble,\n",
        "            })\n",
        "\n",
        "print(TrainingEval.train(encoder, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, encoderFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive, encoder=True))\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLEB6MZfqk4d"
      },
      "outputs": [],
      "source": [
        "segmenter = UNet(encoder=encoder)\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti-Rck8Xq3sj"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "gc.collect()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentationPreTraining\",\n",
        "            name=\"NoWeights\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JH2TvySW9ux8"
      },
      "source": [
        "# **Joint Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "st2leTac4VsP",
        "outputId": "0ee0bbc1-6d44-4e32-8cfa-d737f988c191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda\n",
            "Epoch 0:\n",
            "Train Loss: 0.5339672565460205 Validation Loss: 0.19579926133155823 dice_score: tensor(0.7880, device='cuda:0') dice_loss: tensor(0.2510, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0303, device='cuda:0') \n",
            "Epoch 1:\n",
            "Train Loss: 0.2571074068546295 Validation Loss: 0.17080852389335632 dice_score: tensor(0.8468, device='cuda:0') dice_loss: tensor(0.2193, device='cuda:0') accuracy: 0.95 FocalLoss: tensor(0.0252, device='cuda:0') \n",
            "Epoch 2:\n",
            "Train Loss: 0.20737643539905548 Validation Loss: 0.6549866199493408 dice_score: tensor(0.2321, device='cuda:0') dice_loss: tensor(0.8509, device='cuda:0') accuracy: 0.3233333333333333 FocalLoss: tensor(0.0671, device='cuda:0') \n",
            "Epoch 3:\n",
            "Train Loss: 0.1805156022310257 Validation Loss: 0.14314082264900208 dice_score: tensor(0.8839, device='cuda:0') dice_loss: tensor(0.1830, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0237, device='cuda:0') \n",
            "Epoch 4:\n",
            "Train Loss: 0.15399819612503052 Validation Loss: 0.10647646337747574 dice_score: tensor(0.9299, device='cuda:0') dice_loss: tensor(0.1324, device='cuda:0') accuracy: 0.9533333333333335 FocalLoss: tensor(0.0288, device='cuda:0') \n",
            "Epoch 5:\n",
            "Train Loss: 0.13758006691932678 Validation Loss: 0.1452205330133438 dice_score: tensor(0.8606, device='cuda:0') dice_loss: tensor(0.1860, device='cuda:0') accuracy: 0.9 FocalLoss: tensor(0.0228, device='cuda:0') \n",
            "Epoch 6:\n",
            "Train Loss: 0.12295062094926834 Validation Loss: 0.09137740731239319 dice_score: tensor(0.9337, device='cuda:0') dice_loss: tensor(0.1126, device='cuda:0') accuracy: 0.9566666666666667 FocalLoss: tensor(0.0277, device='cuda:0') \n",
            "Epoch 7:\n",
            "Train Loss: 0.11366831511259079 Validation Loss: 0.10024404525756836 dice_score: tensor(0.9219, device='cuda:0') dice_loss: tensor(0.1125, device='cuda:0') accuracy: 0.9300000000000002 FocalLoss: tensor(0.0634, device='cuda:0') \n",
            "Epoch 8:\n",
            "Train Loss: 0.1035529226064682 Validation Loss: 0.08995217084884644 dice_score: tensor(0.9305, device='cuda:0') dice_loss: tensor(0.1046, device='cuda:0') accuracy: 0.9433333333333332 FocalLoss: tensor(0.0459, device='cuda:0') \n",
            "Epoch 9:\n",
            "Train Loss: 0.10074460506439209 Validation Loss: 0.08835919201374054 dice_score: tensor(0.9328, device='cuda:0') dice_loss: tensor(0.1027, device='cuda:0') accuracy: 0.9433333333333332 FocalLoss: tensor(0.0455, device='cuda:0') \n",
            "Epoch 10:\n",
            "Train Loss: 0.13351140916347504 Validation Loss: 0.08146241307258606 dice_score: tensor(0.9189, device='cuda:0') dice_loss: tensor(0.1038, device='cuda:0') accuracy: 0.9633333333333333 FocalLoss: tensor(0.0146, device='cuda:0') \n",
            "Epoch 11:\n",
            "Train Loss: 0.10868130624294281 Validation Loss: 0.07490330934524536 dice_score: tensor(0.9271, device='cuda:0') dice_loss: tensor(0.0868, device='cuda:0') accuracy: 0.9333333333333335 FocalLoss: tensor(0.0394, device='cuda:0') \n",
            "Epoch 12:\n",
            "Train Loss: 0.0882893055677414 Validation Loss: 0.08199264854192734 dice_score: tensor(0.9080, device='cuda:0') dice_loss: tensor(0.1037, device='cuda:0') accuracy: 0.9266666666666667 FocalLoss: tensor(0.0168, device='cuda:0') \n",
            "Epoch 13:\n",
            "Train Loss: 0.07855959236621857 Validation Loss: 0.060110904276371 dice_score: tensor(0.9381, device='cuda:0') dice_loss: tensor(0.0690, device='cuda:0') accuracy: 0.95 FocalLoss: tensor(0.0336, device='cuda:0') \n",
            "Epoch 14:\n",
            "Train Loss: 0.06852518767118454 Validation Loss: 0.07360830157995224 dice_score: tensor(0.9261, device='cuda:0') dice_loss: tensor(0.0789, device='cuda:0') accuracy: 0.9333333333333335 FocalLoss: tensor(0.0577, device='cuda:0') \n",
            "Epoch 15:\n",
            "Train Loss: 0.06094716489315033 Validation Loss: 0.08537965267896652 dice_score: tensor(0.9126, device='cuda:0') dice_loss: tensor(0.0910, device='cuda:0') accuracy: 0.92 FocalLoss: tensor(0.0685, device='cuda:0') \n",
            "Epoch 16:\n",
            "Train Loss: 0.05646323040127754 Validation Loss: 0.053093187510967255 dice_score: tensor(0.9445, device='cuda:0') dice_loss: tensor(0.0604, device='cuda:0') accuracy: 0.9533333333333333 FocalLoss: tensor(0.0312, device='cuda:0') \n",
            "Epoch 17:\n",
            "Train Loss: 0.05425601825118065 Validation Loss: 0.07952834665775299 dice_score: tensor(0.9174, device='cuda:0') dice_loss: tensor(0.0856, device='cuda:0') accuracy: 0.9233333333333335 FocalLoss: tensor(0.0614, device='cuda:0') \n",
            "Epoch 18:\n",
            "Train Loss: 0.05169398710131645 Validation Loss: 0.0657610222697258 dice_score: tensor(0.9328, device='cuda:0') dice_loss: tensor(0.0707, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0511, device='cuda:0') \n",
            "Epoch 19:\n",
            "Train Loss: 0.050771892070770264 Validation Loss: 0.0660564973950386 dice_score: tensor(0.9329, device='cuda:0') dice_loss: tensor(0.0707, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0522, device='cuda:0') \n",
            "Epoch 20:\n",
            "Train Loss: 0.07961040735244751 Validation Loss: 0.07194320112466812 dice_score: tensor(0.9227, device='cuda:0') dice_loss: tensor(0.0804, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0465, device='cuda:0') \n",
            "Epoch 21:\n",
            "Train Loss: 0.06284232437610626 Validation Loss: 0.056373920291662216 dice_score: tensor(0.9371, device='cuda:0') dice_loss: tensor(0.0650, device='cuda:0') accuracy: 0.9466666666666668 FocalLoss: tensor(0.0304, device='cuda:0') \n",
            "Epoch 22:\n",
            "Train Loss: 0.05880334600806236 Validation Loss: 0.10856325179338455 dice_score: tensor(0.8931, device='cuda:0') dice_loss: tensor(0.1078, device='cuda:0') accuracy: 0.8966666666666667 FocalLoss: tensor(0.1107, device='cuda:0') \n",
            "Epoch 23:\n",
            "Train Loss: 0.04606261104345322 Validation Loss: 0.057509902864694595 dice_score: tensor(0.9399, device='cuda:0') dice_loss: tensor(0.0616, device='cuda:0') accuracy: 0.9466666666666668 FocalLoss: tensor(0.0452, device='cuda:0') \n",
            "Epoch 24:\n",
            "Train Loss: 0.04587288573384285 Validation Loss: 0.08582816272974014 dice_score: tensor(0.9144, device='cuda:0') dice_loss: tensor(0.0863, device='cuda:0') accuracy: 0.92 FocalLoss: tensor(0.0843, device='cuda:0') \n",
            "Epoch 25:\n",
            "Train Loss: 0.041360288858413696 Validation Loss: 0.09715330600738525 dice_score: tensor(0.9085, device='cuda:0') dice_loss: tensor(0.0921, device='cuda:0') accuracy: 0.9133333333333334 FocalLoss: tensor(0.1123, device='cuda:0') \n",
            "Epoch 26:\n",
            "Train Loss: 0.03817303851246834 Validation Loss: 0.07332845777273178 dice_score: tensor(0.9270, device='cuda:0') dice_loss: tensor(0.0737, device='cuda:0') accuracy: 0.9333333333333335 FocalLoss: tensor(0.0721, device='cuda:0') \n",
            "Epoch 27:\n",
            "Train Loss: 0.03544016554951668 Validation Loss: 0.06714221835136414 dice_score: tensor(0.9329, device='cuda:0') dice_loss: tensor(0.0678, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0650, device='cuda:0') \n",
            "Epoch 28:\n",
            "Train Loss: 0.034749530255794525 Validation Loss: 0.07463352382183075 dice_score: tensor(0.9272, device='cuda:0') dice_loss: tensor(0.0734, device='cuda:0') accuracy: 0.9333333333333335 FocalLoss: tensor(0.0783, device='cuda:0') \n",
            "Epoch 29:\n",
            "Train Loss: 0.03394049033522606 Validation Loss: 0.0744166225194931 dice_score: tensor(0.9276, device='cuda:0') dice_loss: tensor(0.0730, device='cuda:0') accuracy: 0.9333333333333335 FocalLoss: tensor(0.0785, device='cuda:0') \n",
            "Epoch 30:\n",
            "Train Loss: 0.05185363441705704 Validation Loss: 0.06612598896026611 dice_score: tensor(0.9299, device='cuda:0') dice_loss: tensor(0.0706, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0526, device='cuda:0') \n",
            "Epoch 31:\n",
            "Train Loss: 0.04321743920445442 Validation Loss: 0.07180622965097427 dice_score: tensor(0.9292, device='cuda:0') dice_loss: tensor(0.0712, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0735, device='cuda:0') \n",
            "Epoch 32:\n",
            "Train Loss: 0.04218791052699089 Validation Loss: 0.06987757980823517 dice_score: tensor(0.9324, device='cuda:0') dice_loss: tensor(0.0680, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0756, device='cuda:0') \n",
            "Epoch 33:\n",
            "Train Loss: 0.034421030431985855 Validation Loss: 0.06447795778512955 dice_score: tensor(0.9333, device='cuda:0') dice_loss: tensor(0.0672, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0563, device='cuda:0') \n",
            "Epoch 34:\n",
            "Train Loss: 0.03104414790868759 Validation Loss: 0.07210059463977814 dice_score: tensor(0.9310, device='cuda:0') dice_loss: tensor(0.0692, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0808, device='cuda:0') \n",
            "Epoch 35:\n",
            "Train Loss: 0.030745012685656548 Validation Loss: 0.0853467658162117 dice_score: tensor(0.9178, device='cuda:0') dice_loss: tensor(0.0824, device='cuda:0') accuracy: 0.9233333333333333 FocalLoss: tensor(0.0941, device='cuda:0') \n",
            "Epoch 36:\n",
            "Train Loss: 0.029019257053732872 Validation Loss: 0.08577413856983185 dice_score: tensor(0.9180, device='cuda:0') dice_loss: tensor(0.0822, device='cuda:0') accuracy: 0.9233333333333333 FocalLoss: tensor(0.0966, device='cuda:0') \n",
            "Epoch 37:\n",
            "Train Loss: 0.027240311726927757 Validation Loss: 0.07425082474946976 dice_score: tensor(0.9271, device='cuda:0') dice_loss: tensor(0.0731, device='cuda:0') accuracy: 0.9333333333333335 FocalLoss: tensor(0.0777, device='cuda:0') \n",
            "Epoch 38:\n",
            "Train Loss: 0.02498476579785347 Validation Loss: 0.07456044852733612 dice_score: tensor(0.9270, device='cuda:0') dice_loss: tensor(0.0732, device='cuda:0') accuracy: 0.9333333333333335 FocalLoss: tensor(0.0787, device='cuda:0') \n",
            "Epoch 39:\n",
            "Train Loss: 0.02508143149316311 Validation Loss: 0.07204985618591309 dice_score: tensor(0.9307, device='cuda:0') dice_loss: tensor(0.0695, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0796, device='cuda:0') \n",
            "Epoch 40:\n",
            "Train Loss: 0.044940050691366196 Validation Loss: 0.12919585406780243 dice_score: tensor(0.8775, device='cuda:0') dice_loss: tensor(0.1226, device='cuda:0') accuracy: 0.8800000000000001 FocalLoss: tensor(0.1489, device='cuda:0') \n",
            "Epoch 41:\n",
            "Train Loss: 0.03526553884148598 Validation Loss: 0.07320579886436462 dice_score: tensor(0.9273, device='cuda:0') dice_loss: tensor(0.0728, device='cuda:0') accuracy: 0.9333333333333335 FocalLoss: tensor(0.0743, device='cuda:0') \n",
            "Epoch 42:\n",
            "Train Loss: 0.03319389745593071 Validation Loss: 0.08588843047618866 dice_score: tensor(0.9119, device='cuda:0') dice_loss: tensor(0.0882, device='cuda:0') accuracy: 0.9166666666666667 FocalLoss: tensor(0.0790, device='cuda:0') \n",
            "Epoch 43:\n",
            "Train Loss: 0.03186763450503349 Validation Loss: 0.06436925381422043 dice_score: tensor(0.9343, device='cuda:0') dice_loss: tensor(0.0658, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0600, device='cuda:0') \n",
            "Epoch 44:\n",
            "Train Loss: 0.026856958866119385 Validation Loss: 0.07678551971912384 dice_score: tensor(0.9242, device='cuda:0') dice_loss: tensor(0.0759, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0795, device='cuda:0') \n",
            "Epoch 45:\n",
            "Train Loss: 0.024883389472961426 Validation Loss: 0.08245353400707245 dice_score: tensor(0.9218, device='cuda:0') dice_loss: tensor(0.0783, device='cuda:0') accuracy: 0.9266666666666667 FocalLoss: tensor(0.0950, device='cuda:0') \n",
            "Epoch 46:\n",
            "Train Loss: 0.024600936099886894 Validation Loss: 0.06194024905562401 dice_score: tensor(0.9367, device='cuda:0') dice_loss: tensor(0.0634, device='cuda:0') accuracy: 0.9433333333333332 FocalLoss: tensor(0.0576, device='cuda:0') \n",
            "Epoch 47:\n",
            "Train Loss: 0.02248872071504593 Validation Loss: 0.06622461974620819 dice_score: tensor(0.9343, device='cuda:0') dice_loss: tensor(0.0658, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0676, device='cuda:0') \n",
            "Epoch 48:\n",
            "Train Loss: 0.02104821614921093 Validation Loss: 0.06801676750183105 dice_score: tensor(0.9339, device='cuda:0') dice_loss: tensor(0.0662, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0736, device='cuda:0') \n",
            "Epoch 49:\n",
            "Train Loss: 0.021806934848427773 Validation Loss: 0.07120770215988159 dice_score: tensor(0.9313, device='cuda:0') dice_loss: tensor(0.0688, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0785, device='cuda:0') \n",
            "Epoch 50:\n",
            "Train Loss: 0.02718905359506607 Validation Loss: 0.07159076631069183 dice_score: tensor(0.9314, device='cuda:0') dice_loss: tensor(0.0687, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0804, device='cuda:0') \n",
            "Epoch 51:\n",
            "Train Loss: 0.03238148242235184 Validation Loss: 0.10028284788131714 dice_score: tensor(0.8989, device='cuda:0') dice_loss: tensor(0.1011, device='cuda:0') accuracy: 0.9033333333333334 FocalLoss: tensor(0.0978, device='cuda:0') \n",
            "Epoch 52:\n",
            "Train Loss: 0.032196175307035446 Validation Loss: 0.12501266598701477 dice_score: tensor(0.8811, device='cuda:0') dice_loss: tensor(0.1192, device='cuda:0') accuracy: 0.8866666666666667 FocalLoss: tensor(0.1425, device='cuda:0') \n",
            "Epoch 53:\n",
            "Train Loss: 0.027687277644872665 Validation Loss: 0.11564613878726959 dice_score: tensor(0.8806, device='cuda:0') dice_loss: tensor(0.1194, device='cuda:0') accuracy: 0.8833333333333334 FocalLoss: tensor(0.1044, device='cuda:0') \n",
            "Epoch 54:\n",
            "Train Loss: 0.02394053153693676 Validation Loss: 0.07817545533180237 dice_score: tensor(0.9247, device='cuda:0') dice_loss: tensor(0.0754, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0866, device='cuda:0') \n",
            "Epoch 55:\n",
            "Train Loss: 0.025981426239013672 Validation Loss: 0.07529245316982269 dice_score: tensor(0.9257, device='cuda:0') dice_loss: tensor(0.0743, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0783, device='cuda:0') \n",
            "Epoch 56:\n",
            "Train Loss: 0.02176542580127716 Validation Loss: 0.1043899804353714 dice_score: tensor(0.9029, device='cuda:0') dice_loss: tensor(0.0971, device='cuda:0') accuracy: 0.9066666666666667 FocalLoss: tensor(0.1263, device='cuda:0') \n",
            "Epoch 57:\n",
            "Train Loss: 0.019583286717534065 Validation Loss: 0.08879213780164719 dice_score: tensor(0.9187, device='cuda:0') dice_loss: tensor(0.0814, device='cuda:0') accuracy: 0.9233333333333335 FocalLoss: tensor(0.1111, device='cuda:0') \n",
            "Epoch 58:\n",
            "Train Loss: 0.019014552235603333 Validation Loss: 0.10621735453605652 dice_score: tensor(0.8997, device='cuda:0') dice_loss: tensor(0.1003, device='cuda:0') accuracy: 0.9033333333333333 FocalLoss: tensor(0.1240, device='cuda:0') \n",
            "Epoch 59:\n",
            "Train Loss: 0.018368467688560486 Validation Loss: 0.1003490537405014 dice_score: tensor(0.9061, device='cuda:0') dice_loss: tensor(0.0939, device='cuda:0') accuracy: 0.91 FocalLoss: tensor(0.1197, device='cuda:0') \n",
            "Epoch 60:\n",
            "Train Loss: 0.026159318163990974 Validation Loss: 0.08537590503692627 dice_score: tensor(0.9166, device='cuda:0') dice_loss: tensor(0.0837, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0904, device='cuda:0') \n",
            "Epoch 61:\n",
            "Train Loss: 0.04041937366127968 Validation Loss: 0.10374998301267624 dice_score: tensor(0.8963, device='cuda:0') dice_loss: tensor(0.1037, device='cuda:0') accuracy: 0.9 FocalLoss: tensor(0.1038, device='cuda:0') \n",
            "Epoch 62:\n",
            "Train Loss: 0.026585778221488 Validation Loss: 0.0796094685792923 dice_score: tensor(0.9238, device='cuda:0') dice_loss: tensor(0.0762, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0897, device='cuda:0') \n",
            "Epoch 63:\n",
            "Train Loss: 0.023150430992245674 Validation Loss: 0.07128926366567612 dice_score: tensor(0.9349, device='cuda:0') dice_loss: tensor(0.0652, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0897, device='cuda:0') \n",
            "Epoch 64:\n",
            "Train Loss: 0.021919744089245796 Validation Loss: 0.08026736974716187 dice_score: tensor(0.9251, device='cuda:0') dice_loss: tensor(0.0749, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0964, device='cuda:0') \n",
            "Epoch 65:\n",
            "Train Loss: 0.019773153588175774 Validation Loss: 0.0853460505604744 dice_score: tensor(0.9241, device='cuda:0') dice_loss: tensor(0.0760, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.1135, device='cuda:0') \n",
            "Epoch 66:\n",
            "Train Loss: 0.019122853875160217 Validation Loss: 0.06218414753675461 dice_score: tensor(0.9375, device='cuda:0') dice_loss: tensor(0.0625, device='cuda:0') accuracy: 0.9433333333333332 FocalLoss: tensor(0.0612, device='cuda:0') \n",
            "Epoch 67:\n",
            "Train Loss: 0.018810398876667023 Validation Loss: 0.07276661694049835 dice_score: tensor(0.9316, device='cuda:0') dice_loss: tensor(0.0685, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0857, device='cuda:0') \n",
            "Epoch 68:\n",
            "Train Loss: 0.017064888030290604 Validation Loss: 0.07256238162517548 dice_score: tensor(0.9310, device='cuda:0') dice_loss: tensor(0.0690, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0833, device='cuda:0') \n",
            "Epoch 69:\n",
            "Train Loss: 0.016897158697247505 Validation Loss: 0.07290917634963989 dice_score: tensor(0.9315, device='cuda:0') dice_loss: tensor(0.0685, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0862, device='cuda:0') \n",
            "Epoch 70:\n",
            "Train Loss: 0.02438812330365181 Validation Loss: 0.07933580875396729 dice_score: tensor(0.9251, device='cuda:0') dice_loss: tensor(0.0749, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0925, device='cuda:0') \n",
            "Epoch 71:\n",
            "Train Loss: 0.021240083500742912 Validation Loss: 0.11098337918519974 dice_score: tensor(0.9004, device='cuda:0') dice_loss: tensor(0.0997, device='cuda:0') accuracy: 0.9033333333333334 FocalLoss: tensor(0.1449, device='cuda:0') \n",
            "Epoch 72:\n",
            "Train Loss: 0.023404071107506752 Validation Loss: 0.07659918069839478 dice_score: tensor(0.9263, device='cuda:0') dice_loss: tensor(0.0737, device='cuda:0') accuracy: 0.9333333333333332 FocalLoss: tensor(0.0853, device='cuda:0') \n",
            "Epoch 73:\n",
            "Train Loss: 0.02078997530043125 Validation Loss: 0.10753361135721207 dice_score: tensor(0.9038, device='cuda:0') dice_loss: tensor(0.0963, device='cuda:0') accuracy: 0.9066666666666667 FocalLoss: tensor(0.1414, device='cuda:0') \n",
            "Epoch 74:\n",
            "Train Loss: 0.021685520187020302 Validation Loss: 0.04629287123680115 dice_score: tensor(0.9519, device='cuda:0') dice_loss: tensor(0.0481, device='cuda:0') accuracy: 0.9600000000000002 FocalLoss: tensor(0.0409, device='cuda:0') \n",
            "Epoch 75:\n",
            "Train Loss: 0.024398639798164368 Validation Loss: 0.07857222855091095 dice_score: tensor(0.9252, device='cuda:0') dice_loss: tensor(0.0748, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0898, device='cuda:0') \n",
            "Epoch 76:\n",
            "Train Loss: 0.01779782772064209 Validation Loss: 0.07071235030889511 dice_score: tensor(0.9318, device='cuda:0') dice_loss: tensor(0.0682, device='cuda:0') accuracy: 0.9366666666666668 FocalLoss: tensor(0.0783, device='cuda:0') \n",
            "Epoch 77:\n",
            "Train Loss: 0.017147209495306015 Validation Loss: 0.07737059891223907 dice_score: tensor(0.9253, device='cuda:0') dice_loss: tensor(0.0747, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0853, device='cuda:0') \n",
            "Epoch 78:\n",
            "Train Loss: 0.01643941178917885 Validation Loss: 0.08035611361265182 dice_score: tensor(0.9250, device='cuda:0') dice_loss: tensor(0.0750, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0963, device='cuda:0') \n",
            "Epoch 79:\n",
            "Train Loss: 0.015758587047457695 Validation Loss: 0.08029837161302567 dice_score: tensor(0.9252, device='cuda:0') dice_loss: tensor(0.0748, device='cuda:0') accuracy: 0.93 FocalLoss: tensor(0.0968, device='cuda:0') \n",
            "Epoch 80:\n",
            "Train Loss: 0.02387499436736107 Validation Loss: 0.09265518933534622 dice_score: tensor(0.9125, device='cuda:0') dice_loss: tensor(0.0875, device='cuda:0') accuracy: 0.9166666666666667 FocalLoss: tensor(0.1082, device='cuda:0') \n",
            "Epoch 81:\n",
            "Train Loss: 0.02106694132089615 Validation Loss: 0.10228020697832108 dice_score: tensor(0.9073, device='cuda:0') dice_loss: tensor(0.0927, device='cuda:0') accuracy: 0.9133333333333333 FocalLoss: tensor(0.1311, device='cuda:0') \n",
            "Epoch 82:\n",
            "Train Loss: 0.022794965654611588 Validation Loss: 0.14198777079582214 dice_score: tensor(0.8708, device='cuda:0') dice_loss: tensor(0.1292, device='cuda:0') accuracy: 0.8733333333333334 FocalLoss: tensor(0.1804, device='cuda:0') \n",
            "Epoch 83:\n",
            "Train Loss: 0.018864138051867485 Validation Loss: 0.08241033554077148 dice_score: tensor(0.9165, device='cuda:0') dice_loss: tensor(0.0835, device='cuda:0') accuracy: 0.9266666666666667 FocalLoss: tensor(0.0790, device='cuda:0') \n",
            "Epoch 84:\n",
            "Train Loss: 0.01817401871085167 Validation Loss: 0.0658097192645073 dice_score: tensor(0.9350, device='cuda:0') dice_loss: tensor(0.0650, device='cuda:0') accuracy: 0.94 FocalLoss: tensor(0.0681, device='cuda:0') \n",
            "Epoch 85:\n",
            "Train Loss: 0.017599986866116524 Validation Loss: 0.10748612880706787 dice_score: tensor(0.9034, device='cuda:0') dice_loss: tensor(0.0966, device='cuda:0') accuracy: 0.9066666666666667 FocalLoss: tensor(0.1402, device='cuda:0') \n",
            "Epoch 86:\n",
            "Train Loss: 0.01658775471150875 Validation Loss: 0.07714968174695969 dice_score: tensor(0.9219, device='cuda:0') dice_loss: tensor(0.0781, device='cuda:0') accuracy: 0.9266666666666667 FocalLoss: tensor(0.0743, device='cuda:0') \n",
            "Epoch 87:\n",
            "Train Loss: 0.014852446503937244 Validation Loss: 0.09198100119829178 dice_score: tensor(0.9127, device='cuda:0') dice_loss: tensor(0.0873, device='cuda:0') accuracy: 0.9166666666666667 FocalLoss: tensor(0.1059, device='cuda:0') \n",
            "Epoch 88:\n",
            "Train Loss: 0.014754614792764187 Validation Loss: 0.0873243659734726 dice_score: tensor(0.9125, device='cuda:0') dice_loss: tensor(0.0876, device='cuda:0') accuracy: 0.9166666666666667 FocalLoss: tensor(0.0866, device='cuda:0') \n",
            "Epoch 89:\n",
            "Train Loss: 0.01463775709271431 Validation Loss: 0.08729852735996246 dice_score: tensor(0.9125, device='cuda:0') dice_loss: tensor(0.0875, device='cuda:0') accuracy: 0.9166666666666667 FocalLoss: tensor(0.0866, device='cuda:0') \n",
            "Epoch 90:\n",
            "Train Loss: 0.02221689559519291 Validation Loss: 0.09803071618080139 dice_score: tensor(0.9088, device='cuda:0') dice_loss: tensor(0.0912, device='cuda:0') accuracy: 0.9133333333333333 FocalLoss: tensor(0.1184, device='cuda:0') \n",
            "Epoch 91:\n",
            "Train Loss: 0.024453124031424522 Validation Loss: 0.0621790885925293 dice_score: tensor(0.9353, device='cuda:0') dice_loss: tensor(0.0648, device='cuda:0') accuracy: 0.9433333333333332 FocalLoss: tensor(0.0545, device='cuda:0') \n",
            "Epoch 92:\n",
            "Train Loss: 0.022164780646562576 Validation Loss: 0.06429864466190338 dice_score: tensor(0.9341, device='cuda:0') dice_loss: tensor(0.0659, device='cuda:0') accuracy: 0.9400000000000002 FocalLoss: tensor(0.0595, device='cuda:0') \n",
            "Epoch 93:\n",
            "Train Loss: 0.020637543871998787 Validation Loss: 0.10773012042045593 dice_score: tensor(0.9043, device='cuda:0') dice_loss: tensor(0.0957, device='cuda:0') accuracy: 0.9100000000000001 FocalLoss: tensor(0.1438, device='cuda:0') \n",
            "Epoch 94:\n",
            "Train Loss: 0.019950538873672485 Validation Loss: 0.09537285566329956 dice_score: tensor(0.9094, device='cuda:0') dice_loss: tensor(0.0906, device='cuda:0') accuracy: 0.9133333333333334 FocalLoss: tensor(0.1097, device='cuda:0') \n",
            "Epoch 95:\n",
            "Train Loss: 0.01501199696213007 Validation Loss: 0.0873258113861084 dice_score: tensor(0.9163, device='cuda:0') dice_loss: tensor(0.0837, device='cuda:0') accuracy: 0.92 FocalLoss: tensor(0.0981, device='cuda:0') \n",
            "Epoch 96:\n",
            "Train Loss: 0.015432528220117092 Validation Loss: 0.06780931353569031 dice_score: tensor(0.9323, device='cuda:0') dice_loss: tensor(0.0677, device='cuda:0') accuracy: 0.9400000000000002 FocalLoss: tensor(0.0682, device='cuda:0') \n",
            "Epoch 97:\n",
            "Train Loss: 0.014317374676465988 Validation Loss: 0.07813063263893127 dice_score: tensor(0.9221, device='cuda:0') dice_loss: tensor(0.0779, device='cuda:0') accuracy: 0.9266666666666667 FocalLoss: tensor(0.0788, device='cuda:0') \n",
            "Epoch 98:\n",
            "Train Loss: 0.013586273416876793 Validation Loss: 0.08576688915491104 dice_score: tensor(0.9155, device='cuda:0') dice_loss: tensor(0.0845, device='cuda:0') accuracy: 0.92 FocalLoss: tensor(0.0895, device='cuda:0') \n",
            "Epoch 99:\n",
            "Train Loss: 0.013144063763320446 Validation Loss: 0.08577112853527069 dice_score: tensor(0.9157, device='cuda:0') dice_loss: tensor(0.0843, device='cuda:0') accuracy: 0.92 FocalLoss: tensor(0.0902, device='cuda:0') \n"
          ]
        }
      ],
      "source": [
        "segmenter = UNet(device, multiTask=True, classThreshold=0, segmentThreshold=0)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentationJointTraining\",\n",
        "            name=\"Weights:\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "classLossFunc = LossFunctions.FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_score, LossFunctions.dice_loss], [LossFunctions.accuracy, classLossFunc]]\n",
        "weights = [[0, 0.75], [0, 0.25]]\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iipij4bjp9hs"
      },
      "source": [
        "# **Evaluation/Ending**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1tLSjzH2F-Z",
        "outputId": "2f548a4b-f201-45cc-e02e-1c90911370e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \n",
            "dice_score: tensor(0.8886, device='cuda:0') hausdorff: 13.689741821647782 accuracy: 0.9280303030303029 f1: 0.0 \n"
          ]
        }
      ],
      "source": [
        "modelName = \"\"\n",
        "classification = False\n",
        "modelFile = \"UsedModels/MultiTaskW=0.9-0.1,T=0BestLoss\"\n",
        "classLossFunc = LossFunctions.FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_score, LossFunctions.hausdorff], [LossFunctions.accuracy, LossFunctions.f1]]\n",
        "#lossFuncs = [[LossFunctions.dice_score, LossFunctions.hausdorff], [LossFunctions.accuracy, LossFunctions.f1]]\n",
        "\n",
        "if classification:\n",
        "    net = encoder\n",
        "    net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "else:\n",
        "    net = UNet(device, multiTask=True).to(device)\n",
        "    net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "\n",
        "#Evaluate Model\n",
        "print(f\"Model: {modelName}\")\n",
        "\n",
        "losses = TrainingEval.evaluate(net, testIter, lossFuncs, device=device, encoder=classification)\n",
        "logStr = \"\"\n",
        "for i, arr in enumerate(losses):\n",
        "    for j, val in enumerate(arr):\n",
        "        logStr += (lossFuncs[i][j].__name__ if str(type(lossFuncs[i][j])) == \"<class 'function'>\" else type(lossFuncs[i][j]).__name__) + \": \" + str(val) + \" \"\n",
        "\n",
        "print(logStr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI_1aq7_VJ01"
      },
      "outputs": [],
      "source": [
        "#modelFile = \"Run 2/Standard Pre-Training/PretrainedUNet7\"\n",
        "modelFile = \"Run 2/Standard Pre-Training/PretrainedUNet6\"\n",
        "dataset = LITSBinaryDataset(\"Datasets/Scan1Dataset.hdf5\")\n",
        "iter = DataLoader(dataset, batch_size=batchSize)\n",
        "\n",
        "net = UNet(0)\n",
        "net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "segmentationMask = TrainingEval.getMasks(net, iter, device=device)\n",
        "\n",
        "masksFile = \"PretrainMasksScan1\"\n",
        "wFile = h5py.File(masksFile, \"w\")\n",
        "\n",
        "for i, slice in enumerate(segmentationMask):\n",
        "    wFile.create_dataset(\"Slice\" + str(i), data=slice)\n",
        "\n",
        "wFile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LDAG1Pd2KXN"
      },
      "outputs": [],
      "source": [
        "#Close datasets\n",
        "trainDataset.closeFile()\n",
        "validationDataset.closeFile()\n",
        "testDataset.closeFile()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IGcZ_Vm5n5Yv",
        "6g1MsLCCoDhb",
        "6adquwMWoH0B",
        "D2RziTUxY8jV",
        "s4TpJ7zaoLed",
        "blz2NJ-mo_vJ",
        "UMT_AzWypZdL"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "ea23a5d6ea5dd6b47a6bacc48f8acbc6e91dc182fa6b25270d70228f0691131c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
