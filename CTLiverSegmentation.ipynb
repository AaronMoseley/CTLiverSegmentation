{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbV9155tKF7w",
        "outputId": "2f70abef-f597-48fe-b05a-60e8f6a0399d"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UySZvCsHhycT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "#from torchsummary import summary\n",
        "import gc\n",
        "import h5py\n",
        "from UNet import UNet, Encoder, ContrastiveEncoder\n",
        "from LITSDataset import LITSBinaryDataset, LITSContDataset\n",
        "import LossFunctions\n",
        "import TrainingEval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tbHyODbs1XNH"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters and training modifications\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "modelName = \"ContFineTune8\"\n",
        "modelFile = \"UsedModels/\" + modelName\n",
        "configFile = \"testConfig.txt\"\n",
        "\n",
        "startEpoch = 0\n",
        "useWandB = 0\n",
        "batchSize = 0\n",
        "learnRate = 0\n",
        "epochs = 0\n",
        "startDim = 0\n",
        "epochsToDouble = 0\n",
        "progressive = 0\n",
        "epochsToSave = 0\n",
        "cosineAnnealing = 0\n",
        "cosineRestartEpochs = 0\n",
        "\n",
        "varDict = {\n",
        "    \"startEpoch\":startEpoch,\n",
        "    \"useWandB\":useWandB,\n",
        "    \"batchSize\":batchSize,\n",
        "    \"learnRate\":learnRate,\n",
        "    \"epochs\":epochs,\n",
        "    \"startDim\":startDim,\n",
        "    \"epochsToDouble\":epochsToDouble,\n",
        "    \"progressive\":progressive,\n",
        "    \"epochsToSave\":epochsToSave,\n",
        "    \"cosineAnnealing\":cosineAnnealing,\n",
        "    \"cosineRestartEpochs\":cosineRestartEpochs,\n",
        "}\n",
        "\n",
        "TrainingEval.ParseConfig(configFile, varDict)\n",
        "\n",
        "for key in varDict:\n",
        "    if varDict[key].is_integer():\n",
        "        locals()[key] = int(varDict[key])\n",
        "    else:\n",
        "        locals()[key] = varDict[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0JenAeF1rFu",
        "outputId": "cfa27150-7236-40f2-ac04-f7babcee52a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets loaded\n"
          ]
        }
      ],
      "source": [
        "#Load Datasets\n",
        "trainDataset = LITSBinaryDataset(\"Datasets/StandardDatasets/FullTrainDataset.hdf5\")\n",
        "validationDataset = LITSBinaryDataset(\"Datasets/StandardDatasets/ValidationDataset.hdf5\")\n",
        "testDataset = LITSBinaryDataset(\"Datasets/StandardDatasets/TestDataset.hdf5\")\n",
        "\n",
        "trainIter = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "validationIter = DataLoader(validationDataset, batch_size=batchSize)\n",
        "testIter = DataLoader(testDataset, batch_size=batchSize)\n",
        "\n",
        "print(\"Datasets loaded\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "blz2NJ-mo_vJ"
      },
      "source": [
        "# **Standard Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvELD2iw1fgj",
        "outputId": "f177e2e7-9382-4335-f9b2-247aed63209b"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "initModel = \"\"\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]\n",
        "\n",
        "segmenter = UNet(1)\n",
        "#print(summary(net, (1, 256, 256)))\n",
        "\n",
        "#Loads model from file if using a pretrained version\n",
        "if initModel != \"\":\n",
        "    segmenter.load_state_dict(torch.load(initModel))\n",
        "\n",
        "segmenter = segmenter.to(device)\n",
        "\n",
        "print(\"Intialized standard UNet model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YVz5cMohycW"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentation\",\n",
        "            name=modelName,\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UMT_AzWypZdL"
      },
      "source": [
        "# **Pre-Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsMuX0NYpYxZ"
      },
      "outputs": [],
      "source": [
        "focal = LossFunctions.FocalLoss(weight0=0.1, weight1=0.9, gamma=2)\n",
        "\n",
        "lossFuncs = [[], [focal, LossFunctions.accuracy, LossFunctions.f1]]\n",
        "weights = [[], [1, 0, 0]]\n",
        "\n",
        "initEncoder = \"Run 2/Progressive Encoders/ProgEncoder10\"\n",
        "encoderFile = \"UsedModels/Encoder1\"\n",
        "\n",
        "encoder = Encoder(1)\n",
        "\n",
        "if initEncoder != \"\":\n",
        "    encoder.load_state_dict(torch.load(initEncoder))\n",
        "\n",
        "encoder = encoder.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR1JX1AeqQAO"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "gc.collect()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"PreTrainedEncoder\",\n",
        "            name=\"UNetEncoder\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble,\n",
        "            })\n",
        "\n",
        "print(TrainingEval.train(encoder, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, encoderFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive, encoder=True))\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLEB6MZfqk4d"
      },
      "outputs": [],
      "source": [
        "segmenter = UNet(encoder=encoder)\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti-Rck8Xq3sj"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "gc.collect()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentationPreTraining\",\n",
        "            name=\"NoWeights\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JH2TvySW9ux8"
      },
      "source": [
        "# **Joint Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "st2leTac4VsP",
        "outputId": "0ee0bbc1-6d44-4e32-8cfa-d737f988c191"
      },
      "outputs": [],
      "source": [
        "segmenter = UNet(device, multiTask=False, classThreshold=0, segmentThreshold=0)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentationJointTraining\",\n",
        "            name=\"Weights:\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "classLossFunc = LossFunctions.FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_score, LossFunctions.dice_loss], [LossFunctions.accuracy, classLossFunc]]\n",
        "weights = [[0, 0.5], [0, 0.5]]\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=progressive)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Contrastive Pre-Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "contTrainDataset = LITSContDataset(\"Datasets/ContrastiveDatasets/ContrastiveTrainDataset.hdf5\")\n",
        "contValDataset = LITSContDataset(\"Datasets/ContrastiveDatasets/ContrastiveValidationDataset.hdf5\")\n",
        "contTestDataset = LITSContDataset(\"Datasets/ContrastiveDatasets/ContrastiveTestDataset.hdf5\")\n",
        "\n",
        "contTrainIter = DataLoader(contTrainDataset, batch_size=batchSize, shuffle=True)\n",
        "contValidationIter = DataLoader(contValDataset, batch_size=batchSize)\n",
        "contTestIter = DataLoader(contTestDataset, batch_size=batchSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = ContrastiveEncoder()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LITSEncoderContrastive\",\n",
        "            name=\"Weights:\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "    \n",
        "#lossFunc = LossFunctions.ContrastiveLossEuclidean\n",
        "lossFunc = LossFunctions.ContrastiveLossCosine(temp=(1 / batchSize))\n",
        "\n",
        "TrainingEval.contrastiveTrain(encoder, lossFunc, contTrainIter, contValidationIter, epochs, startEpoch, learnRate, device, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, isDist=False)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "initEncoder = \"ContrastiveModels/Encoders/ContrastiveEncoder8\"\n",
        "\n",
        "encoder = ContrastiveEncoder()\n",
        "encoder.load_state_dict(torch.load(initEncoder), strict=False)\n",
        "\n",
        "segmenter = UNet(device, encoder=encoder)\n",
        "#segmenter.freezeEncoder()\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_loss, LossFunctions.dice_score], []]\n",
        "weights = [[1, 0], []]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda\n",
            "Epoch 0:\n",
            "Train Loss: 0.8867751359939575 Validation Loss: 0.9789772033691406 dice_loss: tensor(0.9790, device='cuda:0') dice_score: tensor(0.0455, device='cuda:0') \n",
            "Epoch 1:\n",
            "Train Loss: 0.8459157943725586 Validation Loss: 0.9700143933296204 dice_loss: tensor(0.9700, device='cuda:0') dice_score: tensor(0.0721, device='cuda:0') \n",
            "Epoch 2:\n",
            "Train Loss: 0.8084122538566589 Validation Loss: 0.9592773914337158 dice_loss: tensor(0.9593, device='cuda:0') dice_score: tensor(0.0942, device='cuda:0') \n",
            "Epoch 3:\n",
            "Train Loss: 0.7697515487670898 Validation Loss: 0.9452506303787231 dice_loss: tensor(0.9453, device='cuda:0') dice_score: tensor(0.0922, device='cuda:0') \n",
            "Epoch 4:\n",
            "Train Loss: 0.7454974055290222 Validation Loss: 0.9223038554191589 dice_loss: tensor(0.9223, device='cuda:0') dice_score: tensor(0.1788, device='cuda:0') \n",
            "Epoch 5:\n",
            "Train Loss: 0.7240031361579895 Validation Loss: 0.9077265858650208 dice_loss: tensor(0.9077, device='cuda:0') dice_score: tensor(0.1979, device='cuda:0') \n",
            "Epoch 6:\n",
            "Train Loss: 0.7132328152656555 Validation Loss: 0.8987869024276733 dice_loss: tensor(0.8988, device='cuda:0') dice_score: tensor(0.1812, device='cuda:0') \n",
            "Epoch 7:\n",
            "Train Loss: 0.6970800161361694 Validation Loss: 0.8770456910133362 dice_loss: tensor(0.8770, device='cuda:0') dice_score: tensor(0.1953, device='cuda:0') \n",
            "Epoch 8:\n",
            "Train Loss: 0.681733250617981 Validation Loss: 0.8750897645950317 dice_loss: tensor(0.8751, device='cuda:0') dice_score: tensor(0.1856, device='cuda:0') \n",
            "Epoch 9:\n",
            "Train Loss: 0.6805745959281921 Validation Loss: 0.8760272264480591 dice_loss: tensor(0.8760, device='cuda:0') dice_score: tensor(0.1803, device='cuda:0') \n",
            "Epoch 10:\n",
            "Train Loss: 0.6919827461242676 Validation Loss: 0.8536025881767273 dice_loss: tensor(0.8536, device='cuda:0') dice_score: tensor(0.1874, device='cuda:0') \n",
            "Epoch 11:\n",
            "Train Loss: 0.6638573408126831 Validation Loss: 0.8404466509819031 dice_loss: tensor(0.8404, device='cuda:0') dice_score: tensor(0.1908, device='cuda:0') \n",
            "Epoch 12:\n",
            "Train Loss: 0.6429566740989685 Validation Loss: 0.8371193408966064 dice_loss: tensor(0.8371, device='cuda:0') dice_score: tensor(0.1816, device='cuda:0') \n",
            "Epoch 13:\n",
            "Train Loss: 0.6285400390625 Validation Loss: 0.823599100112915 dice_loss: tensor(0.8236, device='cuda:0') dice_score: tensor(0.1921, device='cuda:0') \n",
            "Epoch 14:\n",
            "Train Loss: 0.6205651760101318 Validation Loss: 0.8064588904380798 dice_loss: tensor(0.8065, device='cuda:0') dice_score: tensor(0.2097, device='cuda:0') \n",
            "Epoch 15:\n",
            "Train Loss: 0.6165087223052979 Validation Loss: 0.8109490275382996 dice_loss: tensor(0.8109, device='cuda:0') dice_score: tensor(0.2003, device='cuda:0') \n",
            "Epoch 16:\n",
            "Train Loss: 0.6101237535476685 Validation Loss: 0.798294186592102 dice_loss: tensor(0.7983, device='cuda:0') dice_score: tensor(0.2140, device='cuda:0') \n",
            "Epoch 17:\n",
            "Train Loss: 0.6069648861885071 Validation Loss: 0.7962852716445923 dice_loss: tensor(0.7963, device='cuda:0') dice_score: tensor(0.2158, device='cuda:0') \n",
            "Epoch 18:\n",
            "Train Loss: 0.605218768119812 Validation Loss: 0.7981182932853699 dice_loss: tensor(0.7981, device='cuda:0') dice_score: tensor(0.2130, device='cuda:0') \n",
            "Epoch 19:\n",
            "Train Loss: 0.6030664443969727 Validation Loss: 0.7984070777893066 dice_loss: tensor(0.7984, device='cuda:0') dice_score: tensor(0.2123, device='cuda:0') \n",
            "Epoch 20:\n",
            "Train Loss: 0.6106125116348267 Validation Loss: 0.7955090403556824 dice_loss: tensor(0.7955, device='cuda:0') dice_score: tensor(0.2143, device='cuda:0') \n",
            "Epoch 21:\n",
            "Train Loss: 0.5999477505683899 Validation Loss: 0.8023895025253296 dice_loss: tensor(0.8024, device='cuda:0') dice_score: tensor(0.2032, device='cuda:0') \n",
            "Epoch 22:\n",
            "Train Loss: 0.5918625593185425 Validation Loss: 0.7830040454864502 dice_loss: tensor(0.7830, device='cuda:0') dice_score: tensor(0.2230, device='cuda:0') \n",
            "Epoch 23:\n",
            "Train Loss: 0.5856165885925293 Validation Loss: 0.7811698317527771 dice_loss: tensor(0.7812, device='cuda:0') dice_score: tensor(0.2233, device='cuda:0') \n",
            "Epoch 24:\n",
            "Train Loss: 0.5836492776870728 Validation Loss: 0.7842431664466858 dice_loss: tensor(0.7842, device='cuda:0') dice_score: tensor(0.2192, device='cuda:0') \n",
            "Epoch 25:\n",
            "Train Loss: 0.5791913270950317 Validation Loss: 0.7778563499450684 dice_loss: tensor(0.7779, device='cuda:0') dice_score: tensor(0.2258, device='cuda:0') \n",
            "Epoch 26:\n",
            "Train Loss: 0.5789951086044312 Validation Loss: 0.7780683636665344 dice_loss: tensor(0.7781, device='cuda:0') dice_score: tensor(0.2253, device='cuda:0') \n",
            "Epoch 27:\n",
            "Train Loss: 0.5753674507141113 Validation Loss: 0.7770617008209229 dice_loss: tensor(0.7771, device='cuda:0') dice_score: tensor(0.2261, device='cuda:0') \n",
            "Epoch 28:\n",
            "Train Loss: 0.5734698176383972 Validation Loss: 0.7769663333892822 dice_loss: tensor(0.7770, device='cuda:0') dice_score: tensor(0.2261, device='cuda:0') \n",
            "Epoch 29:\n",
            "Train Loss: 0.5750669836997986 Validation Loss: 0.7768239378929138 dice_loss: tensor(0.7768, device='cuda:0') dice_score: tensor(0.2263, device='cuda:0') \n",
            "Epoch 30:\n",
            "Train Loss: 0.5910308957099915 Validation Loss: 0.7880845069885254 dice_loss: tensor(0.7881, device='cuda:0') dice_score: tensor(0.2140, device='cuda:0') \n",
            "Epoch 31:\n",
            "Train Loss: 0.5760290622711182 Validation Loss: 0.7804533243179321 dice_loss: tensor(0.7805, device='cuda:0') dice_score: tensor(0.2213, device='cuda:0') \n",
            "Epoch 32:\n",
            "Train Loss: 0.5741189122200012 Validation Loss: 0.7752819657325745 dice_loss: tensor(0.7753, device='cuda:0') dice_score: tensor(0.2265, device='cuda:0') \n",
            "Epoch 33:\n",
            "Train Loss: 0.5690313577651978 Validation Loss: 0.7772635817527771 dice_loss: tensor(0.7773, device='cuda:0') dice_score: tensor(0.2241, device='cuda:0') \n",
            "Epoch 34:\n",
            "Train Loss: 0.5657626986503601 Validation Loss: 0.7749224901199341 dice_loss: tensor(0.7749, device='cuda:0') dice_score: tensor(0.2265, device='cuda:0') \n",
            "Epoch 35:\n",
            "Train Loss: 0.5643080472946167 Validation Loss: 0.775501549243927 dice_loss: tensor(0.7755, device='cuda:0') dice_score: tensor(0.2256, device='cuda:0') \n",
            "Epoch 36:\n",
            "Train Loss: 0.5619857907295227 Validation Loss: 0.771664023399353 dice_loss: tensor(0.7717, device='cuda:0') dice_score: tensor(0.2295, device='cuda:0') \n",
            "Epoch 37:\n",
            "Train Loss: 0.5603627562522888 Validation Loss: 0.7750551700592041 dice_loss: tensor(0.7751, device='cuda:0') dice_score: tensor(0.2260, device='cuda:0') \n",
            "Epoch 38:\n",
            "Train Loss: 0.5607089400291443 Validation Loss: 0.7741850018501282 dice_loss: tensor(0.7742, device='cuda:0') dice_score: tensor(0.2269, device='cuda:0') \n",
            "Epoch 39:\n",
            "Train Loss: 0.5593357086181641 Validation Loss: 0.7731105089187622 dice_loss: tensor(0.7731, device='cuda:0') dice_score: tensor(0.2280, device='cuda:0') \n",
            "Epoch 40:\n",
            "Train Loss: 0.5822519063949585 Validation Loss: 0.780170738697052 dice_loss: tensor(0.7802, device='cuda:0') dice_score: tensor(0.2209, device='cuda:0') \n",
            "Epoch 41:\n",
            "Train Loss: 0.5670167803764343 Validation Loss: 0.7732651829719543 dice_loss: tensor(0.7733, device='cuda:0') dice_score: tensor(0.2276, device='cuda:0') \n",
            "Epoch 42:\n",
            "Train Loss: 0.5613422393798828 Validation Loss: 0.7762651443481445 dice_loss: tensor(0.7763, device='cuda:0') dice_score: tensor(0.2243, device='cuda:0') \n",
            "Epoch 43:\n",
            "Train Loss: 0.5598213076591492 Validation Loss: 0.7731459140777588 dice_loss: tensor(0.7731, device='cuda:0') dice_score: tensor(0.2275, device='cuda:0') \n",
            "Epoch 44:\n",
            "Train Loss: 0.5545621514320374 Validation Loss: 0.7725127339363098 dice_loss: tensor(0.7725, device='cuda:0') dice_score: tensor(0.2282, device='cuda:0') \n",
            "Epoch 45:\n",
            "Train Loss: 0.554443359375 Validation Loss: 0.7728726863861084 dice_loss: tensor(0.7729, device='cuda:0') dice_score: tensor(0.2278, device='cuda:0') \n",
            "Epoch 46:\n",
            "Train Loss: 0.5540710687637329 Validation Loss: 0.7743018269538879 dice_loss: tensor(0.7743, device='cuda:0') dice_score: tensor(0.2263, device='cuda:0') \n",
            "Epoch 47:\n",
            "Train Loss: 0.5511263608932495 Validation Loss: 0.7701644897460938 dice_loss: tensor(0.7702, device='cuda:0') dice_score: tensor(0.2305, device='cuda:0') \n",
            "Epoch 48:\n",
            "Train Loss: 0.5501194596290588 Validation Loss: 0.771767258644104 dice_loss: tensor(0.7718, device='cuda:0') dice_score: tensor(0.2288, device='cuda:0') \n",
            "Epoch 49:\n",
            "Train Loss: 0.5484406352043152 Validation Loss: 0.7713027000427246 dice_loss: tensor(0.7713, device='cuda:0') dice_score: tensor(0.2294, device='cuda:0') \n",
            "Epoch 50:\n",
            "Train Loss: 0.5592423677444458 Validation Loss: 0.7743280529975891 dice_loss: tensor(0.7743, device='cuda:0') dice_score: tensor(0.2260, device='cuda:0') \n",
            "Epoch 51:\n",
            "Train Loss: 0.5537983775138855 Validation Loss: 0.7722988128662109 dice_loss: tensor(0.7723, device='cuda:0') dice_score: tensor(0.2283, device='cuda:0') \n",
            "Epoch 52:\n",
            "Train Loss: 0.5542301535606384 Validation Loss: 0.7749881148338318 dice_loss: tensor(0.7750, device='cuda:0') dice_score: tensor(0.2254, device='cuda:0') \n",
            "Epoch 53:\n",
            "Train Loss: 0.5481410622596741 Validation Loss: 0.7736836671829224 dice_loss: tensor(0.7737, device='cuda:0') dice_score: tensor(0.2266, device='cuda:0') \n",
            "Epoch 54:\n",
            "Train Loss: 0.5495252013206482 Validation Loss: 0.7676644921302795 dice_loss: tensor(0.7677, device='cuda:0') dice_score: tensor(0.2333, device='cuda:0') \n",
            "Epoch 55:\n",
            "Train Loss: 0.5471729040145874 Validation Loss: 0.7674673199653625 dice_loss: tensor(0.7675, device='cuda:0') dice_score: tensor(0.2332, device='cuda:0') \n",
            "Epoch 56:\n",
            "Train Loss: 0.5470987558364868 Validation Loss: 0.7685102820396423 dice_loss: tensor(0.7685, device='cuda:0') dice_score: tensor(0.2319, device='cuda:0') \n",
            "Epoch 57:\n",
            "Train Loss: 0.5432872176170349 Validation Loss: 0.7697741985321045 dice_loss: tensor(0.7698, device='cuda:0') dice_score: tensor(0.2306, device='cuda:0') \n",
            "Epoch 58:\n",
            "Train Loss: 0.5442755222320557 Validation Loss: 0.7657328248023987 dice_loss: tensor(0.7657, device='cuda:0') dice_score: tensor(0.2349, device='cuda:0') \n",
            "Epoch 59:\n",
            "Train Loss: 0.5438743829727173 Validation Loss: 0.7669127583503723 dice_loss: tensor(0.7669, device='cuda:0') dice_score: tensor(0.2336, device='cuda:0') \n",
            "Epoch 60:\n",
            "Train Loss: 0.5484551787376404 Validation Loss: 0.7727840542793274 dice_loss: tensor(0.7728, device='cuda:0') dice_score: tensor(0.2275, device='cuda:0') \n",
            "Epoch 61:\n",
            "Train Loss: 0.5535043478012085 Validation Loss: 0.7702228426933289 dice_loss: tensor(0.7702, device='cuda:0') dice_score: tensor(0.2301, device='cuda:0') \n",
            "Epoch 62:\n",
            "Train Loss: 0.5467063784599304 Validation Loss: 0.7656567096710205 dice_loss: tensor(0.7657, device='cuda:0') dice_score: tensor(0.2350, device='cuda:0') \n",
            "Epoch 63:\n",
            "Train Loss: 0.5461110472679138 Validation Loss: 0.7736738324165344 dice_loss: tensor(0.7737, device='cuda:0') dice_score: tensor(0.2265, device='cuda:0') \n",
            "Epoch 64:\n",
            "Train Loss: 0.5418588519096375 Validation Loss: 0.7610571980476379 dice_loss: tensor(0.7611, device='cuda:0') dice_score: tensor(0.2397, device='cuda:0') \n",
            "Epoch 65:\n",
            "Train Loss: 0.5403181314468384 Validation Loss: 0.7683155536651611 dice_loss: tensor(0.7683, device='cuda:0') dice_score: tensor(0.2321, device='cuda:0') \n",
            "Epoch 66:\n",
            "Train Loss: 0.5392910242080688 Validation Loss: 0.7400160431861877 dice_loss: tensor(0.7400, device='cuda:0') dice_score: tensor(0.3403, device='cuda:0') \n",
            "Epoch 67:\n",
            "Train Loss: 0.536198616027832 Validation Loss: 0.7278722524642944 dice_loss: tensor(0.7279, device='cuda:0') dice_score: tensor(0.3358, device='cuda:0') \n",
            "Epoch 68:\n",
            "Train Loss: 0.5340744853019714 Validation Loss: 0.7033178210258484 dice_loss: tensor(0.7033, device='cuda:0') dice_score: tensor(0.4625, device='cuda:0') \n",
            "Epoch 69:\n",
            "Train Loss: 0.5330091714859009 Validation Loss: 0.7170812487602234 dice_loss: tensor(0.7171, device='cuda:0') dice_score: tensor(0.3678, device='cuda:0') \n",
            "Epoch 70:\n",
            "Train Loss: 0.5442994236946106 Validation Loss: 0.7391129732131958 dice_loss: tensor(0.7391, device='cuda:0') dice_score: tensor(0.2691, device='cuda:0') \n",
            "Epoch 71:\n",
            "Train Loss: 0.5422891974449158 Validation Loss: 0.7698976397514343 dice_loss: tensor(0.7699, device='cuda:0') dice_score: tensor(0.2308, device='cuda:0') \n",
            "Epoch 72:\n",
            "Train Loss: 0.5379686951637268 Validation Loss: 0.39323005080223083 dice_loss: tensor(0.3932, device='cuda:0') dice_score: tensor(0.8787, device='cuda:0') \n",
            "Epoch 73:\n",
            "Train Loss: 0.5264925956726074 Validation Loss: 0.27459025382995605 dice_loss: tensor(0.2746, device='cuda:0') dice_score: tensor(0.9490, device='cuda:0') \n",
            "Epoch 74:\n",
            "Train Loss: 0.5173076391220093 Validation Loss: 0.22542360424995422 dice_loss: tensor(0.2254, device='cuda:0') dice_score: tensor(0.9558, device='cuda:0') \n",
            "Epoch 75:\n",
            "Train Loss: 0.5099647045135498 Validation Loss: 0.522765576839447 dice_loss: tensor(0.5228, device='cuda:0') dice_score: tensor(0.5320, device='cuda:0') \n",
            "Epoch 76:\n",
            "Train Loss: 0.5002350211143494 Validation Loss: 0.1781376749277115 dice_loss: tensor(0.1781, device='cuda:0') dice_score: tensor(0.9368, device='cuda:0') \n",
            "Epoch 77:\n",
            "Train Loss: 0.48646900057792664 Validation Loss: 0.17608296871185303 dice_loss: tensor(0.1761, device='cuda:0') dice_score: tensor(0.9259, device='cuda:0') \n",
            "Epoch 78:\n",
            "Train Loss: 0.48339730501174927 Validation Loss: 0.17910270392894745 dice_loss: tensor(0.1791, device='cuda:0') dice_score: tensor(0.9210, device='cuda:0') \n",
            "Epoch 79:\n",
            "Train Loss: 0.4845193028450012 Validation Loss: 0.1528535783290863 dice_loss: tensor(0.1529, device='cuda:0') dice_score: tensor(0.9625, device='cuda:0') \n",
            "Epoch 80:\n",
            "Train Loss: 0.5063902735710144 Validation Loss: 0.21617530286312103 dice_loss: tensor(0.2162, device='cuda:0') dice_score: tensor(0.8820, device='cuda:0') \n",
            "Epoch 81:\n",
            "Train Loss: 0.4880902171134949 Validation Loss: 0.11511015146970749 dice_loss: tensor(0.1151, device='cuda:0') dice_score: tensor(0.9488, device='cuda:0') \n",
            "Epoch 82:\n",
            "Train Loss: 0.4336651861667633 Validation Loss: 0.12264306843280792 dice_loss: tensor(0.1226, device='cuda:0') dice_score: tensor(0.9281, device='cuda:0') \n",
            "Epoch 83:\n",
            "Train Loss: 0.3627576529979706 Validation Loss: 0.053429290652275085 dice_loss: tensor(0.0534, device='cuda:0') dice_score: tensor(0.9727, device='cuda:0') \n",
            "Epoch 84:\n",
            "Train Loss: 0.3174538016319275 Validation Loss: 0.07899095118045807 dice_loss: tensor(0.0790, device='cuda:0') dice_score: tensor(0.9350, device='cuda:0') \n",
            "Epoch 85:\n",
            "Train Loss: 0.27683520317077637 Validation Loss: 0.048650212585926056 dice_loss: tensor(0.0487, device='cuda:0') dice_score: tensor(0.9621, device='cuda:0') \n",
            "Epoch 86:\n",
            "Train Loss: 0.25903308391571045 Validation Loss: 0.045622408390045166 dice_loss: tensor(0.0456, device='cuda:0') dice_score: tensor(0.9647, device='cuda:0') \n",
            "Epoch 87:\n",
            "Train Loss: 0.2480996549129486 Validation Loss: 0.04875863716006279 dice_loss: tensor(0.0488, device='cuda:0') dice_score: tensor(0.9596, device='cuda:0') \n",
            "Epoch 88:\n",
            "Train Loss: 0.23964694142341614 Validation Loss: 0.05232000723481178 dice_loss: tensor(0.0523, device='cuda:0') dice_score: tensor(0.9559, device='cuda:0') \n",
            "Epoch 89:\n",
            "Train Loss: 0.23703113198280334 Validation Loss: 0.053756508976221085 dice_loss: tensor(0.0538, device='cuda:0') dice_score: tensor(0.9534, device='cuda:0') \n",
            "Epoch 90:\n",
            "Train Loss: 0.27214014530181885 Validation Loss: 0.08467397838830948 dice_loss: tensor(0.0847, device='cuda:0') dice_score: tensor(0.9249, device='cuda:0') \n",
            "Epoch 91:\n",
            "Train Loss: 0.2568744122982025 Validation Loss: 0.5280744433403015 dice_loss: tensor(0.5281, device='cuda:0') dice_score: tensor(0.5620, device='cuda:0') \n",
            "Epoch 92:\n",
            "Train Loss: 0.22888246178627014 Validation Loss: 0.034825779497623444 dice_loss: tensor(0.0348, device='cuda:0') dice_score: tensor(0.9699, device='cuda:0') \n",
            "Epoch 93:\n",
            "Train Loss: 0.17580978572368622 Validation Loss: 0.02811555005609989 dice_loss: tensor(0.0281, device='cuda:0') dice_score: tensor(0.9741, device='cuda:0') \n",
            "Epoch 94:\n",
            "Train Loss: 0.13244985044002533 Validation Loss: 0.029230395331978798 dice_loss: tensor(0.0292, device='cuda:0') dice_score: tensor(0.9726, device='cuda:0') \n",
            "Epoch 95:\n",
            "Train Loss: 0.11600467562675476 Validation Loss: 0.03848782554268837 dice_loss: tensor(0.0385, device='cuda:0') dice_score: tensor(0.9629, device='cuda:0') \n",
            "Epoch 96:\n",
            "Train Loss: 0.1078137457370758 Validation Loss: 0.04179692268371582 dice_loss: tensor(0.0418, device='cuda:0') dice_score: tensor(0.9595, device='cuda:0') \n",
            "Epoch 97:\n",
            "Train Loss: 0.10185863077640533 Validation Loss: 0.030326489359140396 dice_loss: tensor(0.0303, device='cuda:0') dice_score: tensor(0.9708, device='cuda:0') \n",
            "Epoch 98:\n",
            "Train Loss: 0.09822598844766617 Validation Loss: 0.03454809635877609 dice_loss: tensor(0.0345, device='cuda:0') dice_score: tensor(0.9667, device='cuda:0') \n",
            "Epoch 99:\n",
            "Train Loss: 0.09577960520982742 Validation Loss: 0.03298823535442352 dice_loss: tensor(0.0330, device='cuda:0') dice_score: tensor(0.9682, device='cuda:0') \n"
          ]
        }
      ],
      "source": [
        "#Train Model\n",
        "gc.collect()\n",
        "\n",
        "if useWandB:\n",
        "    wandb.init(project=\"LiverSegmentationPreTraining\",\n",
        "            name=\"NoWeights\",\n",
        "            config={\n",
        "                \"BatchSize\":batchSize,\n",
        "                \"LearnRate\":learnRate,\n",
        "                \"Epochs\":epochs,\n",
        "                \"StartDimension\":startDim,\n",
        "                \"EpochsToDouble\":epochsToDouble\n",
        "            })\n",
        "\n",
        "TrainingEval.train(segmenter, lossFuncs, weights, trainIter, validationIter, epochs, startEpoch, learnRate, device, startDim, epochsToDouble, modelFile, epochsToSave, useWandB=useWandB, \n",
        "      cosineAnnealing=cosineAnnealing, restartEpochs=cosineRestartEpochs, progressive=0, unfreezeEpoch=-1)\n",
        "\n",
        "if useWandB:\n",
        "    wandb.finish()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iipij4bjp9hs"
      },
      "source": [
        "# **Evaluation/Ending**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1tLSjzH2F-Z",
        "outputId": "2f548a4b-f201-45cc-e02e-1c90911370e8"
      },
      "outputs": [],
      "source": [
        "modelName = \"\"\n",
        "classification = False\n",
        "modelFile = \"UsedModels/ContFineTune8BestLoss\"\n",
        "classLossFunc = LossFunctions.FocalLoss(weight0=0.2, weight1=0.8, gamma=2)\n",
        "\n",
        "lossFuncs = [[LossFunctions.dice_score, LossFunctions.hausdorff], []]\n",
        "#lossFuncs = [[LossFunctions.dice_score, LossFunctions.hausdorff], [LossFunctions.accuracy, LossFunctions.f1]]\n",
        "\n",
        "if classification:\n",
        "    net = encoder\n",
        "    net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "else:\n",
        "    net = UNet(device, multiTask=False).to(device)\n",
        "    net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "\n",
        "#Evaluate Model\n",
        "print(f\"Model: {modelName}\")\n",
        "\n",
        "losses = TrainingEval.evaluate(net, testIter, lossFuncs, device=device, encoder=classification)\n",
        "logStr = \"\"\n",
        "for i, arr in enumerate(losses):\n",
        "    for j, val in enumerate(arr):\n",
        "        logStr += (lossFuncs[i][j].__name__ if str(type(lossFuncs[i][j])) == \"<class 'function'>\" else type(lossFuncs[i][j]).__name__) + \": \" + str(val) + \" \"\n",
        "\n",
        "print(logStr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelName = \"\"\n",
        "modelFile = \"UsedModels/ContrastiveTest1BestLoss\"\n",
        "\n",
        "net = ContrastiveEncoder().to(device)\n",
        "net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "\n",
        "lossFunc = LossFunctions.ContrastiveLossCosine\n",
        "\n",
        "loss = TrainingEval.contrastiveEval(net, contTestIter, lossFunc, device=device, isDist=False)\n",
        "print(str(lossFunc) + \" \" + str(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI_1aq7_VJ01"
      },
      "outputs": [],
      "source": [
        "#modelFile = \"Run 2/Standard Pre-Training/PretrainedUNet7\"\n",
        "modelFile = \"Run 2/Standard Pre-Training/PretrainedUNet6\"\n",
        "dataset = LITSBinaryDataset(\"Datasets/Scan1Dataset.hdf5\")\n",
        "iter = DataLoader(dataset, batch_size=batchSize)\n",
        "\n",
        "net = UNet(0)\n",
        "net.load_state_dict(torch.load(modelFile), strict=False)\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "segmentationMask = TrainingEval.getMasks(net, iter, device=device)\n",
        "\n",
        "masksFile = \"PretrainMasksScan1\"\n",
        "wFile = h5py.File(masksFile, \"w\")\n",
        "\n",
        "for i, slice in enumerate(segmentationMask):\n",
        "    wFile.create_dataset(\"Slice\" + str(i), data=slice)\n",
        "\n",
        "wFile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LDAG1Pd2KXN"
      },
      "outputs": [],
      "source": [
        "#Close datasets\n",
        "trainDataset.closeFile()\n",
        "validationDataset.closeFile()\n",
        "testDataset.closeFile()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IGcZ_Vm5n5Yv",
        "6g1MsLCCoDhb",
        "6adquwMWoH0B",
        "D2RziTUxY8jV",
        "s4TpJ7zaoLed",
        "blz2NJ-mo_vJ",
        "UMT_AzWypZdL"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "ea23a5d6ea5dd6b47a6bacc48f8acbc6e91dc182fa6b25270d70228f0691131c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
